[2m[WebServer] [22m[build-only] 🔧 building frontend (debug)…
[2m[WebServer] [22m[build-only] 🏗  wasm-pack build …
[2m[WebServer] [22m[INFO]: 🎯  Checking for the Wasm target...
[2m[WebServer] [22m[INFO]: 🌀  Compiling to Wasm...
[2m[WebServer] [22m   Compiling agent-platform-frontend v0.1.0 (/Users/davidrose/git/zerg/frontend)
[2m[WebServer] [22mwarning: unused import: `super::*`
[2m[WebServer] [22m  --> src/generated/tool_definitions.rs:83:9
[2m[WebServer] [22m   |
[2m[WebServer] [22m83 |     use super::*;
[2m[WebServer] [22m   |         ^^^^^^^^
[2m[WebServer] [22m   |
[2m[WebServer] [22m   = note: `#[warn(unused_imports)]` on by default
[2m[WebServer] [22m
[2m[WebServer] [22mwarning: unused imports: `Envelope` and `WsMessage`
[2m[WebServer] [22m --> src/generated/mod.rs:9:23
[2m[WebServer] [22m  |
[2m[WebServer] [22m9 | pub use ws_messages::{Envelope, WsMessage};[2m[WebServer] [22m
[2m[WebServer] [22m  |                       ^^^^^^^^  ^^^^^^^^^
[2m[WebServer] [22m
[2m[WebServer] [22mwarning: unused variable: `client_id_str`
[2m[WebServer] [22m   --> src/command_executors.rs:655:17
[2m[WebServer] [22m    |
[2m[WebServer] [22m655 |             let client_id_str = client_id.map(|id| id.to_string()).unwrap_or_default();
[2m[WebServer] [22m    |                 ^^^^^^^^^^^^^ help: if this is intentional, prefix it with an underscore: `_client_id_str`
[2m[WebServer] [22m    |
[2m[WebServer] [22m    = note: `#[warn(unused_variables)]` on by default
[2m[WebServer] [22m
[2m[WebServer] [22mwarning: unused variable: `data`
[2m[WebServer] [22m   --> src/generated/ws_messages.rs:266:26
[2m[WebServer] [22m    |
[2m[WebServer] [22m266 | pub fn validate_envelope(data: &Value) -> Result<(), String> {
[2m[WebServer] [22m    |                          [2m[WebServer] [22m^^^^ help: if this is intentional, prefix it with an underscore: `_data`
[2m[WebServer] [22m
[2m[WebServer] [22mwarning: `agent-platform-frontend` (lib) generated 4 warnings (run `cargo fix --lib -p agent-platform-frontend` to apply 2 suggestions)
[2m[WebServer] [22m    Finished `dev` profile [unoptimized + debuginfo] target(s) in 3.36s
[2m[WebServer] [22m[INFO]: ⬇️  Installing wasm-bindgen...
[2m[WebServer] [22m[INFO]: Optional fields missing from Cargo.toml: 'description', 'repository', and 'license'. These are not necessary, but recommended
[2m[WebServer] [22m[INFO]: ✨   Done in 3.86s
[2m[WebServer] [22m[INFO]: 📦   Your wasm pkg is ready to publish at /Users/davidrose/git/zerg/frontend/pkg.
[2m[WebServer] [22m[build-only] 📦 copying WASM artifacts to www...
[2m[WebServer] [22m[build-only] ✍️  writing bootstrap.js …
[2m[WebServer] [22m[build-only] ✍️  writing config.js …
[2m[WebServer] [22m[build-only] ✅ build complete (output in frontend/www/)
🚀 Setting up test environment...
✅ Pre-test cleanup completed
✅ Test environment setup completed

Running 36 tests using 2 workers

🚀 Starting WCAG compliance test...
📊 Worker ID: 0
🚀 Starting keyboard navigation test...
📊 Test 1: Testing tab order...
📊 Tab 1: BUTTON [create-agent-btn]
📊 Tab 2: BUTTON [reset-db-btn]
📊 Tab 3: BUTTON
📊 Tab 4: BUTTON [global-dashboard-tab]
📊 Tab 5: BUTTON [global-canvas-tab]
📊 Tab 6: BODY
📊 Tab 7: BUTTON [create-agent-btn]
📊 Tab 8: BUTTON [reset-db-btn]
📊 Test 1: Checking semantic structure...
📊 Semantic elements found: {
  header: [33m0[39m,
  nav: [33m0[39m,
  main: [33m0[39m,
  section: [33m0[39m,
  article: [33m0[39m,
  aside: [33m0[39m,
  footer: [33m0[39m
}
⚠️  Consider adding semantic HTML elements
📊 Test 2: Checking heading hierarchy...
📊 Heading structure: { h1: [33m1[39m, h2: [33m1[39m, h3: [33m0[39m, h4: [33m0[39m, h5: [33m0[39m, h6: [33m0[39m }
✅ Page has primary heading (h1)
📊 Test 3: Checking ARIA attributes...
📊 ARIA attributes found: {
  [32m'aria-label'[39m: [33m1[39m,
  [32m'aria-labelledby'[39m: [33m0[39m,
  [32m'aria-describedby'[39m: [33m0[39m,
  [32m'aria-hidden'[39m: [33m1[39m,
  role: [33m1[39m,
  [32m'aria-expanded'[39m: [33m0[39m
}
✅ ARIA attributes are being used
📊 Test 4: Checking form accessibility...
📊 Form elements found: [33m11[39m
📊 Labeled form elements: [33m2[39m
✅ Form elements have labels
✅ WCAG compliance test completed
  ✓  1 tests/accessibility_ui_ux.spec.ts:18:7 › Accessibility and UI/UX › WCAG compliance and semantic markup (2.8s)
🚀 Starting screen reader compatibility test...
📊 Tab 9: BUTTON
📊 Tab 10: BUTTON [global-dashboard-tab]
📊 Unique focusable elements: [33m6[39m
✅ Multiple elements are keyboard accessible
📊 Test 2: Testing escape key functionality...
✅ Escape key press handled
📊 Test 3: Testing enter key activation...
✅ Enter key activation tested
📊 Test 4: Testing arrow key navigation...
✅ Keyboard navigation test completed
  ✓  2 tests/accessibility_ui_ux.spec.ts:113:7 › Accessibility and UI/UX › Keyboard navigation functionality (3.4s)
🚀 Starting color contrast test...
📊 Test 1: Checking page title and structure...
📊 Page title: AI Agent Platform
✅ Page has a descriptive title
📊 Test 2: Checking image alt text...
📊 Total images: [33m0[39m
📊 Images with alt text: [33m0[39m
📊 Decorative images (empty alt): [33m0[39m
📊 No images found on page
📊 Test 3: Checking link accessibility...
📊 Total links: [33m0[39m
📊 Test 4: Checking live regions...
📊 Live regions found: [33m0[39m
📊 Status/alert elements: [33m0[39m
📊 No live regions found (may not be needed)
✅ Screen reader compatibility test completed
  ✓  3 tests/accessibility_ui_ux.spec.ts:196:7 › Accessibility and UI/UX › Screen reader compatibility (1.4s)
🚀 Starting responsive design test...
📊 Test 1: Testing mobile viewport...
📊 Test 1: Analyzing color usage...
📊 Color-based indicators: [33m1[39m
📊 Icon-based indicators: [33m0[39m
⚠️  Consider adding icons or text to supplement color information
📊 Test 2: Checking focus indicators...
📊 Focus styles: {
  outline: [32m'rgb(0, 95, 204) auto 1px'[39m,
  outlineColor: [32m'rgb(0, 95, 204)'[39m,
  outlineWidth: [32m'1px'[39m,
  boxShadow: [32m'none'[39m,
  border: [32m'0px none rgb(10, 10, 15)'[39m
}
✅ Focus indicators are visible
📊 Test 3: Testing text scalability...
📊 Original text sizes: [
  { fontSize: [32m'14px'[39m, lineHeight: [32m'normal'[39m },
  { fontSize: [32m'14px'[39m, lineHeight: [32m'normal'[39m },
  { fontSize: [32m'14px'[39m, lineHeight: [32m'normal'[39m }
]
📊 Scaled text sizes: [
  { fontSize: [32m'19.2px'[39m, lineHeight: [32m'normal'[39m },
  { fontSize: [32m'19.2px'[39m, lineHeight: [32m'normal'[39m },
  { fontSize: [32m'19.2px'[39m, lineHeight: [32m'normal'[39m }
]
✅ Text scalability tested
✅ Color contrast test completed
  ✓  4 tests/accessibility_ui_ux.spec.ts:274:7 › Accessibility and UI/UX › Color contrast and visual accessibility (2.2s)
🚀 Starting user workflow usability test...
📊 Test 1: Testing agent creation workflow...
📊 Mobile layout: {
  bodyWidth: [33m375[39m,
  hasHorizontalScroll: [33mtrue[39m,
  navigationVisible: [33mfalse[39m,
  mainContentVisible: [33mfalse[39m
}
⚠️  Page has horizontal scroll on mobile
📊 Test 2: Testing tablet viewport...
📊 Tablet layout: { bodyWidth: [33m768[39m, hasHorizontalScroll: [33mfalse[39m }
📊 Test 3: Testing desktop viewport...
📊 Desktop layout: { bodyWidth: [33m1920[39m, hasHorizontalScroll: [33mfalse[39m }
📊 Test 4: Testing touch interactions...
📊 Touchable elements: [33m18[39m
📊 Touch target sizes: [
  { width: [33m114.46875[39m, height: [33m23[39m, area: [33m2632.78125[39m },
  { width: [33m109.75[39m, height: [33m30[39m, area: [33m3292.5[39m },
  { width: [33m27.734375[39m, height: [33m22[39m, area: [33m610.15625[39m },
  { width: [33m148.96875[39m, height: [33m43[39m, area: [33m6405.65625[39m },
  { width: [33m127.9375[39m, height: [33m43[39m, area: [33m5501.3125[39m }
]
📊 Adequate touch targets (44x44px+): [33m0[39m
✅ Responsive design test completed
  ✓  5 tests/accessibility_ui_ux.spec.ts:372:7 › Accessibility and UI/UX › Responsive design and mobile compatibility (2.5s)
🔍 Starting complete agent creation test...
📊 Worker ID: 0
📊 Step 0: Resetting database...
[2m[WebServer] [22mWARNING - Resetting database - dropping all tables
✅ Database reset successful
📊 Step 1: Verifying empty state...
📊 Initial agent count: [33m0[39m
📊 Step 2: Creating agent via API...
📊 Agent creation status: [33m201[39m
📊 Created agent ID: [33m1[39m
📊 Created agent name: Test Agent Worker 0
📊 Step 3: Verifying agent appears in list...
📊 Updated agent count: [33m1[39m
✅ Agent found in list with correct data
📊 Step 5: Testing UI integration...
📊 Create buttons found: [33m2[39m
📊 Test agent created: [33m2[39m
📊 Agent visible in dashboard: [33mfalse[39m
📊 Canvas workflow elements: { canvas: [33m0[39m, agentShelf: [33m0[39m, toolPalette: [33m0[39m }
📊 User workflow steps completed: [33m3[39m
📊 Total workflow time: [33m1640[39m ms
📊 Average step time: [33m547[39m ms
✅ User workflow is responsive
📊 Test 2: Testing error recovery...
📊 Agent visible in UI: [33mtrue[39m
✅ Agent successfully appears in UI
📊 Step 6: Creating second agent for isolation test...
📊 Second agent created with ID: [33m3[39m
📊 Step 7: Verifying agent isolation...
📊 Final agent count: [33m3[39m
📊 Worker-specific agent count: [33m2[39m
✅ Complete agent creation and isolation test passed!
  ✓  7 tests/agent_creation_full.spec.ts:15:7 › Agent Creation Full Workflow › Complete agent creation and isolation test (4.4s)
🚀 Starting complete canvas workflow test...
📊 Worker ID: 0
📊 Step 1: Creating test agent...
✅ Test agent created with ID: [33m4[39m
📊 Step 2: Navigating to application...
📊 Recovery elements found: [33m0[39m
✅ User workflow usability test completed
  ✓  6 tests/accessibility_ui_ux.spec.ts:467:7 › Accessibility and UI/UX › User workflow usability testing (6.6s)
🔍 Starting comprehensive debug test...
📊 Worker ID: 1
📊 NODE_ENV: test
🔍 Test 1: Basic connectivity
📊 Basic connectivity status: [33m200[39m
✅ Backend is accessible
🔍 Test 2: Header transmission
📊 Header transmission status: [33m200[39m
✅ Headers can be sent
🔍 Test 3: Agent GET endpoint
📊 Agent GET status: [33m200[39m
📊 Agent GET count: [33m1[39m
✅ Agent GET endpoint working
🔍 Test 4: Testing different database operations
📊 Testing user endpoint...
📊 User endpoint status: [33m200[39m
📊 User data available: [33mtrue[39m
🔍 Test 5: Workflow creation test
📊 Workflow creation status: [33m422[39m
❌ Workflow creation failed: {"detail":[{"type":"missing","loc":["body","canvas_data"],"msg":"Field required","input":{"name":"Test Workflow 1","description":"Test workflow for debugging"}}]}
🔍 Test 6: Minimal agent creation
📊 Minimal agent creation status: [33m201[39m
📊 Minimal agent created ID: [33m2[39m
✅ Agent creation working with mock model
🔍 Test 7: Database introspection
📊 System health status: [33m404[39m
✅ Comprehensive debug test complete
  ✓  9 tests/comprehensive_debug.spec.ts:15:7 › Comprehensive Debug › Complete system debug and diagnosis (365ms)
🚀 Starting data persistence test...
📊 Worker ID: 0
📊 Step 0: Resetting database...
[2m[WebServer] [22mWARNING - Resetting database - dropping all tables
✅ Database reset successful
📊 Test 1: Creating persistent data...
📊 Created agent ID: [33m5[39m
📊 Step 3: Verifying agent in dashboard...
📊 Agent visible in dashboard: [33mtrue[39m
📊 Step 4: Navigating to canvas...
📊 Canvas visible: [33mfalse[39m
✅ Complete canvas workflow test finished
📊 Summary: Basic navigation and UI structure validated
📊 Next: UI implementation needed for full drag-and-drop workflow
  ✓  8 tests/canvas_complete_workflow.spec.ts:17:7 › Complete Canvas Workflow › End-to-end canvas workflow with agent and tool execution (5.6s)
🚀 Starting auto-save test...
📊 Test 1: Looking for auto-save functionality...
📊 Form elements found: [33m8[39m
📊 Auto-save indicators: [33m0[39m
📊 Test 2: Testing data recovery after refresh...
📊 Visible input fields found: [33m0[39m
📊 No visible input fields found for draft recovery test
✅ Auto-save test completed
  ✓  11 tests/data_persistence_recovery.spec.ts:145:7 › Data Persistence and Recovery › Auto-save and draft recovery (1.4s)
🚀 Starting data consistency test...
📊 Test 1: Testing data relationships...
📊 Created agent for consistency test: [33m6[39m
📊 Created workflow with agent reference: [33m2[39m
📊 Test 2: Testing data integrity...
📊 Initial agent count: [33m6[39m
📊 After creation agent count: [33m7[39m
✅ Data integrity maintained during operations
✅ Data consistency test completed
  ✓  12 tests/data_persistence_recovery.spec.ts:218:7 › Data Persistence and Recovery › Data consistency and integrity (681ms)
🚀 Starting export/import test...
📊 Test 1: Looking for export functionality...
📊 Agent row visible in UI: [33mfalse[39m
📊 Agent name visible in UI: [33mfalse[39m
📊 Agent in table by name: [33mfalse[39m
📊 Any agents visible in table: [33mtrue[39m
📊 Test 2: Simulating session restart...
📊 Export buttons found: [33m0[39m
📊 Download buttons found: [33m0[39m
📊 Backup buttons found: [33m0[39m
📊 No export UI elements found (may be in different location)
📊 Test 2: Looking for import functionality...
📊 Import buttons found: [33m0[39m
📊 Upload buttons found: [33m0[39m
📊 File inputs found: [33m0[39m
📊 No import UI elements found (may be in different location)
📊 Test 3: API data integrity verification...
📊 Created test agent for export: [33m8[39m
📊 Data integrity on retrieval: [33mtrue[39m
✅ Data maintains integrity during storage/retrieval
✅ Export/import test completed
  ✓  13 tests/data_persistence_recovery.spec.ts:339:7 › Data Persistence and Recovery › Data export and import integrity (1.4s)
🚀 Starting data corruption recovery test...
📊 Test 1: Invalid data format recovery...
📊 Corrupt data response status: [33m422[39m
✅ Invalid data properly rejected
📊 Error details provided: [33mtrue[39m
📊 Test 2: System state recovery...
📊 Recovery creation status: [33m201[39m
✅ System recovered and accepts valid data after corruption attempt
📊 Test 3: UI state recovery...
📊 UI loaded successfully: [33mtrue[39m
📊 UI error count: [33m0[39m
✅ UI recovered successfully
✅ Data corruption recovery test completed
  ✓  14 tests/data_persistence_recovery.spec.ts:429:7 › Data Persistence and Recovery › Recovery from data corruption scenarios (1.5s)
🚀 Starting API error handling test...
📊 Worker ID: 0
📊 Test 1: Invalid agent creation - missing fields
📊 Invalid agent creation status: [33m422[39m
📊 Validation error structure: [33mtrue[39m
✅ Validation errors properly returned
📊 Test 2: Invalid JSON payload
📊 Invalid JSON status: [33m422[39m
✅ Invalid JSON properly rejected
📊 Test 3: Large payload handling
📊 Large payload status: [33m201[39m
✅ Large payload accepted (system handles large data)
📊 Test 4: Invalid HTTP methods
📊 Invalid method status: [33m405[39m
✅ Invalid HTTP methods properly rejected
📊 Test 5: Non-existent resource access
📊 Non-existent resource status: [33m404[39m
✅ Non-existent resources return 404
✅ API error handling test completed
  ✓  15 tests/error_handling_edge_cases.spec.ts:18:7 › Error Handling and Edge Cases › API error handling with invalid data (47ms)
🚀 Starting database constraint test...
📊 Test 1: Duplicate name handling
📊 First agent created: [33m11[39m
📊 Duplicate creation status: [33m201[39m
✅ Duplicate names allowed (system permits duplicates)
📊 Test 2: Field length validation
📊 Long field status: [33m201[39m
✅ Long fields accepted (no length limits)
✅ Database constraint test completed
  ✓  16 tests/error_handling_edge_cases.spec.ts:126:7 › Error Handling and Edge Cases › Database constraint and data integrity (38ms)
🚀 Starting concurrency test...
📊 Test 1: Concurrent agent creation
📊 Concurrent creation success: [33m5[39m
📊 Concurrent creation errors: [33m0[39m
✅ Concurrent operations handled well
📊 Test 2: Rapid-fire GET requests
📊 Rapid requests success: [33m10[39m
✅ Rapid requests handled well
✅ Concurrency test completed
  ✓  17 tests/error_handling_edge_cases.spec.ts:201:7 › Error Handling and Edge Cases › Concurrent operations and race conditions (678ms)
🚀 Starting UI error state test...
📊 Test 1: Network connectivity simulation
📊 Error indicators found: [33m0[39m
✅ Network connectivity simulation completed
📊 Test 2: Invalid navigation handling
📊 Agent persisted in database: [33mtrue[39m
📊 Total agents in database: [33m18[39m
📊 Agent visible after restart: [33mfalse[39m
⚠️  Agent exists in DB but not visible in UI - checking table rows...
📊 Table rows count: [33m1[39m
✅ Data persistence test completed
  ✓  10 tests/data_persistence_recovery.spec.ts:19:7 › Data Persistence and Recovery › Data persistence across sessions (14.0s)
🚀 Starting multi-user data isolation test...
📊 Created 3 user sessions
📊 Test 1: Creating isolated data per user...
📊 Invalid route page title: AI Agent Platform
📊 Error content present: [33mfalse[39m
📊 Test 3: JavaScript error monitoring
📊 User 0 created agent: [33m1[39m
📊 User 2 created agent: [33m1[39m
📊 User 1 created agent: [33m1[39m
📊 Successful agent creations: [33m3[39m / [33m3[39m
📊 Test 2: Verifying data isolation...
📊 User 0 sees own agent: [33mtrue[39m
📊 User 0 sees other users' agents: [33mtrue[39m
📊 User 1 sees own agent: [33mtrue[39m
📊 User 1 sees other users' agents: [33mtrue[39m
📊 User 2 sees own agent: [33mtrue[39m
📊 User 2 sees other users' agents: [33mtrue[39m
📊 Users with proper data isolation: [33m0[39m / [33m3[39m
⚠️  Data isolation may need improvement
✅ Multi-user data isolation test completed
  ✓  19 tests/multi_user_concurrency.spec.ts:18:7 › Multi-User and Concurrency › Multiple user sessions with data isolation (2.1s)
🚀 Starting concurrent workflow execution test...
📊 Created 3 workflow sessions
📊 Test 1: Creating workflows concurrently...
📊 User 0 created workflow: [33m1[39m
📊 User 1 created workflow: [33m1[39m
📊 User 2 created workflow: [33m1[39m
📊 Successful workflow creations: [33m3[39m / [33m3[39m
📊 Concurrent workflow creation time: [33m319[39m ms
📊 Test 2: Executing workflows concurrently...
[2m[WebServer] [22mERROR - [AgentRunner] Exception during runnable.ainvoke: Error code: 404 - {'error': {'message': 'The model `gpt-mock` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
[2m[WebServer] [22mTraceback (most recent call last):
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/managers/agent_runner.py", line 137, in run_thread
[2m[WebServer] [22m    updated_messages = await self._runnable.ainvoke(original_msgs, config)
[2m[WebServer] [22m                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2850, in ainvoke
[2m[WebServer] [22m    async for chunk in self.astream(
[2m[WebServer] [22m    ...<13 lines>...
[2m[WebServer] [22m            chunks.append(chunk)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2732, in astream
[2m[WebServer] [22m    async for _ in runner.atick(
[2m[WebServer] [22m    ...<7 lines>...
[2m[WebServer] [22m            yield o
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 256, in agent_executor
[2m[WebServer] [22m    return _agent_executor_sync(messages, previous=previous)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 248, in _agent_executor_sync
[2m[WebServer] [22m    return asyncio.run(_agent_executor_async(messages, previous=previous))
[2m[WebServer] [22m           ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/runners.py", line 194, in run
[2m[WebServer] [22m    return runner.run(main)
[2m[WebServer] [22m           ~~~~~~~~~~^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/runners.py", line 118, in run
[2m[WebServer] [22m    return self._loop.run_until_complete(task)
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/base_events.py", line 720, in run_until_complete
[2m[WebServer] [22m    return future.result()
[2m[WebServer] [22m           ~~~~~~~~~~~~~^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 208, in _agent_executor_async
[2m[WebServer] [22m    llm_response = await _call_model_async(current_messages)
[2m[WebServer] [22m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 134, in _call_model_async
[2m[WebServer] [22m    return await asyncio.to_thread(_call_model_sync, messages)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/threads.py", line 25, in to_thread
[2m[WebServer] [22m    return await loop.run_in_executor(None, func_call)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/thread.py", line 59, in run
[2m[WebServer] [22m    result = self.fn(*self.args, **self.kwargs)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 127, in _call_model_sync
[2m[WebServer] [22m    return llm_with_tools.invoke(messages)
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/runnables/base.py", line 5416, in invoke
[2m[WebServer] [22m    return self.bound.invoke(
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        input,
[2m[WebServer] [22m        ^^^^^^
[2m[WebServer] [22m        self._merge_configs(config),
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m        **{**self.kwargs, **kwargs},
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 369, in invoke
[2m[WebServer] [22m    self.generate_prompt(
[2m[WebServer] [22m    ~~~~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        [self._convert_input(input)],
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<6 lines>...
[2m[WebServer] [22m        **kwargs,
[2m[WebServer] [22m        ^^^^^^^^^
[2m[WebServer] [22m    ).generations[0][0],
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 946, in generate_prompt
[2m[WebServer] [22m    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
[2m[WebServer] [22m           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 765, in generate
[2m[WebServer] [22m    self._generate_with_cache(
[2m[WebServer] [22m    ~~~~~~~~~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        m,
[2m[WebServer] [22m        ^^
[2m[WebServer] [22m    ...<2 lines>...
[2m[WebServer] [22m        **kwargs,
[2m[WebServer] [22m        ^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 1011, in _generate_with_cache
[2m[WebServer] [22m    result = self._generate(
[2m[WebServer] [22m        messages, stop=stop, run_manager=run_manager, **kwargs
[2m[WebServer] [22m    )
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py", line 956, in _generate
[2m[WebServer] [22m    return generate_from_stream(stream_iter)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 153, in generate_from_stream
[2m[WebServer] [22m    generation = next(stream, None)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py", line 907, in _stream
[2m[WebServer] [22m    response = self.client.create(**payload)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_utils/_utils.py", line 287, in wrapper
[2m[WebServer] [22m    return func(*args, **kwargs)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py", line 925, in create
[2m[WebServer] [22m    return self._post(
[2m[WebServer] [22m           ~~~~~~~~~~^
[2m[WebServer] [22m        "/chat/completions",
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<43 lines>...
[2m[WebServer] [22m        stream_cls=Stream[ChatCompletionChunk],
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_base_client.py", line 1239, in post
[2m[WebServer] [22m    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
[2m[WebServer] [22m                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_base_client.py", line 1034, in request
[2m[WebServer] [22m    raise self._make_status_error_from_response(err.response) from None
[2m[WebServer] [22mopenai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `gpt-mock` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
[2m[WebServer] [22mDuring task with name 'agent_executor' and id 'a3a61c4f-842b-ea8f-7f56-45a175cacb1e'
[2m[WebServer] [22mERROR - [AgentNode] Exception in agent node agent-1 (agent_id=1): Error code: 404 - {'error': {'message': 'The model `gpt-mock` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
[2m[WebServer] [22mTraceback (most recent call last):
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/services/langgraph_workflow_engine.py", line 729, in agent_node
[2m[WebServer] [22m    created_messages = await runner.run_thread(db, thread)
[2m[WebServer] [22m                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/managers/agent_runner.py", line 137, in run_thread
[2m[WebServer] [22m    updated_messages = await self._runnable.ainvoke(original_msgs, config)
[2m[WebServer] [22m                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2850, in ainvoke
[2m[WebServer] [22m    async for chunk in self.astream(
[2m[WebServer] [22m    ...<13 lines>...
[2m[WebServer] [22m            chunks.append(chunk)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2732, in astream
[2m[WebServer] [22m    async for _ in runner.atick(
[2m[WebServer] [22m    ...<7 lines>...
[2m[WebServer] [22m            yield o
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 256, in agent_executor
[2m[WebServer] [22m    return _agent_executor_sync(messages, previous=previous)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 248, in _agent_executor_sync
[2m[WebServer] [22m    return asyncio.run(_agent_executor_async(messages, previous=previous))
[2m[WebServer] [22m           ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/runners.py", line 194, in run
[2m[WebServer] [22m    return runner.run(main)
[2m[WebServer] [22m           ~~~~~~~~~~^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/runners.py", line 118, in run
[2m[WebServer] [22m    return self._loop.run_until_complete(task)
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/base_events.py", line 720, in run_until_complete
[2m[WebServer] [22m    return future.result()
[2m[WebServer] [22m           ~~~~~~~~~~~~~^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 208, in _agent_executor_async
[2m[WebServer] [22m    llm_response = await _call_model_async(current_messages)
[2m[WebServer] [22m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 134, in _call_model_async
[2m[WebServer] [22m    return await asyncio.to_thread(_call_model_sync, messages)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/threads.py", line 25, in to_thread
[2m[WebServer] [22m    return await loop.run_in_executor(None, func_call)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/thread.py", line 59, in run
[2m[WebServer] [22m    result = self.fn(*self.args, **self.kwargs)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 127, in _call_model_sync
[2m[WebServer] [22m    return llm_with_tools.invoke(messages)
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/runnables/base.py", line 5416, in invoke
[2m[WebServer] [22m    return self.bound.invoke(
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        input,
[2m[WebServer] [22m        ^^^^^^
[2m[WebServer] [22m        self._merge_configs(config),
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m        **{**self.kwargs, **kwargs},
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 369, in invoke
[2m[WebServer] [22m    self.generate_prompt(
[2m[WebServer] [22m    ~~~~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        [self._convert_input(input)],
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<6 lines>...
[2m[WebServer] [22m        **kwargs,
[2m[WebServer] [22m        ^^^^^^^^^
[2m[WebServer] [22m    ).generations[0][0],
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 946, in generate_prompt
[2m[WebServer] [22m    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
[2m[WebServer] [22m           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 765, in generate
[2m[WebServer] [22m    self._generate_with_cache(
[2m[WebServer] [22m    ~~~~~~~~~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        m,
[2m[WebServer] [22m        ^^
[2m[WebServer] [22m    ...<2 lines>...
[2m[WebServer] [22m        **kwargs,
[2m[WebServer] [22m        ^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 1011, in _generate_with_cache
[2m[WebServer] [22m    result = self._generate(
[2m[WebServer] [22m        messages, stop=stop, run_manager=run_manager, **kwargs
[2m[WebServer] [22m    )
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py", line 956, in _generate
[2m[WebServer] [22m    return generate_from_stream(stream_iter)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 153, in generate_from_stream
[2m[WebServer] [22m    generation = next(stream, None)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py", line 907, in _stream
[2m[WebServer] [22m    response = self.client.create(**payload)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_utils/_utils.py", line 287, in wrapper
[2m[WebServer] [22m    return func(*args, **kwargs)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py", line 925, in create
[2m[WebServer] [22m    return self._post(
[2m[WebServer] [22m           ~~~~~~~~~~^
[2m[WebServer] [22m        "/chat/completions",
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<43 lines>...
[2m[WebServer] [22m        stream_cls=Stream[ChatCompletionChunk],
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_base_client.py", line 1239, in post
[2m[WebServer] [22m    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
[2m[WebServer] [22m                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_base_client.py", line 1034, in request
[2m[WebServer] [22m    raise self._make_status_error_from_response(err.response) from None
[2m[WebServer] [22mopenai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `gpt-mock` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
[2m[WebServer] [22mDuring task with name 'agent_executor' and id 'a3a61c4f-842b-ea8f-7f56-45a175cacb1e'
[2m[WebServer] [22mERROR - [AgentNode] Updated node_state to 'failed' in DB
[2m[WebServer] [22mERROR - [AgentNode] Re-raising exception to fail workflow execution
[2m[WebServer] [22mERROR - [LangGraphEngine] Execution failed – execution_id=1
[2m[WebServer] [22mTraceback (most recent call last):
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/services/langgraph_workflow_engine.py", line 146, in execute_workflow
[2m[WebServer] [22m    await self._execute_workflow_internal(workflow, execution, db)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/services/langgraph_workflow_engine.py", line 214, in _execute_workflow_internal
[2m[WebServer] [22m    async for chunk in graph.astream(initial_state, config):
[2m[WebServer] [22m    ...<36 lines>...
[2m[WebServer] [22m            logger.warning(f"[LangGraphEngine] Received empty chunk #{chunk_count}")
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2732, in astream
[2m[WebServer] [22m    async for _ in runner.atick(
[2m[WebServer] [22m    ...<7 lines>...
[2m[WebServer] [22m            yield o
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/services/langgraph_workflow_engine.py", line 729, in agent_node
[2m[WebServer] [22m    created_messages = await runner.run_thread(db, thread)
[2m[WebServer] [22m                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/managers/agent_runner.py", line 137, in run_thread
[2m[WebServer] [22m    updated_messages = await self._runnable.ainvoke(original_msgs, config)
[2m[WebServer] [22m                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2850, in ainvoke
[2m[WebServer] [22m    async for chunk in self.astream(
[2m[WebServer] [22m    ...<13 lines>...
[2m[WebServer] [22m            chunks.append(chunk)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2732, in astream
[2m[WebServer] [22m    async for _ in runner.atick(
[2m[WebServer] [22m    ...<7 lines>...
[2m[WebServer] [22m            yield o
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 256, in agent_executor
[2m[WebServer] [22m    return _agent_executor_sync(messages, previous=previous)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 248, in _agent_executor_sync
[2m[WebServer] [22m    return asyncio.run(_agent_executor_async(messages, previous=previous))
[2m[WebServer] [22m           ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/runners.py", line 194, in run
[2m[WebServer] [22m    return runner.run(main)
[2m[WebServer] [22m           ~~~~~~~~~~^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/runners.py", line 118, in run
[2m[WebServer] [22m    return self._loop.run_until_complete(task)
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/base_events.py", line 720, in run_until_complete
[2m[WebServer] [22m    return future.result()
[2m[WebServer] [22m           ~~~~~~~~~~~~~^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 208, in _agent_executor_async
[2m[WebServer] [22m    llm_response = await _call_model_async(current_messages)
[2m[WebServer] [22m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 134, in _call_model_async
[2m[WebServer] [22m    return await asyncio.to_thread(_call_model_sync, messages)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/threads.py", line 25, in to_thread
[2m[WebServer] [22m    return await loop.run_in_executor(None, func_call)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/thread.py", line 59, in run
[2m[WebServer] [22m    result = self.fn(*self.args, **self.kwargs)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 127, in _call_model_sync
[2m[WebServer] [22m    return llm_with_tools.invoke(messages)
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/runnables/base.py", line 5416, in invoke
[2m[WebServer] [22m    return self.bound.invoke(
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        input,
[2m[WebServer] [22m        ^^^^^^
[2m[WebServer] [22m        self._merge_configs(config),
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m        **{**self.kwargs, **kwargs},
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 369, in invoke
[2m[WebServer] [22m    self.generate_prompt(
[2m[WebServer] [22m    ~~~~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        [self._convert_input(input)],
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<6 lines>...
[2m[WebServer] [22m        **kwargs,
[2m[WebServer] [22m        ^^^^^^^^^
[2m[WebServer] [22m    ).generations[0][0],
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 946, in generate_prompt
[2m[WebServer] [22m    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
[2m[WebServer] [22m           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 765, in generate
[2m[WebServer] [22m    self._generate_with_cache(
[2m[WebServer] [22m    ~~~~~~~~~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        m,
[2m[WebServer] [22m        ^^
[2m[WebServer] [22m    ...<2 lines>...
[2m[WebServer] [22m        **kwargs,
[2m[WebServer] [22m        ^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 1011, in _generate_with_cache
[2m[WebServer] [22m    result = self._generate(
[2m[WebServer] [22m        messages, stop=stop, run_manager=run_manager, **kwargs
[2m[WebServer] [22m    )
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py", line 956, in _generate
[2m[WebServer] [22m    return generate_from_stream(stream_iter)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 153, in generate_from_stream
[2m[WebServer] [22m    generation = next(stream, None)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py", line 907, in _stream
[2m[WebServer] [22m    response = self.client.create(**payload)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_utils/_utils.py", line 287, in wrapper
[2m[WebServer] [22m    return func(*args, **kwargs)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py", line 925, in create
[2m[WebServer] [22m    return self._post(
[2m[WebServer] [22m           ~~~~~~~~~~^
[2m[WebServer] [22m        "/chat/completions",
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<43 lines>...
[2m[WebServer] [22m        stream_cls=Stream[ChatCompletionChunk],
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_base_client.py", line 1239, in post
[2m[WebServer] [22m    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
[2m[WebServer] [22m                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_base_client.py", line 1034, in request
[2m[WebServer] [22m    raise self._make_status_error_from_response(err.response) from None
[2m[WebServer] [22mopenai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `gpt-mock` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
[2m[WebServer] [22mDuring task with name 'agent_executor' and id 'a3a61c4f-842b-ea8f-7f56-45a175cacb1e'
[2m[WebServer] [22mDuring task with name 'agent-1' and id '1e1253aa-7a76-fc74-67e5-ce645c840031'
[2m[WebServer] [22mERROR - Unhandled exception: Error code: 404 - {'error': {'message': 'The model `gpt-mock` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
[2m[WebServer] [22mTraceback (most recent call last):
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/middleware/errors.py", line 165, in __call__
[2m[WebServer] [22m    await self.app(scope, receive, _send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/middleware/worker_db.py", line 101, in __call__
[2m[WebServer] [22m    await self.app(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/middleware/cors.py", line 85, in __call__
[2m[WebServer] [22m    await self.app(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/middleware/exceptions.py", line 62, in __call__
[2m[WebServer] [22m    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
[2m[WebServer] [22m    raise exc
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
[2m[WebServer] [22m    await app(scope, receive, sender)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/routing.py", line 714, in __call__
[2m[WebServer] [22m    await self.middleware_stack(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/routing.py", line 734, in app
[2m[WebServer] [22m    await route.handle(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/routing.py", line 288, in handle
[2m[WebServer] [22m    await self.app(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/routing.py", line 76, in app
[2m[WebServer] [22m    await wrap_app_handling_exceptions(app, request)(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
[2m[WebServer] [22m    raise exc
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
[2m[WebServer] [22m    await app(scope, receive, sender)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/routing.py", line 73, in app
[2m[WebServer] [22m    response = await f(request)
[2m[WebServer] [22m               ^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/fastapi/routing.py", line 301, in app
[2m[WebServer] [22m    raw_response = await run_endpoint_function(
[2m[WebServer] [22m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<3 lines>...
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/fastapi/routing.py", line 212, in run_endpoint_function
[2m[WebServer] [22m    return await dependant.call(**values)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/routers/workflow_executions.py", line 74, in start_workflow_execution
[2m[WebServer] [22m    execution_id = await langgraph_workflow_engine.execute_workflow(workflow_id)
[2m[WebServer] [22m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/services/langgraph_workflow_engine.py", line 146, in execute_workflow
[2m[WebServer] [22m    await self._execute_workflow_internal(workflow, execution, db)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/services/langgraph_workflow_engine.py", line 214, in _execute_workflow_internal
[2m[WebServer] [22m    async for chunk in graph.astream(initial_state, config):
[2m[WebServer] [22m    ...<36 lines>...
[2m[WebServer] [22m            logger.warning(f"[LangGraphEngine] Received empty chunk #{chunk_count}")
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2732, in astream
[2m[WebServer] [22m    async for _ in runner.atick(
[2m[WebServer] [22m    ...<7 lines>...
[2m[WebServer] [22m            yield o
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/services/langgraph_workflow_engine.py", line 729, in agent_node
[2m[WebServer] [22m    created_messages = await runner.run_thread(db, thread)
[2m[WebServer] [22m                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/managers/agent_runner.py", line 137, in run_thread
[2m[WebServer] [22m    updated_messages = await self._runnable.ainvoke(original_msgs, config)
[2m[WebServer] [22m                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2850, in ainvoke
[2m[WebServer] [22m    async for chunk in self.astream(
[2m[WebServer] [22m    ...<13 lines>...
[2m[WebServer] [22m            chunks.append(chunk)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2732, in astream
[2m[WebServer] [22m    async for _ in runner.atick(
[2m[WebServer] [22m    ...<7 lines>...
[2m[WebServer] [22m            yield o
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 256, in agent_executor
[2m[WebServer] [22m    return _agent_executor_sync(messages, previous=previous)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 248, in _agent_executor_sync
[2m[WebServer] [22m    return asyncio.run(_agent_executor_async(messages, previous=previous))
[2m[WebServer] [22m           ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/runners.py", line 194, in run
[2m[WebServer] [22m    return runner.run(main)
[2m[WebServer] [22m           ~~~~~~~~~~^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/runners.py", line 118, in run
[2m[WebServer] [22m    return self._loop.run_until_complete(task)
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/base_events.py", line 720, in run_until_complete
[2m[WebServer] [22m    return future.result()
[2m[WebServer] [22m           ~~~~~~~~~~~~~^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 208, in _agent_executor_async
[2m[WebServer] [22m    llm_response = await _call_model_async(current_messages)
[2m[WebServer] [22m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 134, in _call_model_async
[2m[WebServer] [22m    return await asyncio.to_thread(_call_model_sync, messages)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/threads.py", line 25, in to_thread
[2m[WebServer] [22m    return await loop.run_in_executor(None, func_call)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/thread.py", line 59, in run
[2m[WebServer] [22m    result = self.fn(*self.args, **self.kwargs)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 127, in _call_model_sync
[2m[WebServer] [22m    return llm_with_tools.invoke(messages)
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/runnables/base.py", line 5416, in invoke
[2m[WebServer] [22m    return self.bound.invoke(
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        input,
[2m[WebServer] [22m        ^^^^^^
[2m[WebServer] [22m        self._merge_configs(config),
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m        **{**self.kwargs, **kwargs},
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 369, in invoke
[2m[WebServer] [22m    self.generate_prompt(
[2m[WebServer] [22m    ~~~~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        [self._convert_input(input)],
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<6 lines>...
[2m[WebServer] [22m        **kwargs,
[2m[WebServer] [22m        ^^^^^^^^^
[2m[WebServer] [22m    ).generations[0][0],
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 946, in generate_prompt
[2m[WebServer] [22m    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
[2m[WebServer] [22m           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 765, [2m[WebServer] [22min generate
[2m[WebServer] [22m    self._generate_with_cache(
[2m[WebServer] [22m    ~~~~~~~~~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        m,
[2m[WebServer] [22m        ^^
[2m[WebServer] [22m    ...<2 lines>...
[2m[WebServer] [22m        **kwargs,
[2m[WebServer] [22m        ^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 1011, in _generate_with_cache
[2m[WebServer] [22m    result = self._generate(
[2m[WebServer] [22m        messages, stop=stop, run_manager=run_manager, **kwargs
[2m[WebServer] [22m    )
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py", line 956, in _generate
[2m[WebServer] [22m    return generate_from_stream(stream_iter)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 153, in generate_from_stream
[2m[WebServer] [22m    generation = next(stream, None)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py", line 907, in _stream
[2m[WebServer] [22m    response = self.client.create(**payload)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_utils/_utils.py", line 287, in wrapper
[2m[WebServer] [22m    return func(*args, **kwargs)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py", line 925, in create
[2m[WebServer] [22m    return self._post(
[2m[WebServer] [22m           ~~~~~~~~~~^
[2m[WebServer] [22m        "/chat/completions",
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<43 lines>...
[2m[WebServer] [22m        stream_cls=Stream[ChatCompletionChunk],
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_base_client.py", line 1239, in post
[2m[WebServer] [22m    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
[2m[WebServer] [22m                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_base_client.py", line 1034, in request
[2m[WebServer] [22m    raise self._make_status_error_from_response(err.response) from None
[2m[WebServer] [22mopenai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `gpt-mock` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
[2m[WebServer] [22mDuring task with name 'agent_executor' and id 'a3a61c4f-842b-ea8f-7f56-45a175cacb1e'
[2m[WebServer] [22mDuring task with name 'agent-1' and id '1e1253aa-7a76-fc74-67e5-ce645c840031'
❌ User 2 execution failed: [33m500[39m
[2m[WebServer] [22mERROR:    Exception in ASGI application
[2m[WebServer] [22mTraceback (most recent call last):
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/uvicorn/protocols/http/h11_impl.py", line 408, in run_asgi
[2m[WebServer] [22m    result = await app(  # type: ignore[func-returns-value]
[2m[WebServer] [22m             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m        self.scope, self.receive, self.send
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/uvicorn/middleware/proxy_headers.py", line 84, in __call__
[2m[WebServer] [22m    return await self.app(scope, receive, send)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/fastapi/applications.py", line 1054, in __call__
[2m[WebServer] [22m    await super().__call__(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/applications.py", line 112, in __call__
[2m[WebServer] [22m    await self.middleware_stack(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/middleware/errors.py", line 187, in __call__
[2m[WebServer] [22m    raise exc
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/middleware/errors.py", line 165, in __call__
[2m[WebServer] [22m    await self.app(scope, receive, _send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/middleware/worker_db.py", line 101, in __call__
[2m[WebServer] [22m    await self.app(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/middleware/cors.py", line 85, in __call__
[2m[WebServer] [22m    await self.app(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/middleware/exceptions.py", line 62, in __call__
[2m[WebServer] [22m    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
[2m[WebServer] [22m    raise exc
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
[2m[WebServer] [22m    await app(scope, receive, sender)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/routing.py", line 714, in __call__
[2m[WebServer] [22m    await self.middleware_stack(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/routing.py", line 734, in app
[2m[WebServer] [22m    await route.handle(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/routing.py", line 288, in handle
[2m[WebServer] [22m    await self.app(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/routing.py", line 76, in app
[2m[WebServer] [22m    await wrap_app_handling_exceptions(app, request)(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
[2m[WebServer] [22m    raise exc
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
[2m[WebServer] [22m    await app(scope, receive, sender)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/routing.py", line 73, in app
[2m[WebServer] [22m    response = await f(request)
[2m[WebServer] [22m               ^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/fastapi/routing.py", line 301, in app
[2m[WebServer] [22m    raw_response = await run_endpoint_function(
[2m[WebServer] [22m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<3 lines>...
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/fastapi/routing.py", line 212, in run_endpoint_function
[2m[WebServer] [22m    return await dependant.call(**values)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/routers/workflow_executions.py", line 74, in start_workflow_execution
[2m[WebServer] [22m    execution_id = await langgraph_workflow_engine.execute_workflow(workflow_id)
[2m[WebServer] [22m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/services/langgraph_workflow_engine.py", line 146, in execute_workflow
[2m[WebServer] [22m    await self._execute_workflow_internal(workflow, execution, db)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/services/langgraph_workflow_engine.py", line 214, in _execute_workflow_internal
[2m[WebServer] [22m    async for chunk in graph.astream(initial_state, config):
[2m[WebServer] [22m    ...<36 lines>...
[2m[WebServer] [22m            logger.warning(f"[LangGraphEngine] Received empty chunk #{chunk_count}")
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2732, in astream
[2m[WebServer] [22m    async for _ in runner.atick(
[2m[WebServer] [22m    ...<7 lines>...
[2m[WebServer] [22m            yield o
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/services/langgraph_workflow_engine.py", line 729, in agent_node
[2m[WebServer] [22m    created_messages = await runner.run_thread(db, thread)
[2m[WebServer] [22m                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/managers/agent_runner.py", line 137, in run_thread
[2m[WebServer] [22m    updated_messages = await self._runnable.ainvoke(original_msgs, config)
[2m[WebServer] [22m                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2850, in ainvoke
[2m[WebServer] [22m    async for chunk in self.astream(
[2m[WebServer] [22m    ...<13 lines>...
[2m[WebServer] [22m            chunks.append(chunk)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2732, in astream
[2m[WebServer] [22m    async for _ in runner.atick(
[2m[WebServer] [22m    ...<7 lines>...
[2m[WebServer] [22m            yield o
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 256, in agent_executor
[2m[WebServer] [22m    return _agent_executor_sync(messages, previous=previous)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 248, in _agent_executor_sync
[2m[WebServer] [22m    return asyncio.run(_agent_executor_async(messages, previous=previous))
[2m[WebServer] [22m           ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/runners.py", line 194, in run
[2m[WebServer] [22m    return runner.run(main)
[2m[WebServer] [22m           ~~~~~~~~~~^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/runners.py", line 118, in run
[2m[WebServer] [22m    return self._loop.run_until_complete(task)
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/base_events.py", line 720, in run_until_complete
[2m[WebServer] [22m    return future.result()
[2m[WebServer] [22m           ~~~~~~~~~~~~~^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 208, in _agent_executor_async
[2m[WebServer] [22m    llm_response = await _call_model_async(current_messages)
[2m[WebServer] [22m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 134, in _call_model_async
[2m[WebServer] [22m    return await asyncio.to_thread(_call_model_sync, messages)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/threads.py", line 25, in to_thread
[2m[WebServer] [22m    return await loop.run_in_executor(None, func_call)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/thread.py", line 59, in run
[2m[WebServer] [22m    result = self.fn(*self.args, **self.kwargs)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 127, in _call_model_sync
[2m[WebServer] [22m    return llm_with_tools.invoke(messages)
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/runnables/base.py", line 5416, in invoke
[2m[WebServer] [22m    return self.bound.invoke(
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        input,
[2m[WebServer] [22m        ^^^^^^
[2m[WebServer] [22m        self._merge_configs(config),
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^[2m[WebServer] [22m^^^^^^^^^
[2m[WebServer] [22m        **{**self.kwargs, **kwargs},
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 369, in invoke
[2m[WebServer] [22m    self.generate_prompt(
[2m[WebServer] [22m    ~~~~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        [self._convert_input(input)],
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<6 lines>...
[2m[WebServer] [22m        **kwargs,
[2m[WebServer] [22m        ^^^^^^^^^
[2m[WebServer] [22m    ).generations[0][0],
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 946, in generate_prompt
[2m[WebServer] [22m    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
[2m[WebServer] [22m           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 765, in generate
[2m[WebServer] [22m    self._generate_with_cache(
[2m[WebServer] [22m    ~~~~~~~~~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        m,
[2m[WebServer] [22m        ^^
[2m[WebServer] [22m    ...<2 lines>...
[2m[WebServer] [22m        **kwargs,
[2m[WebServer] [22m        ^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 1011, in _generate_with_cache
[2m[WebServer] [22m    result = self._generate(
[2m[WebServer] [22m        messages, stop=stop, run_manager=run_manager, **kwargs
[2m[WebServer] [22m    )
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py", line 956, in _generate
[2m[WebServer] [22m    return generate_from_stream(stream_iter)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 153, in generate_from_stream
[2m[WebServer] [22m    generation = next(stream, None)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py", line 907, in _stream
[2m[WebServer] [22m    response = self.client.create(**payload)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_utils/_utils.py", line 287, in wrapper
[2m[WebServer] [22m    return func(*args, **kwargs)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py", line 925, in create
[2m[WebServer] [22m    return self._post(
[2m[WebServer] [22m           ~~~~~~~~~~^
[2m[WebServer] [22m        "/chat/completions",
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<43 lines>...
[2m[WebServer] [22m        stream_cls=Stream[ChatCompletionChunk],
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_base_client.py", line 1239, in post
[2m[WebServer] [22m    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
[2m[WebServer] [22m                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_base_client.py", line 1034, in request
[2m[WebServer] [22m    raise self._make_status_error_from_response(err.response) from None
[2m[WebServer] [22mopenai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `gpt-mock` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
[2m[WebServer] [22mDuring task with name 'agent_executor' and id 'a3a61c4f-842b-ea8f-7f56-45a175cacb1e'
[2m[WebServer] [22mDuring task with name 'agent-1' and id '1e1253aa-7a76-fc74-67e5-ce645c840031'
[2m[WebServer] [22mERROR - [AgentRunner] Exception during runnable.ainvoke: Error code: 404 - {'error': {'message': 'The model `gpt-mock` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
[2m[WebServer] [22mTraceback (most recent call last):
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/managers/agent_runner.py", line 137, in run_thread
[2m[WebServer] [22m    updated_messages = await self._runnable.ainvoke(original_msgs, config)
[2m[WebServer] [22m                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2850, in ainvoke
[2m[WebServer] [22m    async for chunk in self.astream(
[2m[WebServer] [22m    ...<13 lines>...
[2m[WebServer] [22m            chunks.append(chunk)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2732, in astream
[2m[WebServer] [22m    async for _ in runner.atick(
[2m[WebServer] [22m    ...<7 lines>...
[2m[WebServer] [22m            yield o
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 256, in agent_executor
[2m[WebServer] [22m    return _agent_executor_sync(messages, previous=previous)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 248, in _agent_executor_sync
[2m[WebServer] [22m    return asyncio.run(_agent_executor_async(messages, previous=previous))
[2m[WebServer] [22m           ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/runners.py", line 194, in run
[2m[WebServer] [22m    return runner.run(main)
[2m[WebServer] [22m           ~~~~~~~~~~^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/runners.py", line 118, in run
[2m[WebServer] [22m    return self._loop.run_until_complete(task)
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/base_events.py", line 720, in run_until_complete
[2m[WebServer] [22m    return future.result()
[2m[WebServer] [22m           ~~~~~~~~~~~~~^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 208, in _agent_executor_async
[2m[WebServer] [22m    llm_response = await _call_model_async(current_messages)
[2m[WebServer] [22m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 134, in _call_model_async
[2m[WebServer] [22m    return await asyncio.to_thread(_call_model_sync, messages)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/threads.py", line 25, in to_thread
[2m[WebServer] [22m    return await loop.run_in_executor(None, func_call)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/thread.py", line 59, in run
[2m[WebServer] [22m    result = self.fn(*self.args, **self.kwargs)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 127, in _call_model_sync
[2m[WebServer] [22m    return llm_with_tools.invoke(messages)
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/runnables/base.py", line 5416, in invoke
[2m[WebServer] [22m    return self.bound.invoke(
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        input,
[2m[WebServer] [22m        ^^^^^^
[2m[WebServer] [22m        self._merge_configs(config),
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m        **{**self.kwargs, **kwargs},
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 369, in invoke
[2m[WebServer] [22m    self.generate_prompt(
[2m[WebServer] [22m    ~~~~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        [self._convert_input(input)],
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<6 lines>...
[2m[WebServer] [22m        **kwargs,
[2m[WebServer] [22m        ^^^^^^^^^
[2m[WebServer] [22m    ).generations[0][0],
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 946, in generate_prompt
[2m[WebServer] [22m    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
[2m[WebServer] [22m           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 765, in generate
[2m[WebServer] [22m    self._generate_with_cache(
[2m[WebServer] [22m    ~~~~~~~~~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        m,
[2m[WebServer] [22m        ^^
[2m[WebServer] [22m    ...<2 lines>...
[2m[WebServer] [22m        **kwargs,
[2m[WebServer] [22m        ^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 1011, in _generate_with_cache
[2m[WebServer] [22m    result = self._generate(
[2m[WebServer] [22m        messages, stop=stop, run_manager=run_manager, **kwargs
[2m[WebServer] [22m    )
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py", line 956, in _generate
[2m[WebServer] [22m    return generate_from_stream(stream_iter)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 153, in generate_from_stream
[2m[WebServer] [22m    generation = next(stream, None)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py", line 907, in _stream
[2m[WebServer] [22m    response = self.client.create(**payload)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_utils/_utils.py", line 287, in wrapper
[2m[WebServer] [22m    return func(*args, **kwargs)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py", line 925, in create
[2m[WebServer] [22m    return self._post(
[2m[WebServer] [22m           ~~~~~~~~~~^
[2m[WebServer] [22m        "/chat/completions",
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<43 lines>...
[2m[WebServer] [22m        stream_cls=Stream[ChatCompletionChunk],
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_base_client.py", line 1239, in post
[2m[WebServer] [22m    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
[2m[WebServer] [22m                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_base_client.py", line 1034, in request
[2m[WebServer] [22m    raise self._make_status_error_from_response(err.response) from None
[2m[WebServer] [22mopenai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `gpt-mock` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
[2m[WebServer] [22mDuring task with name 'agent_executor' and id '4d2c0759-78ed-fa70-cbb8-1022469f115a'
[2m[WebServer] [22mERROR - [AgentNode] Exception in agent node agent-1 (agent_id=1): Error code: 404 - {'error': {'message': 'The model `gpt-mock` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
[2m[WebServer] [22mTraceback (most recent call last):
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/services/langgraph_workflow_engine.py", line 729, in agent_node
[2m[WebServer] [22m    created_messages = await runner.run_thread(db, thread)
[2m[WebServer] [22m                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/managers/agent_runner.py", line 137, in run_thread
[2m[WebServer] [22m    updated_messages = await self._runnable.ainvoke(original_msgs, config)
[2m[WebServer] [22m                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2850, in ainvoke
[2m[WebServer] [22m    async for chunk in self.astream(
[2m[WebServer] [22m    ...<13 lines>...
[2m[WebServer] [22m            chunks.append(chunk)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2732, in astream
[2m[WebServer] [22m    async for _ in runner.atick(
[2m[WebServer] [22m    ...<7 lines>...
[2m[WebServer] [22m            yield o
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 256, in agent_executor
[2m[WebServer] [22m    return _agent_executor_sync(messages, previous=previous)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 248, in _agent_executor_sync
[2m[WebServer] [22m    return asyncio.run(_agent_executor_async(messages, previous=previous))
[2m[WebServer] [22m           ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/runners.py", line 194, in run
[2m[WebServer] [22m    return runner.run(main)
[2m[WebServer] [22m           ~~~~~~~~~~^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/runners.py", line 118, in run
[2m[WebServer] [22m    return self._loop.run_until_complete(task)
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/base_events.py", line 720, in run_until_complete
[2m[WebServer] [22m    return future.result()
[2m[WebServer] [22m           ~~~~~~~~~~~~~^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 208, in _agent_executor_async
[2m[WebServer] [22m    llm_response = await _call_model_async(current_messages)
[2m[WebServer] [22m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 134, in _call_model_async
[2m[WebServer] [22m    return await asyncio.to_thread(_call_model_sync, messages)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/threads.py", line 25, in to_thread
[2m[WebServer] [22m    return await loop.run_in_executor(None, func_call)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/thread.py", line 59, in run
[2m[WebServer] [22m    result = self.fn(*self.args, **self.kwargs)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 127, in _call_model_sync
[2m[WebServer] [22m    return llm_with_tools.invoke(messages)
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/runnables/base.py", line 5416, in invoke
[2m[WebServer] [22m    return self.bound.invoke(
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        input,
[2m[WebServer] [22m        ^^^^^^
[2m[WebServer] [22m        self._merge_configs(config),
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m        **{**self.kwargs, **kwargs},
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 369, in invoke
[2m[WebServer] [22m    self.generate_prompt(
[2m[WebServer] [22m    ~~~~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        [self._convert_input(input)],
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<6 lines>...
[2m[WebServer] [22m        **kwargs,
[2m[WebServer] [22m        ^^^^^^^^^
[2m[WebServer] [22m    ).generations[0][0],
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 946, in generate_prompt
[2m[WebServer] [22m    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
[2m[WebServer] [22m           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 765, in generate
[2m[WebServer] [22m    self._generate_with_cache(
[2m[WebServer] [22m    ~~~~~~~~~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        m,
[2m[WebServer] [22m        ^^
[2m[WebServer] [22m    ...<2 lines>...
[2m[WebServer] [22m        **kwargs,
[2m[WebServer] [22m        ^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 1011, in _generate_with_cache
[2m[WebServer] [22m    result = self._generate(
[2m[WebServer] [22m        messages, stop=stop, run_manager=run_manager, **kwargs
[2m[WebServer] [22m    )
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py", line 956, in _generate
[2m[WebServer] [22m    return generate_from_stream(stream_iter)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 153, in generate_from_stream
[2m[WebServer] [22m    generation = next(stream, None)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py", line 907, in _stream
[2m[WebServer] [22m    response = self.client.create(**payload)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_utils/_utils.py", line 287, in wrapper
[2m[WebServer] [22m    return func(*args, **kwargs)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py", line 925, in create
[2m[WebServer] [22m    return self._post(
[2m[WebServer] [22m           ~~~~~~~~~~^
[2m[WebServer] [22m        "/chat/completions",
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<43 lines>...
[2m[WebServer] [22m        stream_cls=Stream[ChatCompletionChunk],
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_base_client.py", line 1239, in post
[2m[WebServer] [22m    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
[2m[WebServer] [22m                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_base_client.py", line 1034, in request
[2m[WebServer] [22m    raise self._make_status_error_from_response(err.response) from None
[2m[WebServer] [22mopenai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `gpt-mock` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
[2m[WebServer] [22mDuring task with name 'agent_executor' and id '4d2c0759-78ed-fa70-cbb8-1022469f115a'
[2m[WebServer] [22mERROR - [AgentNode] Updated node_state to 'failed' in DB
[2m[WebServer] [22mERROR - [AgentNode] Re-raising exception to fail workflow execution
[2m[WebServer] [22mERROR - [LangGraphEngine] Execution failed – execution_id=1
[2m[WebServer] [22mTraceback (most recent call last):
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/services/langgraph_workflow_engine.py", line 146, in execute_workflow
[2m[WebServer] [22m    await self._execute_workflow_internal(workflow, execution, db)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/services/langgraph_workflow_engine.py", line 214, in _execute_workflow_internal
[2m[WebServer] [22m    async for chunk in graph.astream(initial_state, config):
[2m[WebServer] [22m    ...<36 lines>...
[2m[WebServer] [22m            logger.warning(f"[LangGraphEngine] Received empty chunk #{chunk_count}")
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2732, in astream
[2m[WebServer] [22m    async for _ in runner.atick(
[2m[WebServer] [22m    ...<7 lines>...
[2m[WebServer] [22m            yield o
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/services/langgraph_workflow_engine.py", line 729, in agent_node
[2m[WebServer] [22m    created_messages = await runner.run_thread(db, thread)
[2m[WebServer] [22m                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/managers/agent_runner.py", line 137, in run_thread
[2m[WebServer] [22m    updated_messages = await self._runnable.ainvoke(original_msgs, config)
[2m[WebServer] [22m                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2850, in ainvoke
[2m[WebServer] [22m    async for chunk in self.astream(
[2m[WebServer] [22m    ...<13 lines>...
[2m[WebServer] [22m            chunks.append(chunk)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2732, in astream
[2m[WebServer] [22m    async for _ in runner.atick(
[2m[WebServer] [22m    ...<7 lines>...
[2m[WebServer] [22m            yield o
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 256, in agent_executor
[2m[WebServer] [22m    return _agent_executor_sync(messages, previous=previous)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 248, in _agent_executor_sync
[2m[WebServer] [22m    return asyncio.run(_agent_executor_async(messages, previous=previous))
[2m[WebServer] [22m           ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/runners.py", line 194, in run
[2m[WebServer] [22m    return runner.run(main)
[2m[WebServer] [22m           ~~~~~~~~~~^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/runners.py", line 118, in run
[2m[WebServer] [22m    return self._loop.run_until_complete(task)
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/base_events.py", line 720, in run_until_complete
[2m[WebServer] [22m    return future.result()
[2m[WebServer] [22m           ~~~~~~~~~~~~~^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 208, in _agent_executor_async
[2m[WebServer] [22m    llm_response = await _call_model_async(current_messages)
[2m[WebServer] [22m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 134, in _call_model_async
[2m[WebServer] [22m    return await asyncio.to_thread(_call_model_sync, messages)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/threads.py", line 25, in to_thread
[2m[WebServer] [22m    return await loop.run_in_executor(None, func_call)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/thread.py", line 59, in run
[2m[WebServer] [22m    result = self.fn(*self.args, **self.kwargs)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 127, in _call_model_sync
[2m[WebServer] [22m    return llm_with_tools.invoke(messages)
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/runnables/base.py", line 5416, in invoke
[2m[WebServer] [22m    return self.bound.invoke(
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        input,
[2m[WebServer] [22m        ^^^^^^
[2m[WebServer] [22m        self._merge_configs(config),
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m        **{**self.kwargs, **kwargs},
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 369, in invoke
[2m[WebServer] [22m    self.generate_prompt(
[2m[WebServer] [22m    ~~~~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        [self._convert_input(input)],
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<6 lines>...
[2m[WebServer] [22m        **kwargs,
[2m[WebServer] [22m        ^^^^^^^^^
[2m[WebServer] [22m    ).generations[0][0],
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 946, in generate_prompt
[2m[WebServer] [22m    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
[2m[WebServer] [22m           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 765, in generate
[2m[WebServer] [22m    self._generate_with_cache(
[2m[WebServer] [22m    ~~~~~~~~~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        m,
[2m[WebServer] [22m        ^^
[2m[WebServer] [22m    ...<2 lines>...
[2m[WebServer] [22m        **kwargs,
[2m[WebServer] [22m        ^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 1011, in _generate_with_cache
[2m[WebServer] [22m    result = self._generate(
[2m[WebServer] [22m        messages, stop=stop, run_manager=run_manager, **kwargs
[2m[WebServer] [22m    )
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py", line 956, in _generate
[2m[WebServer] [22m    return generate_from_stream(stream_iter)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 153, in generate_from_stream
[2m[WebServer] [22m    generation = next(stream, None)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py", line 907, in _stream
[2m[WebServer] [22m    response = self.client.create(**payload)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_utils/_utils.py", line 287, in wrapper
[2m[WebServer] [22m    return func(*args, **kwargs)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py", line 925, in create
[2m[WebServer] [22m    return self._post(
[2m[WebServer] [22m           ~~~~~~~~~~^
[2m[WebServer] [22m        "/chat/completions",
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<43 lines>...
[2m[WebServer] [22m        stream_cls=Stream[ChatCompletionChunk],
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_base_client.py", line 1239, in post
[2m[WebServer] [22m    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
[2m[WebServer] [22m                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_base_client.py", line 1034, in request
[2m[WebServer] [22m    raise self._make_status_error_from_response(err.response) from None
[2m[WebServer] [22mopenai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `gpt-mock` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
[2m[WebServer] [22mDuring task with name 'agent_executor' and id '4d2c0759-78ed-fa70-cbb8-1022469f115a'
[2m[WebServer] [22mDuring task with name 'agent-1' and id '7045affe-bcd2-ddc5-4470-83487c2e0802'
[2m[WebServer] [22mERROR - Unhandled exception: Error code: 404 - {'error': {'message': 'The model `gpt-mock` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
[2m[WebServer] [22mTraceback (most recent call last):
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/middleware/errors.py", line 165, in __call__
[2m[WebServer] [22m    await self.app(scope, receive, _send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/middleware/worker_db.py", line 101, in __call__
[2m[WebServer] [22m    await self.app(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/middleware/cors.py", line 85, in __call__
[2m[WebServer] [22m    await self.app(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/middleware/exceptions.py", line 62, in __call__
[2m[WebServer] [22m    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
[2m[WebServer] [22m    raise exc
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
[2m[WebServer] [22m    await app(scope, receive, sender)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/routing.py", line 714, in __call__
[2m[WebServer] [22m    await self.middleware_stack(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/routing.py", line 734, in app
[2m[WebServer] [22m    await route.handle(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/routing.py", line 288, in handle
[2m[WebServer] [22m    await self.app(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/routing.py", line 76, in app
[2m[WebServer] [22m    await wrap_app_handling_exceptions(app, request)(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
[2m[WebServer] [22m    raise exc
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
[2m[WebServer] [22m    await app(scope, receive, sender)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/routing.py", line 73, in app
[2m[WebServer] [22m    response = await f(request)
[2m[WebServer] [22m               ^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/fastapi/routing.py", line 301, in app
[2m[WebServer] [22m    raw_response = await run_endpoint_function(
[2m[WebServer] [22m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<3 lines>...
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/fastapi/routing.py", line 212, in run_endpoint_function
[2m[WebServer] [22m    return await dependant.call(**values)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/routers/workflow_executions.py", line 74, in start_workflow_execution
[2m[WebServer] [22m    execution_id = await langgraph_workflow_engine.execute_workflow(workflow_id)
[2m[WebServer] [22m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/services/langgraph_workflow_engine.py", line 146, in execute_workflow
[2m[WebServer] [22m    await self._execute_workflow_internal(workflow, execution, db)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/services/langgraph_workflow_engine.py", line 214, in _execute_workflow_internal
[2m[WebServer] [22m    async for chunk in graph.astream(initial_state, config):
[2m[WebServer] [22m    ...<36 lines>...
[2m[WebServer] [22m            logger.warning(f"[LangGraphEngine] Received empty chunk #{chunk_count}")
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2732, in astream
[2m[WebServer] [22m    async for _ in runner.atick(
[2m[WebServer] [22m    ...<7 lines>...
[2m[WebServer] [22m            yield o
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/services/langgraph_workflow_engine.py", line 729, in agent_node
[2m[WebServer] [22m    created_messages = await runner.run_thread(db, thread)
[2m[WebServer] [22m                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/managers/agent_runner.py", line 137, in run_thread
[2m[WebServer] [22m    updated_messages = await self._runnable.ainvoke(original_msgs, config)
[2m[WebServer] [22m                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2850, in ainvoke
[2m[WebServer] [22m    async for chunk in self.astream(
[2m[WebServer] [22m    ...<13 lines>...
[2m[WebServer] [22m            chunks.append(chunk)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2732, in astream
[2m[WebServer] [22m    async for _ in runner.atick(
[2m[WebServer] [22m    ...<7 lines>...
[2m[WebServer] [22m            yield o
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 256, in agent_executor
[2m[WebServer] [22m    return _agent_executor_sync(messages, previous=previous)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 248, in _agent_executor_sync
[2m[WebServer] [22m    return asyncio.run(_agent_executor_async(messages, previous=previous))
[2m[WebServer] [22m           ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/runners.py", line 194, in run
[2m[WebServer] [22m    return runner.run(main)
[2m[WebServer] [22m           ~~~~~~~~~~^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/runners.py", line 118, in run
[2m[WebServer] [22m    return self._loop.run_until_complete(task)
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/base_events.py", line 720, in run_until_complete
[2m[WebServer] [22m    return future.result()
[2m[WebServer] [22m           ~~~~~~~~~~~~~^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 208, in _agent_executor_async
[2m[WebServer] [22m    llm_response = await _call_model_async(current_messages)
[2m[WebServer] [22m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 134, in _call_model_async
[2m[WebServer] [22m    return await asyncio.to_thread(_call_model_sync, messages)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/threads.py", line 25, in to_thread
[2m[WebServer] [22m    return await loop.run_in_executor(None, func_call)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/thread.py", line 59, in run
[2m[WebServer] [22m    result = self.fn(*self.args, **self.kwargs)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 127, in _call_model_sync
[2m[WebServer] [22m    return llm_with_tools.invoke(messages)
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/runnables/base.py", line 5416, in invoke
[2m[WebServer] [22m    return self.bound.invoke(
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        input,
[2m[WebServer] [22m        ^^^^^^
[2m[WebServer] [22m        self._merge_configs(config),
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m        **{**self.kwargs, **kwargs},
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 369, in invoke
[2m[WebServer] [22m    self.generate_prompt(
[2m[WebServer] [22m    ~~~~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        [self._convert_input(input)],
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<6 lines>...
[2m[WebServer] [22m        **kwargs,
[2m[WebServer] [22m        ^^^^^^^^^
[2m[WebServer] [22m    ).generations[0][0],
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 946, in generate_prompt
[2m[WebServer] [22m    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
[2m[WebServer] [22m           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 765, [2m[WebServer] [22min generate
[2m[WebServer] [22m    self._generate_with_cache(
[2m[WebServer] [22m    ~~~~~~~~~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        m,
[2m[WebServer] [22m        ^^
[2m[WebServer] [22m    ...<2 lines>...
[2m[WebServer] [22m        **kwargs,
[2m[WebServer] [22m        ^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 1011, in _generate_with_cache
[2m[WebServer] [22m    result = self._generate(
[2m[WebServer] [22m        messages, stop=stop, run_manager=run_manager, **kwargs
[2m[WebServer] [22m    )
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py", line 956, in _generate
[2m[WebServer] [22m    return generate_from_stream(stream_iter)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 153, in generate_from_stream
[2m[WebServer] [22m    generation = next(stream, None)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py", line 907, in _stream
[2m[WebServer] [22m    response = self.client.create(**payload)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_utils/_utils.py", line 287, in wrapper
[2m[WebServer] [22m    return func(*args, **kwargs)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py", line 925, in create
[2m[WebServer] [22m    return self._post(
[2m[WebServer] [22m           ~~~~~~~~~~^
[2m[WebServer] [22m        "/chat/completions",
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<43 lines>...
[2m[WebServer] [22m        stream_cls=Stream[ChatCompletionChunk],
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_base_client.py", line 1239, in post
[2m[WebServer] [22m    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
[2m[WebServer] [22m                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_base_client.py", line 1034, in request
[2m[WebServer] [22m    raise self._make_status_error_from_response(err.response) from None
[2m[WebServer] [22mopenai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `gpt-mock` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
[2m[WebServer] [22mDuring task with name 'agent_executor' and id '4d2c0759-78ed-fa70-cbb8-1022469f115a'
[2m[WebServer] [22mDuring task with name 'agent-1' and id '7045affe-bcd2-ddc5-4470-83487c2e0802'
❌ User 0 execution failed: [33m500[39m
[2m[WebServer] [22mERROR:    Exception in ASGI application
[2m[WebServer] [22mTraceback (most recent call last):
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/uvicorn/protocols/http/h11_impl.py", line 408, in run_asgi
[2m[WebServer] [22m    result = await app(  # type: ignore[func-returns-value]
[2m[WebServer] [22m             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m        self.scope, self.receive, self.send
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/uvicorn/middleware/proxy_headers.py", line 84, in __call__
[2m[WebServer] [22m    return await self.app(scope, receive, send)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/fastapi/applications.py", line 1054, in __call__
[2m[WebServer] [22m    await super().__call__(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/applications.py", line 112, in __call__
[2m[WebServer] [22m    await self.middleware_stack(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/middleware/errors.py", line 187, in __call__
[2m[WebServer] [22m    raise exc
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/middleware/errors.py", line 165, in __call__
[2m[WebServer] [22m    await self.app(scope, receive, _send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/middleware/worker_db.py", line 101, in __call__
[2m[WebServer] [22m    await self.app(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/middleware/cors.py", line 85, in __call__
[2m[WebServer] [22m    await self.app(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/middleware/exceptions.py", line 62, in __call__
[2m[WebServer] [22m    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
[2m[WebServer] [22m    raise exc
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
[2m[WebServer] [22m    await app(scope, receive, sender)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/routing.py", line 714, in __call__
[2m[WebServer] [22m    await self.middleware_stack(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/routing.py", line 734, in app
[2m[WebServer] [22m    await route.handle(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/routing.py", line 288, in handle
[2m[WebServer] [22m    await self.app(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/routing.py", line 76, in app
[2m[WebServer] [22m    await wrap_app_handling_exceptions(app, request)(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
[2m[WebServer] [22m    raise exc
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
[2m[WebServer] [22m    await app(scope, receive, sender)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/routing.py", line 73, in app
[2m[WebServer] [22m    response = await f(request)
[2m[WebServer] [22m               ^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/fastapi/routing.py", line 301, in app
[2m[WebServer] [22m    raw_response = await run_endpoint_function(
[2m[WebServer] [22m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<3 lines>...
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/fastapi/routing.py", line 212, in run_endpoint_function
[2m[WebServer] [22m    return await dependant.call(**values)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/routers/workflow_executions.py", line 74, in start_workflow_execution
[2m[WebServer] [22m    execution_id = await langgraph_workflow_engine.execute_workflow(workflow_id)
[2m[WebServer] [22m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/services/langgraph_workflow_engine.py", line 146, in execute_workflow
[2m[WebServer] [22m    await self._execute_workflow_internal(workflow, execution, db)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/services/langgraph_workflow_engine.py", line 214, in _execute_workflow_internal
[2m[WebServer] [22m    async for chunk in graph.astream(initial_state, config):
[2m[WebServer] [22m    ...<36 lines>...
[2m[WebServer] [22m            logger.warning(f"[LangGraphEngine] Received empty chunk #{chunk_count}")
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2732, in astream
[2m[WebServer] [22m    async for _ in runner.atick(
[2m[WebServer] [22m    ...<7 lines>...
[2m[WebServer] [22m            yield o
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/services/langgraph_workflow_engine.py", line 729, in agent_node
[2m[WebServer] [22m    created_messages = await runner.run_thread(db, thread)
[2m[WebServer] [22m                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/managers/agent_runner.py", line 137, in run_thread
[2m[WebServer] [22m    updated_messages = await self._runnable.ainvoke(original_msgs, config)
[2m[WebServer] [22m                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2850, in ainvoke
[2m[WebServer] [22m    async for chunk in self.astream(
[2m[WebServer] [22m    ...<13 lines>...
[2m[WebServer] [22m            chunks.append(chunk)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2732, in astream
[2m[WebServer] [22m    async for _ in runner.atick(
[2m[WebServer] [22m    ...<7 lines>...
[2m[WebServer] [22m            yield o
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 256, in agent_executor
[2m[WebServer] [22m    return _agent_executor_sync(messages, previous=previous)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 248, in _agent_executor_sync
[2m[WebServer] [22m    return asyncio.run(_agent_executor_async(messages, previous=previous))
[2m[WebServer] [22m           ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/runners.py", line 194, in run
[2m[WebServer] [22m    return runner.run(main)
[2m[WebServer] [22m           ~~~~~~~~~~^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/runners.py", line 118, in run
[2m[WebServer] [22m    return self._loop.run_until_complete(task)
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/base_events.py", line 720, in run_until_complete
[2m[WebServer] [22m    return future.result()
[2m[WebServer] [22m           ~~~~~~~~~~~~~^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 208, in _agent_executor_async
[2m[WebServer] [22m    llm_response = await _call_model_async(current_messages)
[2m[WebServer] [22m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 134, in _call_model_async
[2m[WebServer] [22m    return await asyncio.to_thread(_call_model_sync, messages)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/threads.py", line 25, in to_thread
[2m[WebServer] [22m    return await loop.run_in_executor(None, func_call)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/thread.py", line 59, in run
[2m[WebServer] [22m    result = self.fn(*self.args, **self.kwargs)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 127, in _call_model_sync
[2m[WebServer] [22m    return llm_with_tools.invoke(messages)
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/runnables/base.py", line 5416, in invoke
[2m[WebServer] [22m    return self.bound.invoke(
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        input,
[2m[WebServer] [22m        ^^^^^^
[2m[WebServer] [22m        self._merge_configs(config),
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^[2m[WebServer] [22m^^^^^^^^^
[2m[WebServer] [22m        **{**self.kwargs, **kwargs},
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 369, in invoke
[2m[WebServer] [22m    self.generate_prompt(
[2m[WebServer] [22m    ~~~~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        [self._convert_input(input)],
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<6 lines>...
[2m[WebServer] [22m        **kwargs,
[2m[WebServer] [22m        ^^^^^^^^^
[2m[WebServer] [22m    ).generations[0][0],
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 946, in generate_prompt
[2m[WebServer] [22m    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
[2m[WebServer] [22m           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 765, in generate
[2m[WebServer] [22m    self._generate_with_cache(
[2m[WebServer] [22m    ~~~~~~~~~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        m,
[2m[WebServer] [22m        ^^
[2m[WebServer] [22m    ...<2 lines>...
[2m[WebServer] [22m        **kwargs,
[2m[WebServer] [22m        ^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 1011, in _generate_with_cache
[2m[WebServer] [22m    result = self._generate(
[2m[WebServer] [22m        messages, stop=stop, run_manager=run_manager, **kwargs
[2m[WebServer] [22m    )
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py", line 956, in _generate
[2m[WebServer] [22m    return generate_from_stream(stream_iter)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 153, in generate_from_stream
[2m[WebServer] [22m    generation = next(stream, None)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py", line 907, in _stream
[2m[WebServer] [22m    response = self.client.create(**payload)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_utils/_utils.py", line 287, in wrapper
[2m[WebServer] [22m    return func(*args, **kwargs)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py", line 925, in create
[2m[WebServer] [22m    return self._post(
[2m[WebServer] [22m           ~~~~~~~~~~^
[2m[WebServer] [22m        "/chat/completions",
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<43 lines>...
[2m[WebServer] [22m        stream_cls=Stream[ChatCompletionChunk],
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_base_client.py", line 1239, in post
[2m[WebServer] [22m    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
[2m[WebServer] [22m                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_base_client.py", line 1034, in request
[2m[WebServer] [22m    raise self._make_status_error_from_response(err.response) from None
[2m[WebServer] [22mopenai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `gpt-mock` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
[2m[WebServer] [22mDuring task with name 'agent_executor' and id '4d2c0759-78ed-fa70-cbb8-1022469f115a'
[2m[WebServer] [22mDuring task with name 'agent-1' and id '7045affe-bcd2-ddc5-4470-83487c2e0802'
[2m[WebServer] [22mERROR - [AgentRunner] Exception during runnable.ainvoke: Error code: 404 - {'error': {'message': 'The model `gpt-mock` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
[2m[WebServer] [22mTraceback (most recent call last):
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/managers/agent_runner.py", line 137, in run_thread
[2m[WebServer] [22m    updated_messages = await self._runnable.ainvoke(original_msgs, config)
[2m[WebServer] [22m                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2850, in ainvoke
[2m[WebServer] [22m    async for chunk in self.astream(
[2m[WebServer] [22m    ...<13 lines>...
[2m[WebServer] [22m            chunks.append(chunk)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2732, in astream
[2m[WebServer] [22m    async for _ in runner.atick(
[2m[WebServer] [22m    ...<7 lines>...
[2m[WebServer] [22m            yield o
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 256, in agent_executor
[2m[WebServer] [22m    return _agent_executor_sync(messages, previous=previous)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 248, in _agent_executor_sync
[2m[WebServer] [22m    return asyncio.run(_agent_executor_async(messages, previous=previous))
[2m[WebServer] [22m           ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/runners.py", line 194, in run
[2m[WebServer] [22m    return runner.run(main)
[2m[WebServer] [22m           ~~~~~~~~~~^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/runners.py", line 118, in run
[2m[WebServer] [22m    return self._loop.run_until_complete(task)
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/base_events.py", line 720, in run_until_complete
[2m[WebServer] [22m    return future.result()
[2m[WebServer] [22m           ~~~~~~~~~~~~~^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 208, in _agent_executor_async
[2m[WebServer] [22m    llm_response = await _call_model_async(current_messages)
[2m[WebServer] [22m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 134, in _call_model_async
[2m[WebServer] [22m    return await asyncio.to_thread(_call_model_sync, messages)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/threads.py", line 25, in to_thread
[2m[WebServer] [22m    return await loop.run_in_executor(None, func_call)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/thread.py", line 59, in run
[2m[WebServer] [22m    result = self.fn(*self.args, **self.kwargs)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 127, in _call_model_sync
[2m[WebServer] [22m    return llm_with_tools.invoke(messages)
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/runnables/base.py", line 5416, in invoke
[2m[WebServer] [22m    return self.bound.invoke(
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        input,
[2m[WebServer] [22m        ^^^^^^
[2m[WebServer] [22m        self._merge_configs(config),
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m        **{**self.kwargs, **kwargs},
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 369, in invoke
[2m[WebServer] [22m    self.generate_prompt(
[2m[WebServer] [22m    ~~~~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        [self._convert_input(input)],
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<6 lines>...
[2m[WebServer] [22m        **kwargs,
[2m[WebServer] [22m        ^^^^^^^^^
[2m[WebServer] [22m    ).generations[0][0],
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 946, in generate_prompt
[2m[WebServer] [22m    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
[2m[WebServer] [22m           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 765, in generate
[2m[WebServer] [22m    self._generate_with_cache(
[2m[WebServer] [22m    ~~~~~~~~~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        m,
[2m[WebServer] [22m        ^^
[2m[WebServer] [22m    ...<2 lines>...
[2m[WebServer] [22m        **kwargs,
[2m[WebServer] [22m        ^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 1011, in _generate_with_cache
[2m[WebServer] [22m    result = self._generate(
[2m[WebServer] [22m        messages, stop=stop, run_manager=run_manager, **kwargs
[2m[WebServer] [22m    )
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py", line 956, in _generate
[2m[WebServer] [22m    return generate_from_stream(stream_iter)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 153, in generate_from_stream
[2m[WebServer] [22m    generation = next(stream, None)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py", line 907, in _stream
[2m[WebServer] [22m    response = self.client.create(**payload)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_utils/_utils.py", line 287, in wrapper
[2m[WebServer] [22m    return func(*args, **kwargs)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py", line 925, in create
[2m[WebServer] [22m    return self._post(
[2m[WebServer] [22m           ~~~~~~~~~~^
[2m[WebServer] [22m        "/chat/completions",
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<43 lines>...
[2m[WebServer] [22m        stream_cls=Stream[ChatCompletionChunk],
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_base_client.py", line 1239, in post
[2m[WebServer] [22m    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
[2m[WebServer] [22m                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_base_client.py", line 1034, in request
[2m[WebServer] [22m    raise self._make_status_error_from_response(err.response) from None
[2m[WebServer] [22mopenai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `gpt-mock` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
[2m[WebServer] [22mDuring task with name 'agent_executor' and id 'f30bb81b-ce0e-f73d-81eb-63e9c78e6873'
[2m[WebServer] [22mERROR - [AgentNode] Exception in agent node agent-1 (agent_id=1): Error code: 404 - {'error': {'message': 'The model `gpt-mock` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
[2m[WebServer] [22mTraceback (most recent call last):
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/services/langgraph_workflow_engine.py", line 729, in agent_node
[2m[WebServer] [22m    created_messages = await runner.run_thread(db, thread)
[2m[WebServer] [22m                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/managers/agent_runner.py", line 137, in run_thread
[2m[WebServer] [22m    updated_messages = await self._runnable.ainvoke(original_msgs, config)
[2m[WebServer] [22m                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2850, in ainvoke
[2m[WebServer] [22m    async for chunk in self.astream(
[2m[WebServer] [22m    ...<13 lines>...
[2m[WebServer] [22m            chunks.append(chunk)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2732, in astream
[2m[WebServer] [22m    async for _ in runner.atick(
[2m[WebServer] [22m    ...<7 lines>...
[2m[WebServer] [22m            yield o
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 256, in agent_executor
[2m[WebServer] [22m    return _agent_executor_sync(messages, previous=previous)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 248, in _agent_executor_sync
[2m[WebServer] [22m    return asyncio.run(_agent_executor_async(messages, previous=previous))
[2m[WebServer] [22m           ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/runners.py", line 194, in run
[2m[WebServer] [22m    return runner.run(main)
[2m[WebServer] [22m           ~~~~~~~~~~^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/runners.py", line 118, in run
[2m[WebServer] [22m    return self._loop.run_until_complete(task)
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/base_events.py", line 720, in run_until_complete
[2m[WebServer] [22m    return future.result()
[2m[WebServer] [22m           ~~~~~~~~~~~~~^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 208, in _agent_executor_async
[2m[WebServer] [22m    llm_response = await _call_model_async(current_messages)
[2m[WebServer] [22m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 134, in _call_model_async
[2m[WebServer] [22m    return await asyncio.to_thread(_call_model_sync, messages)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/threads.py", line 25, in to_thread
[2m[WebServer] [22m    return await loop.run_in_executor(None, func_call)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/thread.py", line 59, in run
[2m[WebServer] [22m    result = self.fn(*self.args, **self.kwargs)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 127, in _call_model_sync
[2m[WebServer] [22m    return llm_with_tools.invoke(messages)
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/runnables/base.py", line 5416, in invoke
[2m[WebServer] [22m    return self.bound.invoke(
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        input,
[2m[WebServer] [22m        ^^^^^^
[2m[WebServer] [22m        self._merge_configs(config),
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m        **{**self.kwargs, **kwargs},
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 369, in invoke
[2m[WebServer] [22m    self.generate_prompt(
[2m[WebServer] [22m    ~~~~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        [self._convert_input(input)],
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<6 lines>...
[2m[WebServer] [22m        **kwargs,
[2m[WebServer] [22m        ^^^^^^^^^
[2m[WebServer] [22m    ).generations[0][0],
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 946, in generate_prompt
[2m[WebServer] [22m    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
[2m[WebServer] [22m           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 765, in generate
[2m[WebServer] [22m    self._generate_with_cache(
[2m[WebServer] [22m    ~~~~~~~~~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        m,
[2m[WebServer] [22m        ^^
[2m[WebServer] [22m    ...<2 lines>...
[2m[WebServer] [22m        **kwargs,
[2m[WebServer] [22m        ^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 1011, in _generate_with_cache
[2m[WebServer] [22m    result = self._generate(
[2m[WebServer] [22m        messages, stop=stop, run_manager=run_manager, **kwargs
[2m[WebServer] [22m    )
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py", line 956, in _generate
[2m[WebServer] [22m    return generate_from_stream(stream_iter)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 153, in generate_from_stream
[2m[WebServer] [22m    generation = next(stream, None)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py", line 907, in _stream
[2m[WebServer] [22m    response = self.client.create(**payload)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_utils/_utils.py", line 287, in wrapper
[2m[WebServer] [22m    return func(*args, **kwargs)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py", line 925, in create
[2m[WebServer] [22m    return self._post(
[2m[WebServer] [22m           ~~~~~~~~~~^
[2m[WebServer] [22m        "/chat/completions",
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<43 lines>...
[2m[WebServer] [22m        stream_cls=Stream[ChatCompletionChunk],
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_base_client.py", line 1239, in post
[2m[WebServer] [22m    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
[2m[WebServer] [22m                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_base_client.py", line 1034, in request
[2m[WebServer] [22m    raise self._make_status_error_from_response(err.response) from None
[2m[WebServer] [22mopenai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `gpt-mock` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
[2m[WebServer] [22mDuring task with name 'agent_executor' and id 'f30bb81b-ce0e-f73d-81eb-63e9c78e6873'
[2m[WebServer] [22mERROR - [AgentNode] Updated node_state to 'failed' in DB
[2m[WebServer] [22mERROR - [AgentNode] Re-raising exception to fail workflow execution
[2m[WebServer] [22mERROR - [LangGraphEngine] Execution failed – execution_id=1
[2m[WebServer] [22mTraceback (most recent call last):
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/services/langgraph_workflow_engine.py", line 146, in execute_workflow
[2m[WebServer] [22m    await self._execute_workflow_internal(workflow, execution, db)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/services/langgraph_workflow_engine.py", line 214, in _execute_workflow_internal
[2m[WebServer] [22m    async for chunk in graph.astream(initial_state, config):
[2m[WebServer] [22m    ...<36 lines>...
[2m[WebServer] [22m            logger.warning(f"[LangGraphEngine] Received empty chunk #{chunk_count}")
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2732, in astream
[2m[WebServer] [22m    async for _ in runner.atick(
[2m[WebServer] [22m    ...<7 lines>...
[2m[WebServer] [22m            yield o
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/services/langgraph_workflow_engine.py", line 729, in agent_node
[2m[WebServer] [22m    created_messages = await runner.run_thread(db, thread)
[2m[WebServer] [22m                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/managers/agent_runner.py", line 137, in run_thread
[2m[WebServer] [22m    updated_messages = await self._runnable.ainvoke(original_msgs, config)
[2m[WebServer] [22m                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2850, in ainvoke
[2m[WebServer] [22m    async for chunk in self.astream(
[2m[WebServer] [22m    ...<13 lines>...
[2m[WebServer] [22m            chunks.append(chunk)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2732, in astream
[2m[WebServer] [22m    async for _ in runner.atick(
[2m[WebServer] [22m    ...<7 lines>...
[2m[WebServer] [22m            yield o
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 256, in agent_executor
[2m[WebServer] [22m    return _agent_executor_sync(messages, previous=previous)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 248, in _agent_executor_sync
[2m[WebServer] [22m    return asyncio.run(_agent_executor_async(messages, previous=previous))
[2m[WebServer] [22m           ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/runners.py", line 194, in run
[2m[WebServer] [22m    return runner.run(main)
[2m[WebServer] [22m           ~~~~~~~~~~^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/runners.py", line 118, in run
[2m[WebServer] [22m    return self._loop.run_until_complete(task)
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/base_events.py", line 720, in run_until_complete
[2m[WebServer] [22m    return future.result()
[2m[WebServer] [22m           ~~~~~~~~~~~~~^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 208, in _agent_executor_async
[2m[WebServer] [22m    llm_response = await _call_model_async(current_messages)
[2m[WebServer] [22m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 134, in _call_model_async
[2m[WebServer] [22m    return await asyncio.to_thread(_call_model_sync, messages)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/threads.py", line 25, in to_thread
[2m[WebServer] [22m    return await loop.run_in_executor(None, func_call)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/thread.py", line 59, in run
[2m[WebServer] [22m    result = self.fn(*self.args, **self.kwargs)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 127, in _call_model_sync
[2m[WebServer] [22m    return llm_with_tools.invoke(messages)
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/runnables/base.py", line 5416, in invoke
[2m[WebServer] [22m    return self.bound.invoke(
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        input,
[2m[WebServer] [22m        ^^^^^^
[2m[WebServer] [22m        self._merge_configs(config),
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m        **{**self.kwargs, **kwargs},
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 369, in invoke
[2m[WebServer] [22m    self.generate_prompt(
[2m[WebServer] [22m    ~~~~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        [self._convert_input(input)],
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<6 lines>...
[2m[WebServer] [22m        **kwargs,
[2m[WebServer] [22m        ^^^^^^^^^
[2m[WebServer] [22m    ).generations[0][0],
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 946, in generate_prompt
[2m[WebServer] [22m    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
[2m[WebServer] [22m           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 765, in generate
[2m[WebServer] [22m    self._generate_with_cache(
[2m[WebServer] [22m    ~~~~~~~~~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        m,
[2m[WebServer] [22m        ^^
[2m[WebServer] [22m    ...<2 lines>...
[2m[WebServer] [22m        **kwargs,
[2m[WebServer] [22m        ^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 1011, in _generate_with_cache
[2m[WebServer] [22m    result = self._generate(
[2m[WebServer] [22m        messages, stop=stop, run_manager=run_manager, **kwargs
[2m[WebServer] [22m    )
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py", line 956, in _generate
[2m[WebServer] [22m    return generate_from_stream(stream_iter)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 153, in generate_from_stream
[2m[WebServer] [22m    generation = next(stream, None)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py", line 907, in _stream
[2m[WebServer] [22m    response = self.client.create(**payload)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_utils/_utils.py", line 287, in wrapper
[2m[WebServer] [22m    return func(*args, **kwargs)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py", line 925, in create
[2m[WebServer] [22m    return self._post(
[2m[WebServer] [22m           ~~~~~~~~~~^
[2m[WebServer] [22m        "/chat/completions",
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<43 lines>...
[2m[WebServer] [22m        stream_cls=Stream[ChatCompletionChunk],
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_base_client.py", line 1239, in post
[2m[WebServer] [22m    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
[2m[WebServer] [22m                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_base_client.py", line 1034, in request
[2m[WebServer] [22m    raise self._make_status_error_from_response(err.response) from None
[2m[WebServer] [22mopenai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `gpt-mock` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
[2m[WebServer] [22mDuring task with name 'agent_executor' and id 'f30bb81b-ce0e-f73d-81eb-63e9c78e6873'
[2m[WebServer] [22mDuring task with name 'agent-1' and id 'ebd3f1dd-2ed5-902d-9950-070d4ca83d98'
[2m[WebServer] [22mERROR - Unhandled exception: Error code: 404 - {'error': {'message': 'The model `gpt-mock` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
[2m[WebServer] [22mTraceback (most recent call last):
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/middleware/errors.py", line 165, in __call__
[2m[WebServer] [22m    await self.app(scope, receive, _send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/middleware/worker_db.py", line 101, in __call__
[2m[WebServer] [22m    await self.app(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/middleware/cors.py", line 85, in __call__
[2m[WebServer] [22m    await self.app(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/middleware/exceptions.py", line 62, in __call__
[2m[WebServer] [22m    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
[2m[WebServer] [22m    raise exc
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
[2m[WebServer] [22m    await app(scope, receive, sender)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/routing.py", line 714, in __call__
[2m[WebServer] [22m    await self.middleware_stack(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/routing.py", line 734, in app
[2m[WebServer] [22m    await route.handle(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/routing.py", line 288, in handle
[2m[WebServer] [22m    await self.app(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/routing.py", line 76, in app
[2m[WebServer] [22m    await wrap_app_handling_exceptions(app, request)(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
[2m[WebServer] [22m    raise exc
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
[2m[WebServer] [22m    await app(scope, receive, sender)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/routing.py", line 73, in app
[2m[WebServer] [22m    response = await f(request)
[2m[WebServer] [22m               ^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/fastapi/routing.py", line 301, in app
[2m[WebServer] [22m    raw_response = await run_endpoint_function(
[2m[WebServer] [22m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<3 lines>...
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/fastapi/routing.py", line 212, in run_endpoint_function
[2m[WebServer] [22m    return await dependant.call(**values)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/routers/workflow_executions.py", line 74, in start_workflow_execution
[2m[WebServer] [22m    execution_id = await langgraph_workflow_engine.execute_workflow(workflow_id)
[2m[WebServer] [22m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/services/langgraph_workflow_engine.py", line 146, in execute_workflow
[2m[WebServer] [22m    await self._execute_workflow_internal(workflow, execution, db)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/services/langgraph_workflow_engine.py", line 214, in _execute_workflow_internal
[2m[WebServer] [22m    async for chunk in graph.astream(initial_state, config):
[2m[WebServer] [22m    ...<36 lines>...
[2m[WebServer] [22m            logger.warning(f"[LangGraphEngine] Received empty chunk #{chunk_count}")
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2732, in astream
[2m[WebServer] [22m    async for _ in runner.atick(
[2m[WebServer] [22m    ...<7 lines>...
[2m[WebServer] [22m            yield o
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/services/langgraph_workflow_engine.py", line 729, in agent_node
[2m[WebServer] [22m    created_messages = await runner.run_thread(db, thread)
[2m[WebServer] [22m                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/managers/agent_runner.py", line 137, in run_thread
[2m[WebServer] [22m    updated_messages = await self._runnable.ainvoke(original_msgs, config)
[2m[WebServer] [22m                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2850, in ainvoke
[2m[WebServer] [22m    async for chunk in self.astream(
[2m[WebServer] [22m    ...<13 lines>...
[2m[WebServer] [22m            chunks.append(chunk)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2732, in astream
[2m[WebServer] [22m    async for _ in runner.atick(
[2m[WebServer] [22m    ...<7 lines>...
[2m[WebServer] [22m            yield o
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 256, in agent_executor
[2m[WebServer] [22m    return _agent_executor_sync(messages, previous=previous)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 248, in _agent_executor_sync
[2m[WebServer] [22m    return asyncio.run(_agent_executor_async(messages, previous=previous))
[2m[WebServer] [22m           ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/runners.py", line 194, in run
[2m[WebServer] [22m    return runner.run(main)
[2m[WebServer] [22m           ~~~~~~~~~~^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/runners.py", line 118, in run
[2m[WebServer] [22m    return self._loop.run_until_complete(task)
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/base_events.py", line 720, in run_until_complete
[2m[WebServer] [22m    return future.result()
[2m[WebServer] [22m           ~~~~~~~~~~~~~^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 208, in _agent_executor_async
[2m[WebServer] [22m    llm_response = await _call_model_async(current_messages)
[2m[WebServer] [22m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 134, in _call_model_async
[2m[WebServer] [22m    return await asyncio.to_thread(_call_model_sync, messages)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/threads.py", line 25, in to_thread
[2m[WebServer] [22m    return await loop.run_in_executor(None, func_call)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/thread.py", line 59, in run
[2m[WebServer] [22m    result = self.fn(*self.args, **self.kwargs)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 127, in _call_model_sync
[2m[WebServer] [22m    return llm_with_tools.invoke(messages)
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/runnables/base.py", line 5416, in invoke
[2m[WebServer] [22m    return self.bound.invoke(
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        input,
[2m[WebServer] [22m        ^^^^^^
[2m[WebServer] [22m        self._merge_configs(config),
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m        **{**self.kwargs, **kwargs},
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 369, in invoke
[2m[WebServer] [22m    self.generate_prompt(
[2m[WebServer] [22m    ~~~~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        [self._convert_input(input)],
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<6 lines>...
[2m[WebServer] [22m        **kwargs,
[2m[WebServer] [22m        ^^^^^^^^^
[2m[WebServer] [22m    ).generations[0][0],
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 946, in generate_prompt
[2m[WebServer] [22m    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
[2m[WebServer] [22m           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 765, [2m[WebServer] [22min generate
[2m[WebServer] [22m    self._generate_with_cache(
[2m[WebServer] [22m    ~~~~~~~~~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        m,
[2m[WebServer] [22m        ^^
[2m[WebServer] [22m    ...<2 lines>...
[2m[WebServer] [22m        **kwargs,
[2m[WebServer] [22m        ^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 1011, in _generate_with_cache
[2m[WebServer] [22m    result = self._generate(
[2m[WebServer] [22m        messages, stop=stop, run_manager=run_manager, **kwargs
[2m[WebServer] [22m    )
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py", line 956, in _generate
[2m[WebServer] [22m    return generate_from_stream(stream_iter)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 153, in generate_from_stream
[2m[WebServer] [22m    generation = next(stream, None)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py", line 907, in _stream
[2m[WebServer] [22m    response = self.client.create(**payload)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_utils/_utils.py", line 287, in wrapper
[2m[WebServer] [22m    return func(*args, **kwargs)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py", line 925, in create
[2m[WebServer] [22m    return self._post(
[2m[WebServer] [22m           ~~~~~~~~~~^
[2m[WebServer] [22m        "/chat/completions",
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<43 lines>...
[2m[WebServer] [22m        stream_cls=Stream[ChatCompletionChunk],
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_base_client.py", line 1239, in post
[2m[WebServer] [22m    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
[2m[WebServer] [22m                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_base_client.py", line 1034, in request
[2m[WebServer] [22m    raise self._make_status_error_from_response(err.response) from None
[2m[WebServer] [22mopenai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `gpt-mock` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
[2m[WebServer] [22mDuring task with name 'agent_executor' and id 'f30bb81b-ce0e-f73d-81eb-63e9c78e6873'
[2m[WebServer] [22mDuring task with name 'agent-1' and id 'ebd3f1dd-2ed5-902d-9950-070d4ca83d98'
❌ User 1 execution failed: [33m500[39m
📊 Successful workflow executions: [33m0[39m / [33m3[39m
📊 Concurrent execution start time: [33m1140[39m ms
📊 Test 3: Monitoring concurrent executions...
[2m[WebServer] [22mERROR:    Exception in ASGI application
[2m[WebServer] [22mTraceback (most recent call last):
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/uvicorn/protocols/http/h11_impl.py", line 408, in run_asgi
[2m[WebServer] [22m    result = await app(  # type: ignore[func-returns-value]
[2m[WebServer] [22m             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m        self.scope, self.receive, self.send
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/uvicorn/middleware/proxy_headers.py", line 84, in __call__
[2m[WebServer] [22m    return await self.app(scope, receive, send)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/fastapi/applications.py", line 1054, in __call__
[2m[WebServer] [22m    await super().__call__(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/applications.py", line 112, in __call__
[2m[WebServer] [22m    await self.middleware_stack(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/middleware/errors.py", line 187, in __call__
[2m[WebServer] [22m    raise exc
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/middleware/errors.py", line 165, in __call__
[2m[WebServer] [22m    await self.app(scope, receive, _send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/middleware/worker_db.py", line 101, in __call__
[2m[WebServer] [22m    await self.app(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/middleware/cors.py", line 85, in __call__
[2m[WebServer] [22m    await self.app(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/middleware/exceptions.py", line 62, in __call__
[2m[WebServer] [22m    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
[2m[WebServer] [22m    raise exc
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
[2m[WebServer] [22m    await app(scope, receive, sender)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/routing.py", line 714, in __call__
[2m[WebServer] [22m    await self.middleware_stack(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/routing.py", line 734, in app
[2m[WebServer] [22m    await route.handle(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/routing.py", line 288, in handle
[2m[WebServer] [22m    await self.app(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/routing.py", line 76, in app
[2m[WebServer] [22m    await wrap_app_handling_exceptions(app, request)(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
[2m[WebServer] [22m    raise exc
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
[2m[WebServer] [22m    await app(scope, receive, sender)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/routing.py", line 73, in app
[2m[WebServer] [22m    response = await f(request)
[2m[WebServer] [22m               ^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/fastapi/routing.py", line 301, in app
[2m[WebServer] [22m    raw_response = await run_endpoint_function(
[2m[WebServer] [22m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<3 lines>...
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/fastapi/routing.py", line 212, in run_endpoint_function
[2m[WebServer] [22m    return await dependant.call(**values)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/routers/workflow_executions.py", line 74, in start_workflow_execution
[2m[WebServer] [22m    execution_id = await langgraph_workflow_engine.execute_workflow(workflow_id)
[2m[WebServer] [22m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/services/langgraph_workflow_engine.py", line 146, in execute_workflow
[2m[WebServer] [22m    await self._execute_workflow_internal(workflow, execution, db)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/services/langgraph_workflow_engine.py", line 214, in _execute_workflow_internal
[2m[WebServer] [22m    async for chunk in graph.astream(initial_state, config):
[2m[WebServer] [22m    ...<36 lines>...
[2m[WebServer] [22m            logger.warning(f"[LangGraphEngine] Received empty chunk #{chunk_count}")
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2732, in astream
[2m[WebServer] [22m    async for _ in runner.atick(
[2m[WebServer] [22m    ...<7 lines>...
[2m[WebServer] [22m            yield o
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/services/langgraph_workflow_engine.py", line 729, in agent_node
[2m[WebServer] [22m    created_messages = await runner.run_thread(db, thread)
[2m[WebServer] [22m                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/managers/agent_runner.py", line 137, in run_thread
[2m[WebServer] [22m    updated_messages = await self._runnable.ainvoke(original_msgs, config)
[2m[WebServer] [22m                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2850, in ainvoke
[2m[WebServer] [22m    async for chunk in self.astream(
[2m[WebServer] [22m    ...<13 lines>...
[2m[WebServer] [22m            chunks.append(chunk)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2732, in astream
[2m[WebServer] [22m    async for _ in runner.atick(
[2m[WebServer] [22m    ...<7 lines>...
[2m[WebServer] [22m            yield o
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 256, in agent_executor
[2m[WebServer] [22m    return _agent_executor_sync(messages, previous=previous)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 248, in _agent_executor_sync
[2m[WebServer] [22m    return asyncio.run(_agent_executor_async(messages, previous=previous))
[2m[WebServer] [22m           ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/runners.py", line 194, in run
[2m[WebServer] [22m    return runner.run(main)
[2m[WebServer] [22m           ~~~~~~~~~~^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/runners.py", line 118, in run
[2m[WebServer] [22m    return self._loop.run_until_complete(task)
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/base_events.py", line 720, in run_until_complete
[2m[WebServer] [22m    return future.result()
[2m[WebServer] [22m           ~~~~~~~~~~~~~^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 208, in _agent_executor_async
[2m[WebServer] [22m    llm_response = await _call_model_async(current_messages)
[2m[WebServer] [22m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 134, in _call_model_async
[2m[WebServer] [22m    return await asyncio.to_thread(_call_model_sync, messages)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/threads.py", line 25, in to_thread
[2m[WebServer] [22m    return await loop.run_in_executor(None, func_call)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/thread.py", line 59, in run
[2m[WebServer] [22m    result = self.fn(*self.args, **self.kwargs)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 127, in _call_model_sync
[2m[WebServer] [22m    return llm_with_tools.invoke(messages)
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/runnables/base.py", line 5416, in invoke
[2m[WebServer] [22m    return self.bound.invoke(
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        input,
[2m[WebServer] [22m        ^^^^^^
[2m[WebServer] [22m        self._merge_configs(config),
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^[2m[WebServer] [22m^^^^^^^^^
[2m[WebServer] [22m        **{**self.kwargs, **kwargs},
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 369, in invoke
[2m[WebServer] [22m    self.generate_prompt(
[2m[WebServer] [22m    ~~~~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        [self._convert_input(input)],
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<6 lines>...
[2m[WebServer] [22m        **kwargs,
[2m[WebServer] [22m        ^^^^^^^^^
[2m[WebServer] [22m    ).generations[0][0],
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 946, in generate_prompt
[2m[WebServer] [22m    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
[2m[WebServer] [22m           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 765, in generate
[2m[WebServer] [22m    self._generate_with_cache(
[2m[WebServer] [22m    ~~~~~~~~~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        m,
[2m[WebServer] [22m        ^^
[2m[WebServer] [22m    ...<2 lines>...
[2m[WebServer] [22m        **kwargs,
[2m[WebServer] [22m        ^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 1011, in _generate_with_cache
[2m[WebServer] [22m    result = self._generate(
[2m[WebServer] [22m        messages, stop=stop, run_manager=run_manager, **kwargs
[2m[WebServer] [22m    )
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py", line 956, in _generate
[2m[WebServer] [22m    return generate_from_stream(stream_iter)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 153, in generate_from_stream
[2m[WebServer] [22m    generation = next(stream, None)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py", line 907, in _stream
[2m[WebServer] [22m    response = self.client.create(**payload)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_utils/_utils.py", line 287, in wrapper
[2m[WebServer] [22m    return func(*args, **kwargs)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py", line 925, in create
[2m[WebServer] [22m    return self._post(
[2m[WebServer] [22m           ~~~~~~~~~~^
[2m[WebServer] [22m        "/chat/completions",
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<43 lines>...
[2m[WebServer] [22m        stream_cls=Stream[ChatCompletionChunk],
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_base_client.py", line 1239, in post
[2m[WebServer] [22m    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
[2m[WebServer] [22m                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_base_client.py", line 1034, in request
[2m[WebServer] [22m    raise self._make_status_error_from_response(err.response) from None
[2m[WebServer] [22mopenai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `gpt-mock` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
[2m[WebServer] [22mDuring task with name 'agent_executor' and id 'f30bb81b-ce0e-f73d-81eb-63e9c78e6873'
[2m[WebServer] [22mDuring task with name 'agent-1' and id 'ebd3f1dd-2ed5-902d-9950-070d4ca83d98'
✅ Concurrent workflow execution test completed
  ✓  20 tests/multi_user_concurrency.spec.ts:137:7 › Multi-User and Concurrency › Concurrent workflow execution (1.5s)
🚀 Starting WebSocket broadcasting test...
📊 Created 2 WebSocket monitoring sessions
📊 Test 1: Connecting users and monitoring initial messages...
📊 JavaScript errors detected: [33m0[39m
✅ No JavaScript errors during navigation
✅ UI error state test completed
  ✓  18 tests/error_handling_edge_cases.spec.ts:261:7 › Error Handling and Edge Cases › UI error state handling (8.2s)
🚀 Starting resource sharing and conflict resolution test...
📊 Created 2 sessions for conflict testing
📊 Test 1: Testing concurrent modifications...
📊 User 1 WebSocket connected: ws://localhost:8001/api/ws
📊 User 0 WebSocket connected: ws://localhost:8001/api/ws
📊 User 1 received: user_update
📊 User 1 received: ping
📊 User 0 received: user_update
📊 User 0 received: ping
📊 User 0 created agent: [33m1[39m (331ms)
📊 User 1 created agent: [33m1[39m (348ms)
📊 Successful concurrent operations: [33m2[39m / [33m2[39m
📊 Response time range: [33m331[39m ms - [33m348[39m ms
📊 Average response time: [33m340[39m ms
✅ Concurrent operations have similar response times
📊 Test 2: Verifying database consistency...
📊 User 0 sees 1 agents
📊 User 1 sees 1 agents
📊 Test 3: Testing resource contention...
📊 User 0 created workflow referencing shared agent: [33m1[39m
📊 User 1 created workflow referencing shared agent: [33m1[39m
📊 Successful resource sharing operations: [33m2[39m / [33m2[39m
✅ Resource sharing handles concurrent access well
✅ Resource sharing and conflict resolution test completed
  ✓  22 tests/multi_user_concurrency.spec.ts:511:7 › Multi-User and Concurrency › Resource sharing and conflict resolution (710ms)
🚀 Starting session management test...
📊 Test 1: Testing session lifecycle...
📊 Test 2: Testing cross-session message broadcasting...
📊 Created agent in primary session: [33m1[39m
📊 Created agent in session 1: [33m1[39m
📊 Closed session 1
📊 Test 2: Testing data persistence after session closure...
📊 Agent persisted after session closure: [33mtrue[39m
✅ Data persists correctly after session closure
📊 Test 3: Verifying session isolation...
📊 Created agent in session 2: [33m1[39m
📊 Session 2 sees session 1 data: [33mtrue[39m
📊 Session 2 sees own data: [33mtrue[39m
📊 Sessions share data (may be intended behavior)
📊 Test 4: Testing cleanup mechanisms...
📊 Created temporary agent: [33m1[39m
📊 User 0 received 1 agent-related messages
✅ User 0 received WebSocket notifications
📊 User 1 received 1 agent-related messages
✅ User 1 received WebSocket notifications
📊 Test 3: Testing session isolation in WebSocket messages...
📊 Primary session message types: []
📊 Secondary session message types: []
📊 Cross-session messages in secondary: [33m0[39m
✅ WebSocket messages properly isolated between sessions
📊 Test 4: Testing high-frequency message handling...
📊 Cleanup verification completed (manual inspection may be needed)
✅ Session management test completed
  ✓  23 tests/multi_user_concurrency.spec.ts:666:7 › Multi-User and Concurrency › Session management and cleanup (4.0s)
🚀 Starting UI responsiveness test...
📊 Worker ID: 0
📊 Test 1: Page load performance...
📊 Rapid operations completed: [33m5[39m / [33m5[39m
📊 Rapid operations time: [33m313[39m ms
📊 Page load time: [33m1014[39m ms
✅ Page loads within acceptable time (< 3s)
📊 Test 2: Navigation performance...
📊 Dashboard navigation time: [33m146[39m ms
✅ Dashboard navigation is responsive (< 500ms)
📊 Canvas navigation time: [33m202[39m ms
✅ Canvas navigation is responsive (< 500ms)
📊 Test 3: UI interaction responsiveness...
📊 Interactive elements found: [33m113[39m
📊 User 0 received 0 messages during rapid operations
📊 User 1 received 0 messages during rapid operations
✅ WebSocket broadcasting test completed
  ✓  21 tests/multi_user_concurrency.spec.ts:351:7 › Multi-User and Concurrency › WebSocket message broadcasting and isolation (8.3s)
🚀 Starting API performance test...
📊 Test 1: Single API request performance...
📊 GET /api/agents response time: [33m4[39m ms
📊 GET /api/agents status: [33m200[39m
✅ GET /api/agents is very fast (< 200ms)
📊 GET /api/workflows response time: [33m3[39m ms
📊 GET /api/workflows status: [33m200[39m
✅ GET /api/workflows is very fast (< 200ms)
📊 GET /api/users/me response time: [33m2[39m ms
📊 GET /api/users/me status: [33m200[39m
✅ GET /api/users/me is very fast (< 200ms)
📊 Test 2: Batch API request performance...
📊 Batch requests completed: [33m10[39m / [33m10[39m
📊 Batch total time: [33m331[39m ms
📊 Average per request: [33m33[39m ms
✅ Batch API performance is good
✅ API performance test completed
  ✓  25 tests/performance_load_testing.spec.ts:94:7 › Performance and Load Testing › API response time benchmarking (375ms)
🚀 Starting database performance test...
📊 Test 1: Creating large dataset...
📊 Agents created successfully: [33m50[39m / [33m50[39m
📊 Creation time: [33m637[39m ms
📊 Average creation time: [33m13[39m ms per agent
✅ Large dataset creation successful
📊 Test 2: Query performance with large dataset...
📊 Total agents retrieved: [33m68[39m
📊 Query time: [33m7[39m ms
✅ Large dataset query performance is good (< 1s)
📊 Test 3: Testing pagination performance...
📊 Pagination query status: [33m200[39m
📊 Pagination query time: [33m3[39m ms
📊 Paginated results returned: [33m10[39m
✅ Pagination performance is excellent
✅ Database performance test completed
  ✓  26 tests/performance_load_testing.spec.ts:161:7 › Performance and Load Testing › Database performance with large datasets (683ms)
🚀 Starting memory usage test...
📊 Test 1: Establishing memory baseline...
📊 Initial memory usage: { used: [33m10000000[39m, total: [33m10000000[39m, limit: [33m3760000000[39m }
📊 Page timing: { domContentLoaded: [33m514[39m, fullyLoaded: [33m560[39m }
📊 Test 2: Memory usage during intensive operations...
📊 Hover test skipped (element not interactive)
✅ UI responsiveness test completed
  ✓  24 tests/performance_load_testing.spec.ts:18:7 › Performance and Load Testing › UI responsiveness benchmarking (6.4s)
🚀 Starting concurrent user simulation...
📊 Test 1: Simulating 5 concurrent users...
📊 Memory usage after operations: { used: [33m10000000[39m, total: [33m10000000[39m }
📊 Memory increase: [33m0[39m %
✅ Memory usage increase is reasonable
📊 Test 3: Memory leak detection...
📊 Memory usage after GC: { used: [33m10000000[39m, total: [33m10000000[39m }
📊 Memory freed by GC: [33m0[39m bytes
✅ Memory usage test completed
  ✓  27 tests/performance_load_testing.spec.ts:256:7 › Performance and Load Testing › Memory usage and resource monitoring (5.0s)
📊 User 0 agent creation: success
🚀 Starting large workflow performance test...
📊 Test 1: Creating agents for large workflow...
📊 Created agent 0: [33m79[39m
📊 Created agent 1: [33m80[39m
📊 Created agent 2: [33m81[39m
📊 Created agent 3: [33m82[39m
📊 Created agent 4: [33m83[39m
📊 Created agent 5: [33m84[39m
📊 Created agent 6: [33m85[39m
📊 Created agent 7: [33m86[39m
📊 Created agent 8: [33m87[39m
📊 Created agent 9: [33m88[39m
📊 Total agents for large workflow: [33m10[39m
📊 Test 2: Creating large workflow...
📊 User 4 agent creation: success
📊 User 2 agent creation: success
📊 Large workflow creation status: [33m200[39m
📊 Large workflow creation time: [33m307[39m ms
📊 Workflow nodes: [33m16[39m
📊 Workflow connections: [33m16[39m
📊 Large workflow created with ID: [33m3[39m
📊 Large workflow retrieval time: [33m1[39m ms
✅ Large workflow performance is acceptable
✅ Large workflow performance test completed
  ✓  29 tests/performance_load_testing.spec.ts:444:7 › Performance and Load Testing › Large workflow performance (383ms)
🚀 Starting WebSocket monitoring test...
📊 Worker ID: 0
📊 Step 1: Connecting to application...
📊 User 1 agent creation: success
📊 User 3 agent creation: success
📊 Concurrent users completed successfully: [33m5[39m / [33m5[39m
📊 Total simulation time: [33m4090[39m ms
📊 Average time per user: [33m818[39m ms
✅ Concurrent user handling is robust
✅ Concurrent user simulation completed
  ✓  28 tests/performance_load_testing.spec.ts:371:7 › Performance and Load Testing › Concurrent user simulation (4.1s)
🚀 Starting tool palette discovery test...
📊 Worker ID: 0
📊 Step 2: Monitoring WebSocket activity...
📊 Step 3: Creating agent to trigger updates...
✅ Agent created, waiting for WebSocket updates...
📊 Test 1: Locating tool palette...
📊 Tool palette visible: [33mfalse[39m
⚠️  Tool palette not visible - checking alternative locations...
📊 Alternative tool containers found: [33m0[39m
✅ Tool palette discovery completed
  ✓  31 tests/tool_palette_node_connections.spec.ts:18:7 › Tool Palette and Node Connections › Tool palette discovery and cataloging (3.6s)
🚀 Starting tool drag-and-drop test...
📊 Created test agent: [33m90[39m
📊 Step 4: Navigating to trigger more WebSocket events...
📊 Step 5: Analyzing WebSocket messages...
📊 Total WebSocket messages received: [33m0[39m
⚠️  No WebSocket messages received - may need connection investigation
📊 Step 6: Testing real-time UI updates...
📊 Test 1: Identifying drag-and-drop targets...
📊 Canvas container visible: [33mfalse[39m
✅ Tool drag-and-drop test completed
  ✓  32 tests/tool_palette_node_connections.spec.ts:84:7 › Tool Palette and Node Connections › Tool drag-and-drop from palette to canvas (3.7s)
🚀 Starting node connection test...
📊 Agent visible in dashboard: [33mfalse[39m
📊 Step 7: Checking for real-time status indicators...
📊 Status indicators found: [33m0[39m
📊 Online indicators found: [33m0[39m
📊 Activity indicators found: [33m0[39m
✅ WebSocket monitoring test completed
📊 Summary: Real-time WebSocket communication validated
  ✓  30 tests/realtime_websocket_monitoring.spec.ts:15:7 › Real-time WebSocket Monitoring › WebSocket event monitoring and real-time updates (8.6s)
🚀 Starting complex workflow topology test...
📊 Test 1: Creating multiple agents...
📊 Created agent 1: [33m92[39m
📊 Created agent 2: [33m93[39m
📊 Created agent 3: [33m94[39m
📊 Total agents created: [33m3[39m
📊 Test 2: Creating complex workflow topology...
📊 Complex workflow created: [33m4[39m
📊 Test 3: Verifying topology integrity...
✅ Complex workflow topology test completed
  ✓  34 tests/tool_palette_node_connections.spec.ts:309:7 › Tool Palette and Node Connections › Complex workflow topology creation (660ms)
🚀 Starting connection validation test...
📊 Test 1: Testing valid connection topology...
📊 Valid workflow creation status: [33m200[39m
✅ Valid connection topology accepted
📊 Test 2: Testing invalid connection scenarios...
📊 Circular workflow creation status: [33m200[39m
📊 Circular references allowed (system permits cycles)
📊 Test 3: Testing non-existent node references...
📊 Invalid node workflow status: [33m200[39m
✅ Connection validation test completed
  ✓  35 tests/tool_palette_node_connections.spec.ts:458:7 › Tool Palette and Node Connections › Connection validation and constraint checking (954ms)
🚀 Starting workflow execution test...
📊 Worker ID: 1
📊 Step 1: Creating test agent...
✅ Test agent created with ID: [33m1[39m
📊 Step 2: Attempting workflow creation...
✅ Workflow created with ID: [33m2[39m
📊 Step 3: Executing workflow...
[2m[WebServer] [22mERROR - [AgentRunner] Exception during runnable.ainvoke: Error code: 404 - {'error': {'message': 'The model `gpt-mock` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
[2m[WebServer] [22mTraceback (most recent call last):
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/managers/agent_runner.py", line 137, in run_thread
[2m[WebServer] [22m    updated_messages = await self._runnable.ainvoke(original_msgs, config)
[2m[WebServer] [22m                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2850, in ainvoke
[2m[WebServer] [22m    async for chunk in self.astream(
[2m[WebServer] [22m    ...<13 lines>...
[2m[WebServer] [22m            chunks.append(chunk)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2732, in astream
[2m[WebServer] [22m    async for _ in runner.atick(
[2m[WebServer] [22m    ...<7 lines>...
[2m[WebServer] [22m            yield o
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 256, in agent_executor
[2m[WebServer] [22m    return _agent_executor_sync(messages, previous=previous)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 248, in _agent_executor_sync
[2m[WebServer] [22m    return asyncio.run(_agent_executor_async(messages, previous=previous))
[2m[WebServer] [22m           ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/runners.py", line 194, in run
[2m[WebServer] [22m    return runner.run(main)
[2m[WebServer] [22m           ~~~~~~~~~~^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/runners.py", line 118, in run
[2m[WebServer] [22m    return self._loop.run_until_complete(task)
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/base_events.py", line 720, in run_until_complete
[2m[WebServer] [22m    return future.result()
[2m[WebServer] [22m           ~~~~~~~~~~~~~^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 208, in _agent_executor_async
[2m[WebServer] [22m    llm_response = await _call_model_async(current_messages)
[2m[WebServer] [22m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 134, in _call_model_async
[2m[WebServer] [22m    return await asyncio.to_thread(_call_model_sync, messages)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/threads.py", line 25, in to_thread
[2m[WebServer] [22m    return await loop.run_in_executor(None, func_call)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/thread.py", line 59, in run
[2m[WebServer] [22m    result = self.fn(*self.args, **self.kwargs)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 127, in _call_model_sync
[2m[WebServer] [22m    return llm_with_tools.invoke(messages)
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/runnables/base.py", line 5416, in invoke
[2m[WebServer] [22m    return self.bound.invoke(
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        input,
[2m[WebServer] [22m        ^^^^^^
[2m[WebServer] [22m        self._merge_configs(config),
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m        **{**self.kwargs, **kwargs},
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 369, in invoke
[2m[WebServer] [22m    self.generate_prompt(
[2m[WebServer] [22m    ~~~~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        [self._convert_input(input)],
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<6 lines>...
[2m[WebServer] [22m        **kwargs,
[2m[WebServer] [22m        ^^^^^^^^^
[2m[WebServer] [22m    ).generations[0][0],
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 946, in generate_prompt
[2m[WebServer] [22m    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
[2m[WebServer] [22m           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 765, in generate
[2m[WebServer] [22m    self._generate_with_cache(
[2m[WebServer] [22m    ~~~~~~~~~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        m,
[2m[WebServer] [22m        ^^
[2m[WebServer] [22m    ...<2 lines>...
[2m[WebServer] [22m        **kwargs,
[2m[WebServer] [22m        ^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 1011, in _generate_with_cache
[2m[WebServer] [22m    result = self._generate(
[2m[WebServer] [22m        messages, stop=stop, run_manager=run_manager, **kwargs
[2m[WebServer] [22m    )
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py", line 956, in _generate
[2m[WebServer] [22m    return generate_from_stream(stream_iter)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 153, in generate_from_stream
[2m[WebServer] [22m    generation = next(stream, None)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py", line 907, in _stream
[2m[WebServer] [22m    response = self.client.create(**payload)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_utils/_utils.py", line 287, in wrapper
[2m[WebServer] [22m    return func(*args, **kwargs)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py", line 925, in create
[2m[WebServer] [22m    return self._post(
[2m[WebServer] [22m           ~~~~~~~~~~^
[2m[WebServer] [22m        "/chat/completions",
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<43 lines>...
[2m[WebServer] [22m        stream_cls=Stream[ChatCompletionChunk],
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_base_client.py", line 1239, in post
[2m[WebServer] [22m    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
[2m[WebServer] [22m                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_base_client.py", line 1034, in request
[2m[WebServer] [22m    raise self._make_status_error_from_response(err.response) from None
[2m[WebServer] [22mopenai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `gpt-mock` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
[2m[WebServer] [22mDuring task with name 'agent_executor' and id '39b2a477-5bbe-f7cd-0304-eed1a79e0365'
[2m[WebServer] [22mERROR - [AgentNode] Exception in agent node agent-1 (agent_id=1): Error code: 404 - {'error': {'message': 'The model `gpt-mock` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
[2m[WebServer] [22mTraceback (most recent call last):
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/services/langgraph_workflow_engine.py", line 729, in agent_node
[2m[WebServer] [22m    created_messages = await runner.run_thread(db, thread)
[2m[WebServer] [22m                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/managers/agent_runner.py", line 137, in run_thread
[2m[WebServer] [22m    updated_messages = await self._runnable.ainvoke(original_msgs, config)
[2m[WebServer] [22m                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2850, in ainvoke
[2m[WebServer] [22m    async for chunk in self.astream(
[2m[WebServer] [22m    ...<13 lines>...
[2m[WebServer] [22m            chunks.append(chunk)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2732, in astream
[2m[WebServer] [22m    async for _ in runner.atick(
[2m[WebServer] [22m    ...<7 lines>...
[2m[WebServer] [22m            yield o
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 256, in agent_executor
[2m[WebServer] [22m    return _agent_executor_sync(messages, previous=previous)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 248, in _agent_executor_sync
[2m[WebServer] [22m    return asyncio.run(_agent_executor_async(messages, previous=previous))
[2m[WebServer] [22m           ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/runners.py", line 194, in run
[2m[WebServer] [22m    return runner.run(main)
[2m[WebServer] [22m           ~~~~~~~~~~^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/runners.py", line 118, in run
[2m[WebServer] [22m    return self._loop.run_until_complete(task)
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/base_events.py", line 720, in run_until_complete
[2m[WebServer] [22m    return future.result()
[2m[WebServer] [22m           ~~~~~~~~~~~~~^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 208, in _agent_executor_async
[2m[WebServer] [22m    llm_response = await _call_model_async(current_messages)
[2m[WebServer] [22m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 134, in _call_model_async
[2m[WebServer] [22m    return await asyncio.to_thread(_call_model_sync, messages)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/threads.py", line 25, in to_thread
[2m[WebServer] [22m    return await loop.run_in_executor(None, func_call)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/thread.py", line 59, in run
[2m[WebServer] [22m    result = self.fn(*self.args, **self.kwargs)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 127, in _call_model_sync
[2m[WebServer] [22m    return llm_with_tools.invoke(messages)
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/runnables/base.py", line 5416, in invoke
[2m[WebServer] [22m    return self.bound.invoke(
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        input,
[2m[WebServer] [22m        ^^^^^^
[2m[WebServer] [22m        self._merge_configs(config),
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m        **{**self.kwargs, **kwargs},
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 369, in invoke
[2m[WebServer] [22m    self.generate_prompt(
[2m[WebServer] [22m    ~~~~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        [self._convert_input(input)],
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<6 lines>...
[2m[WebServer] [22m        **kwargs,
[2m[WebServer] [22m        ^^^^^^^^^
[2m[WebServer] [22m    ).generations[0][0],
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 946, in generate_prompt
[2m[WebServer] [22m    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
[2m[WebServer] [22m           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 765, in generate
[2m[WebServer] [22m    self._generate_with_cache(
[2m[WebServer] [22m    ~~~~~~~~~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        m,
[2m[WebServer] [22m        ^^
[2m[WebServer] [22m    ...<2 lines>...
[2m[WebServer] [22m        **kwargs,
[2m[WebServer] [22m        ^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 1011, in _generate_with_cache
[2m[WebServer] [22m    result = self._generate(
[2m[WebServer] [22m        messages, stop=stop, run_manager=run_manager, **kwargs
[2m[WebServer] [22m    )
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py", line 956, in _generate
[2m[WebServer] [22m    return generate_from_stream(stream_iter)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 153, in generate_from_stream
[2m[WebServer] [22m    generation = next(stream, None)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py", line 907, in _stream
[2m[WebServer] [22m    response = self.client.create(**payload)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_utils/_utils.py", line 287, in wrapper
[2m[WebServer] [22m    return func(*args, **kwargs)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py", line 925, in create
[2m[WebServer] [22m    return self._post(
[2m[WebServer] [22m           ~~~~~~~~~~^
[2m[WebServer] [22m        "/chat/completions",
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<43 lines>...
[2m[WebServer] [22m        stream_cls=Stream[ChatCompletionChunk],
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_base_client.py", line 1239, in post
[2m[WebServer] [22m    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
[2m[WebServer] [22m                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_base_client.py", line 1034, in request
[2m[WebServer] [22m    raise self._make_status_error_from_response(err.response) from None
[2m[WebServer] [22mopenai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `gpt-mock` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
[2m[WebServer] [22mDuring task with name 'agent_executor' and id '39b2a477-5bbe-f7cd-0304-eed1a79e0365'
[2m[WebServer] [22mERROR - [AgentNode] Updated node_state to 'failed' in DB
[2m[WebServer] [22mERROR - [AgentNode] Re-raising exception to fail workflow execution
[2m[WebServer] [22mERROR - [LangGraphEngine] Execution failed – execution_id=1
[2m[WebServer] [22mTraceback (most recent call last):
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/services/langgraph_workflow_engine.py", line 146, in execute_workflow
[2m[WebServer] [22m    await self._execute_workflow_internal(workflow, execution, db)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/services/langgraph_workflow_engine.py", line 214, in _execute_workflow_internal
[2m[WebServer] [22m    async for chunk in graph.astream(initial_state, config):
[2m[WebServer] [22m    ...<36 lines>...
[2m[WebServer] [22m            logger.warning(f"[LangGraphEngine] Received empty chunk #{chunk_count}")
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2732, in astream
[2m[WebServer] [22m    async for _ in runner.atick(
[2m[WebServer] [22m    ...<7 lines>...
[2m[WebServer] [22m            yield o
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/services/langgraph_workflow_engine.py", line 729, in agent_node
[2m[WebServer] [22m    created_messages = await runner.run_thread(db, thread)
[2m[WebServer] [22m                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/managers/agent_runner.py", line 137, in run_thread
[2m[WebServer] [22m    updated_messages = await self._runnable.ainvoke(original_msgs, config)
[2m[WebServer] [22m                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2850, in ainvoke
[2m[WebServer] [22m    async for chunk in self.astream(
[2m[WebServer] [22m    ...<13 lines>...
[2m[WebServer] [22m            chunks.append(chunk)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2732, in astream
[2m[WebServer] [22m    async for _ in runner.atick(
[2m[WebServer] [22m    ...<7 lines>...
[2m[WebServer] [22m            yield o
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 256, in agent_executor
[2m[WebServer] [22m    return _agent_executor_sync(messages, previous=previous)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 248, in _agent_executor_sync
[2m[WebServer] [22m    return asyncio.run(_agent_executor_async(messages, previous=previous))
[2m[WebServer] [22m           ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/runners.py", line 194, in run
[2m[WebServer] [22m    return runner.run(main)
[2m[WebServer] [22m           ~~~~~~~~~~^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/runners.py", line 118, in run
[2m[WebServer] [22m    return self._loop.run_until_complete(task)
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/base_events.py", line 720, in run_until_complete
[2m[WebServer] [22m    return future.result()
[2m[WebServer] [22m           ~~~~~~~~~~~~~^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 208, in _agent_executor_async
[2m[WebServer] [22m    llm_response = await _call_model_async(current_messages)
[2m[WebServer] [22m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 134, in _call_model_async
[2m[WebServer] [22m    return await asyncio.to_thread(_call_model_sync, messages)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/threads.py", line 25, in to_thread
[2m[WebServer] [22m    return await loop.run_in_executor(None, func_call)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/thread.py", line 59, in run
[2m[WebServer] [22m    result = self.fn(*self.args, **self.kwargs)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 127, in _call_model_sync
[2m[WebServer] [22m    return llm_with_tools.invoke(messages)
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/runnables/base.py", line 5416, in invoke
[2m[WebServer] [22m    return self.bound.invoke(
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        input,
[2m[WebServer] [22m        ^^^^^^
[2m[WebServer] [22m        self._merge_configs(config),
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m        **{**self.kwargs, **kwargs},
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 369, in invoke
[2m[WebServer] [22m    self.generate_prompt(
[2m[WebServer] [22m    ~~~~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        [self._convert_input(input)],
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<6 lines>...
[2m[WebServer] [22m        **kwargs,
[2m[WebServer] [22m        ^^^^^^^^^
[2m[WebServer] [22m    ).generations[0][0],
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 946, in generate_prompt
[2m[WebServer] [22m    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
[2m[WebServer] [22m           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 765, in generate
[2m[WebServer] [22m    self._generate_with_cache(
[2m[WebServer] [22m    ~~~~~~~~~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        m,
[2m[WebServer] [22m        ^^
[2m[WebServer] [22m    ...<2 lines>...
[2m[WebServer] [22m        **kwargs,
[2m[WebServer] [22m        ^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 1011, in _generate_with_cache
[2m[WebServer] [22m    result = self._generate(
[2m[WebServer] [22m        messages, stop=stop, run_manager=run_manager, **kwargs
[2m[WebServer] [22m    )
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py", line 956, in _generate
[2m[WebServer] [22m    return generate_from_stream(stream_iter)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 153, in generate_from_stream
[2m[WebServer] [22m    generation = next(stream, None)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py", line 907, in _stream
[2m[WebServer] [22m    response = self.client.create(**payload)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_utils/_utils.py", line 287, in wrapper
[2m[WebServer] [22m    return func(*args, **kwargs)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py", line 925, in create
[2m[WebServer] [22m    return self._post(
[2m[WebServer] [22m           ~~~~~~~~~~^
[2m[WebServer] [22m        "/chat/completions",
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<43 lines>...
[2m[WebServer] [22m        stream_cls=Stream[ChatCompletionChunk],
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_base_client.py", line 1239, in post
[2m[WebServer] [22m    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
[2m[WebServer] [22m                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_base_client.py", line 1034, in request
[2m[WebServer] [22m    raise self._make_status_error_from_response(err.response) from None
[2m[WebServer] [22mopenai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `gpt-mock` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
[2m[WebServer] [22mDuring task with name 'agent_executor' and id '39b2a477-5bbe-f7cd-0304-eed1a79e0365'
[2m[WebServer] [22mDuring task with name 'agent-1' and id 'f81e95f1-9391-261b-9cc8-e6e647888306'
[2m[WebServer] [22mERROR - Unhandled exception: Error code: 404 - {'error': {'message': 'The model `gpt-mock` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
[2m[WebServer] [22mTraceback (most recent call last):
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/middleware/errors.py", line 165, in __call__
[2m[WebServer] [22m    await self.app(scope, receive, _send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/middleware/worker_db.py", line 101, in __call__
[2m[WebServer] [22m    await self.app(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/middleware/cors.py", line 85, in __call__
[2m[WebServer] [22m    await self.app(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/middleware/exceptions.py", line 62, in __call__
[2m[WebServer] [22m    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
[2m[WebServer] [22m    raise exc
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
[2m[WebServer] [22m    await app(scope, receive, sender)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/routing.py", line 714, in __call__
[2m[WebServer] [22m    await self.middleware_stack(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/routing.py", line 734, in app
[2m[WebServer] [22m    await route.handle(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/routing.py", line 288, in handle
[2m[WebServer] [22m    await self.app(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/routing.py", line 76, in app
[2m[WebServer] [22m    await wrap_app_handling_exceptions(app, request)(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
[2m[WebServer] [22m    raise exc
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
[2m[WebServer] [22m    await app(scope, receive, sender)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/routing.py", line 73, in app
[2m[WebServer] [22m    response = await f(request)
[2m[WebServer] [22m               ^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/fastapi/routing.py", line 301, in app
[2m[WebServer] [22m    raw_response = await run_endpoint_function(
[2m[WebServer] [22m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<3 lines>...
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/fastapi/routing.py", line 212, in run_endpoint_function
[2m[WebServer] [22m    return await dependant.call(**values)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/routers/workflow_executions.py", line 74, in start_workflow_execution
[2m[WebServer] [22m    execution_id = await langgraph_workflow_engine.execute_workflow(workflow_id)
[2m[WebServer] [22m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/services/langgraph_workflow_engine.py", line 146, in execute_workflow
[2m[WebServer] [22m    await self._execute_workflow_internal(workflow, execution, db)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/services/langgraph_workflow_engine.py", line 214, in _execute_workflow_internal
[2m[WebServer] [22m    async for chunk in graph.astream(initial_state, config):
[2m[WebServer] [22m    ...<36 lines>...
[2m[WebServer] [22m            logger.warning(f"[LangGraphEngine] Received empty chunk #{chunk_count}")
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2732, in astream
[2m[WebServer] [22m    async for _ in runner.atick(
[2m[WebServer] [22m    ...<7 lines>...
[2m[WebServer] [22m            yield o
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/services/langgraph_workflow_engine.py", line 729, in agent_node
[2m[WebServer] [22m    created_messages = await runner.run_thread(db, thread)
[2m[WebServer] [22m                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/managers/agent_runner.py", line 137, in run_thread
[2m[WebServer] [22m    updated_messages = await self._runnable.ainvoke(original_msgs, config)
[2m[WebServer] [22m                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2850, in ainvoke
[2m[WebServer] [22m    async for chunk in self.astream(
[2m[WebServer] [22m    ...<13 lines>...
[2m[WebServer] [22m            chunks.append(chunk)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2732, in astream
[2m[WebServer] [22m    async for _ in runner.atick(
[2m[WebServer] [22m    ...<7 lines>...
[2m[WebServer] [22m            yield o
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 256, in agent_executor
[2m[WebServer] [22m    return _agent_executor_sync(messages, previous=previous)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 248, in _agent_executor_sync
[2m[WebServer] [22m    return asyncio.run(_agent_executor_async(messages, previous=previous))
[2m[WebServer] [22m           ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/runners.py", line 194, in run
[2m[WebServer] [22m    return runner.run(main)
[2m[WebServer] [22m           ~~~~~~~~~~^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/runners.py", line 118, in run
[2m[WebServer] [22m    return self._loop.run_until_complete(task)
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/base_events.py", line 720, in run_until_complete
[2m[WebServer] [22m    return future.result()
[2m[WebServer] [22m           ~~~~~~~~~~~~~^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 208, in _agent_executor_async
[2m[WebServer] [22m    llm_response = await _call_model_async(current_messages)
[2m[WebServer] [22m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 134, in _call_model_async
[2m[WebServer] [22m    return await asyncio.to_thread(_call_model_sync, messages)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/threads.py", line 25, in to_thread
[2m[WebServer] [22m    return await loop.run_in_executor(None, func_call)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/thread.py", line 59, in run
[2m[WebServer] [22m    result = self.fn(*self.args, **self.kwargs)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 127, in _call_model_sync
[2m[WebServer] [22m    return llm_with_tools.invoke(messages)
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/runnables/base.py", line 5416, in invoke
[2m[WebServer] [22m    return self.bound.invoke(
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        input,
[2m[WebServer] [22m        ^^^^^^
[2m[WebServer] [22m        self._merge_configs(config),
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m        **{**self.kwargs, **kwargs},
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 369, in invoke
[2m[WebServer] [22m    self.generate_prompt(
[2m[WebServer] [22m    ~~~~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        [self._convert_input(input)],
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<6 lines>...
[2m[WebServer] [22m        **kwargs,
[2m[WebServer] [22m        ^^^^^^^^^
[2m[WebServer] [22m    ).generations[0][0],
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 946, in generate_prompt
[2m[WebServer] [22m    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
[2m[WebServer] [22m           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 765, [2m[WebServer] [22min generate
[2m[WebServer] [22m    self._generate_with_cache(
[2m[WebServer] [22m    ~~~~~~~~~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        m,
[2m[WebServer] [22m        ^^
[2m[WebServer] [22m    ...<2 lines>...
[2m[WebServer] [22m        **kwargs,
[2m[WebServer] [22m        ^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 1011, in _generate_with_cache
[2m[WebServer] [22m    result = self._generate(
[2m[WebServer] [22m        messages, stop=stop, run_manager=run_manager, **kwargs
[2m[WebServer] [22m    )
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py", line 956, in _generate
[2m[WebServer] [22m    return generate_from_stream(stream_iter)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 153, in generate_from_stream
[2m[WebServer] [22m    generation = next(stream, None)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py", line 907, in _stream
[2m[WebServer] [22m    response = self.client.create(**payload)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_utils/_utils.py", line 287, in wrapper
[2m[WebServer] [22m    return func(*args, **kwargs)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py", line 925, in create
[2m[WebServer] [22m    return self._post(
[2m[WebServer] [22m           ~~~~~~~~~~^
[2m[WebServer] [22m        "/chat/completions",
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<43 lines>...
[2m[WebServer] [22m        stream_cls=Stream[ChatCompletionChunk],
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_base_client.py", line 1239, in post
[2m[WebServer] [22m    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
[2m[WebServer] [22m                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_base_client.py", line 1034, in request
[2m[WebServer] [22m    raise self._make_status_error_from_response(err.response) from None
[2m[WebServer] [22mopenai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `gpt-mock` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
[2m[WebServer] [22mDuring task with name 'agent_executor' and id '39b2a477-5bbe-f7cd-0304-eed1a79e0365'
[2m[WebServer] [22mDuring task with name 'agent-1' and id 'f81e95f1-9391-261b-9cc8-e6e647888306'
❌ Workflow execution failed: [33m500[39m
📊 Step 5: Testing direct HTTP tool usage...
[2m[WebServer] [22mERROR:    Exception in ASGI application
[2m[WebServer] [22mTraceback (most recent call last):
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/uvicorn/protocols/http/h11_impl.py", line 408, in run_asgi
[2m[WebServer] [22m    result = await app(  # type: ignore[func-returns-value]
[2m[WebServer] [22m             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m        self.scope, self.receive, self.send
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/uvicorn/middleware/proxy_headers.py", line 84, in __call__
[2m[WebServer] [22m    return await self.app(scope, receive, send)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/fastapi/applications.py", line 1054, in __call__
[2m[WebServer] [22m    await super().__call__(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/applications.py", line 112, in __call__
[2m[WebServer] [22m    await self.middleware_stack(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/middleware/errors.py", line 187, in __call__
[2m[WebServer] [22m    raise exc
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/middleware/errors.py", line 165, in __call__
[2m[WebServer] [22m    await self.app(scope, receive, _send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/middleware/worker_db.py", line 101, in __call__
[2m[WebServer] [22m    await self.app(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/middleware/cors.py", line 85, in __call__
[2m[WebServer] [22m    await self.app(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/middleware/exceptions.py", line 62, in __call__
[2m[WebServer] [22m    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
[2m[WebServer] [22m    raise exc
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
[2m[WebServer] [22m    await app(scope, receive, sender)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/routing.py", line 714, in __call__
[2m[WebServer] [22m    await self.middleware_stack(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/routing.py", line 734, in app
[2m[WebServer] [22m    await route.handle(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/routing.py", line 288, in handle
[2m[WebServer] [22m    await self.app(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/routing.py", line 76, in app
[2m[WebServer] [22m    await wrap_app_handling_exceptions(app, request)(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
[2m[WebServer] [22m    raise exc
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
[2m[WebServer] [22m    await app(scope, receive, sender)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/routing.py", line 73, in app
[2m[WebServer] [22m    response = await f(request)
[2m[WebServer] [22m               ^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/fastapi/routing.py", line 301, in app
[2m[WebServer] [22m    raw_response = await run_endpoint_function(
[2m[WebServer] [22m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<3 lines>...
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/fastapi/routing.py", line 212, in run_endpoint_function
[2m[WebServer] [22m    return await dependant.call(**values)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/routers/workflow_executions.py", line 74, in start_workflow_execution
[2m[WebServer] [22m    execution_id = await langgraph_workflow_engine.execute_workflow(workflow_id)
[2m[WebServer] [22m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/services/langgraph_workflow_engine.py", line 146, in execute_workflow
[2m[WebServer] [22m    await self._execute_workflow_internal(workflow, execution, db)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/services/langgraph_workflow_engine.py", line 214, in _execute_workflow_internal
[2m[WebServer] [22m    async for chunk in graph.astream(initial_state, config):
[2m[WebServer] [22m    ...<36 lines>...
[2m[WebServer] [22m            logger.warning(f"[LangGraphEngine] Received empty chunk #{chunk_count}")
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2732, in astream
[2m[WebServer] [22m    async for _ in runner.atick(
[2m[WebServer] [22m    ...<7 lines>...
[2m[WebServer] [22m            yield o
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/services/langgraph_workflow_engine.py", line 729, in agent_node
[2m[WebServer] [22m    created_messages = await runner.run_thread(db, thread)
[2m[WebServer] [22m                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/managers/agent_runner.py", line 137, in run_thread
[2m[WebServer] [22m    updated_messages = await self._runnable.ainvoke(original_msgs, config)
[2m[WebServer] [22m                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2850, in ainvoke
[2m[WebServer] [22m    async for chunk in self.astream(
[2m[WebServer] [22m    ...<13 lines>...
[2m[WebServer] [22m            chunks.append(chunk)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2732, in astream
[2m[WebServer] [22m    async for _ in runner.atick(
[2m[WebServer] [22m    ...<7 lines>...
[2m[WebServer] [22m            yield o
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 256, in agent_executor
[2m[WebServer] [22m    return _agent_executor_sync(messages, previous=previous)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 248, in _agent_executor_sync
[2m[WebServer] [22m    return asyncio.run(_agent_executor_async(messages, previous=previous))
[2m[WebServer] [22m           ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/runners.py", line 194, in run
[2m[WebServer] [22m    return runner.run(main)
[2m[WebServer] [22m           ~~~~~~~~~~^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/runners.py", line 118, in run
[2m[WebServer] [22m    return self._loop.run_until_complete(task)
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/base_events.py", line 720, in run_until_complete
[2m[WebServer] [22m    return future.result()
[2m[WebServer] [22m           ~~~~~~~~~~~~~^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 208, in _agent_executor_async
[2m[WebServer] [22m    llm_response = await _call_model_async(current_messages)
[2m[WebServer] [22m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 134, in _call_model_async
[2m[WebServer] [22m    return await asyncio.to_thread(_call_model_sync, messages)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/threads.py", line 25, in to_thread
[2m[WebServer] [22m    return await loop.run_in_executor(None, func_call)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/thread.py", line 59, in run
[2m[WebServer] [22m    result = self.fn(*self.args, **self.kwargs)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 127, in _call_model_sync
[2m[WebServer] [22m    return llm_with_tools.invoke(messages)
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/runnables/base.py", line 5416, in invoke
[2m[WebServer] [22m    return self.bound.invoke(
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        input,
[2m[WebServer] [22m        ^^^^^^
[2m[WebServer] [22m        self._merge_configs(config),
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^[2m[WebServer] [22m^^^^^^^^^
[2m[WebServer] [22m        **{**self.kwargs, **kwargs},
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 369, in invoke
[2m[WebServer] [22m    self.generate_prompt(
[2m[WebServer] [22m    ~~~~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        [self._convert_input(input)],
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<6 lines>...
[2m[WebServer] [22m        **kwargs,
[2m[WebServer] [22m        ^^^^^^^^^
[2m[WebServer] [22m    ).generations[0][0],
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 946, in generate_prompt
[2m[WebServer] [22m    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
[2m[WebServer] [22m           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 765, in generate
[2m[WebServer] [22m    self._generate_with_cache(
[2m[WebServer] [22m    ~~~~~~~~~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        m,
[2m[WebServer] [22m        ^^
[2m[WebServer] [22m    ...<2 lines>...
[2m[WebServer] [22m        **kwargs,
[2m[WebServer] [22m        ^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 1011, in _generate_with_cache
[2m[WebServer] [22m    result = self._generate(
[2m[WebServer] [22m        messages, stop=stop, run_manager=run_manager, **kwargs
[2m[WebServer] [22m    )
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py", line 956, in _generate
[2m[WebServer] [22m    return generate_from_stream(stream_iter)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 153, in generate_from_stream
[2m[WebServer] [22m    generation = next(stream, None)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py", line 907, in _stream
[2m[WebServer] [22m    response = self.client.create(**payload)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_utils/_utils.py", line 287, in wrapper
[2m[WebServer] [22m    return func(*args, **kwargs)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py", line 925, in create
[2m[WebServer] [22m    return self._post(
[2m[WebServer] [22m           ~~~~~~~~~~^
[2m[WebServer] [22m        "/chat/completions",
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<43 lines>...
[2m[WebServer] [22m        stream_cls=Stream[ChatCompletionChunk],
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_base_client.py", line 1239, in post
[2m[WebServer] [22m    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
[2m[WebServer] [22m                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_base_client.py", line 1034, in request
[2m[WebServer] [22m    raise self._make_status_error_from_response(err.response) from None
[2m[WebServer] [22mopenai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `gpt-mock` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
[2m[WebServer] [22mDuring task with name 'agent_executor' and id '39b2a477-5bbe-f7cd-0304-eed1a79e0365'
[2m[WebServer] [22mDuring task with name 'agent-1' and id 'f81e95f1-9391-261b-9cc8-e6e647888306'
📊 Tools endpoint not available or error: apiRequestContext.get: read ECONNRESET
Call log:
[2m  - → GET http://localhost:8001/api/tools[22m
[2m    - user-agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/136.0.7103.25 Safari/537.36[22m
[2m    - accept: */*[22m
[2m    - accept-encoding: gzip,deflate,br[22m
[2m    - X-Test-Worker: 1[22m

📊 Step 6: Checking UI for workflow execution...
📊 Test 1: Detecting canvas nodes...
📊 Existing nodes on canvas: [33m0[39m
📊 No existing nodes - attempting to create nodes for connection test...
📊 Test 2: Detecting connection handles...
📊 Connection handles found: [33m0[39m
⚠️  No connection handles detected - may need UI implementation
✅ Node connection test completed
  ✓  33 tests/tool_palette_node_connections.spec.ts:180:7 › Tool Palette and Node Connections › Node connection handle detection and interaction (3.7s)
📊 Execute buttons found: [33m0[39m
📊 Run buttons found: [33m0[39m
📊 Workflow elements found: [33m0[39m
✅ Workflow execution test completed
📊 Summary: Workflow execution infrastructure validated
  ✓  36 tests/workflow_execution_http.spec.ts:15:7 › Workflow Execution with HTTP Tools › Execute workflow with HTTP tool and verify requests (2.9s)
🧹 Starting test environment cleanup...
✅ Test database cleanup completed
✅ Test environment cleanup completed

  36 passed (1.1m)
