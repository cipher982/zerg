[2m[WebServer] [22m[build-only] ğŸ”§ building frontend (debug)â€¦
[2m[WebServer] [22m[build-only] ğŸ—  wasm-pack build â€¦
[2m[WebServer] [22m[INFO]: ğŸ¯  Checking for the Wasm target...
[2m[WebServer] [22m[INFO]: ğŸŒ€  Compiling to Wasm...
[2m[WebServer] [22m   Compiling agent-platform-frontend v0.1.0 (/Users/davidrose/git/zerg/frontend)
[2m[WebServer] [22mwarning: unused import: `super::*`
[2m[WebServer] [22m  --> src/generated/tool_definitions.rs:83:9
[2m[WebServer] [22m   |
[2m[WebServer] [22m83 |     use super::*;
[2m[WebServer] [22m   |         ^^^^^^^^
[2m[WebServer] [22m   |
[2m[WebServer] [22m   = note: `#[warn(unused_imports)]` on by default
[2m[WebServer] [22m
[2m[WebServer] [22mwarning: unused imports: `Envelope` and `WsMessage`
[2m[WebServer] [22m --> src/generated/mod.rs:9:23
[2m[WebServer] [22m  |
[2m[WebServer] [22m9 | pub use ws_messages::{Envelope, WsMessage};[2m[WebServer] [22m
[2m[WebServer] [22m  |                       ^^^^^^^^  ^^^^^^^^^
[2m[WebServer] [22m
[2m[WebServer] [22mwarning: unused variable: `client_id_str`
[2m[WebServer] [22m   --> src/command_executors.rs:655:17
[2m[WebServer] [22m    |
[2m[WebServer] [22m655 |             let client_id_str = client_id.map(|id| id.to_string()).unwrap_or_default();
[2m[WebServer] [22m    |                 ^^^^^^^^^^^^^ help: if this is intentional, prefix it with an underscore: `_client_id_str`
[2m[WebServer] [22m    |
[2m[WebServer] [22m    = note: `#[warn(unused_variables)]` on by default
[2m[WebServer] [22m
[2m[WebServer] [22mwarning: unused variable: `data`
[2m[WebServer] [22m   --> src/generated/ws_messages.rs:266:26
[2m[WebServer] [22m    |
[2m[WebServer] [22m266 | pub fn validate_envelope(data: &Value) -> Result<(), String> {
[2m[WebServer] [22m    |                          [2m[WebServer] [22m^^^^ help: if this is intentional, prefix it with an underscore: `_data`
[2m[WebServer] [22m
[2m[WebServer] [22mwarning: `agent-platform-frontend` (lib) generated 4 warnings (run `cargo fix --lib -p agent-platform-frontend` to apply 2 suggestions)
[2m[WebServer] [22m    Finished `dev` profile [unoptimized + debuginfo] target(s) in 3.36s
[2m[WebServer] [22m[INFO]: â¬‡ï¸  Installing wasm-bindgen...
[2m[WebServer] [22m[INFO]: Optional fields missing from Cargo.toml: 'description', 'repository', and 'license'. These are not necessary, but recommended
[2m[WebServer] [22m[INFO]: âœ¨   Done in 3.86s
[2m[WebServer] [22m[INFO]: ğŸ“¦   Your wasm pkg is ready to publish at /Users/davidrose/git/zerg/frontend/pkg.
[2m[WebServer] [22m[build-only] ğŸ“¦ copying WASM artifacts to www...
[2m[WebServer] [22m[build-only] âœï¸  writing bootstrap.js â€¦
[2m[WebServer] [22m[build-only] âœï¸  writing config.js â€¦
[2m[WebServer] [22m[build-only] âœ… build complete (output in frontend/www/)
ğŸš€ Setting up test environment...
âœ… Pre-test cleanup completed
âœ… Test environment setup completed

Running 36 tests using 2 workers

ğŸš€ Starting WCAG compliance test...
ğŸ“Š Worker ID: 0
ğŸš€ Starting keyboard navigation test...
ğŸ“Š Test 1: Testing tab order...
ğŸ“Š Tab 1: BUTTON [create-agent-btn]
ğŸ“Š Tab 2: BUTTON [reset-db-btn]
ğŸ“Š Tab 3: BUTTON
ğŸ“Š Tab 4: BUTTON [global-dashboard-tab]
ğŸ“Š Tab 5: BUTTON [global-canvas-tab]
ğŸ“Š Tab 6: BODY
ğŸ“Š Tab 7: BUTTON [create-agent-btn]
ğŸ“Š Tab 8: BUTTON [reset-db-btn]
ğŸ“Š Test 1: Checking semantic structure...
ğŸ“Š Semantic elements found: {
  header: [33m0[39m,
  nav: [33m0[39m,
  main: [33m0[39m,
  section: [33m0[39m,
  article: [33m0[39m,
  aside: [33m0[39m,
  footer: [33m0[39m
}
âš ï¸  Consider adding semantic HTML elements
ğŸ“Š Test 2: Checking heading hierarchy...
ğŸ“Š Heading structure: { h1: [33m1[39m, h2: [33m1[39m, h3: [33m0[39m, h4: [33m0[39m, h5: [33m0[39m, h6: [33m0[39m }
âœ… Page has primary heading (h1)
ğŸ“Š Test 3: Checking ARIA attributes...
ğŸ“Š ARIA attributes found: {
  [32m'aria-label'[39m: [33m1[39m,
  [32m'aria-labelledby'[39m: [33m0[39m,
  [32m'aria-describedby'[39m: [33m0[39m,
  [32m'aria-hidden'[39m: [33m1[39m,
  role: [33m1[39m,
  [32m'aria-expanded'[39m: [33m0[39m
}
âœ… ARIA attributes are being used
ğŸ“Š Test 4: Checking form accessibility...
ğŸ“Š Form elements found: [33m11[39m
ğŸ“Š Labeled form elements: [33m2[39m
âœ… Form elements have labels
âœ… WCAG compliance test completed
  âœ“  1 tests/accessibility_ui_ux.spec.ts:18:7 â€º Accessibility and UI/UX â€º WCAG compliance and semantic markup (2.8s)
ğŸš€ Starting screen reader compatibility test...
ğŸ“Š Tab 9: BUTTON
ğŸ“Š Tab 10: BUTTON [global-dashboard-tab]
ğŸ“Š Unique focusable elements: [33m6[39m
âœ… Multiple elements are keyboard accessible
ğŸ“Š Test 2: Testing escape key functionality...
âœ… Escape key press handled
ğŸ“Š Test 3: Testing enter key activation...
âœ… Enter key activation tested
ğŸ“Š Test 4: Testing arrow key navigation...
âœ… Keyboard navigation test completed
  âœ“  2 tests/accessibility_ui_ux.spec.ts:113:7 â€º Accessibility and UI/UX â€º Keyboard navigation functionality (3.4s)
ğŸš€ Starting color contrast test...
ğŸ“Š Test 1: Checking page title and structure...
ğŸ“Š Page title: AI Agent Platform
âœ… Page has a descriptive title
ğŸ“Š Test 2: Checking image alt text...
ğŸ“Š Total images: [33m0[39m
ğŸ“Š Images with alt text: [33m0[39m
ğŸ“Š Decorative images (empty alt): [33m0[39m
ğŸ“Š No images found on page
ğŸ“Š Test 3: Checking link accessibility...
ğŸ“Š Total links: [33m0[39m
ğŸ“Š Test 4: Checking live regions...
ğŸ“Š Live regions found: [33m0[39m
ğŸ“Š Status/alert elements: [33m0[39m
ğŸ“Š No live regions found (may not be needed)
âœ… Screen reader compatibility test completed
  âœ“  3 tests/accessibility_ui_ux.spec.ts:196:7 â€º Accessibility and UI/UX â€º Screen reader compatibility (1.4s)
ğŸš€ Starting responsive design test...
ğŸ“Š Test 1: Testing mobile viewport...
ğŸ“Š Test 1: Analyzing color usage...
ğŸ“Š Color-based indicators: [33m1[39m
ğŸ“Š Icon-based indicators: [33m0[39m
âš ï¸  Consider adding icons or text to supplement color information
ğŸ“Š Test 2: Checking focus indicators...
ğŸ“Š Focus styles: {
  outline: [32m'rgb(0, 95, 204) auto 1px'[39m,
  outlineColor: [32m'rgb(0, 95, 204)'[39m,
  outlineWidth: [32m'1px'[39m,
  boxShadow: [32m'none'[39m,
  border: [32m'0px none rgb(10, 10, 15)'[39m
}
âœ… Focus indicators are visible
ğŸ“Š Test 3: Testing text scalability...
ğŸ“Š Original text sizes: [
  { fontSize: [32m'14px'[39m, lineHeight: [32m'normal'[39m },
  { fontSize: [32m'14px'[39m, lineHeight: [32m'normal'[39m },
  { fontSize: [32m'14px'[39m, lineHeight: [32m'normal'[39m }
]
ğŸ“Š Scaled text sizes: [
  { fontSize: [32m'19.2px'[39m, lineHeight: [32m'normal'[39m },
  { fontSize: [32m'19.2px'[39m, lineHeight: [32m'normal'[39m },
  { fontSize: [32m'19.2px'[39m, lineHeight: [32m'normal'[39m }
]
âœ… Text scalability tested
âœ… Color contrast test completed
  âœ“  4 tests/accessibility_ui_ux.spec.ts:274:7 â€º Accessibility and UI/UX â€º Color contrast and visual accessibility (2.2s)
ğŸš€ Starting user workflow usability test...
ğŸ“Š Test 1: Testing agent creation workflow...
ğŸ“Š Mobile layout: {
  bodyWidth: [33m375[39m,
  hasHorizontalScroll: [33mtrue[39m,
  navigationVisible: [33mfalse[39m,
  mainContentVisible: [33mfalse[39m
}
âš ï¸  Page has horizontal scroll on mobile
ğŸ“Š Test 2: Testing tablet viewport...
ğŸ“Š Tablet layout: { bodyWidth: [33m768[39m, hasHorizontalScroll: [33mfalse[39m }
ğŸ“Š Test 3: Testing desktop viewport...
ğŸ“Š Desktop layout: { bodyWidth: [33m1920[39m, hasHorizontalScroll: [33mfalse[39m }
ğŸ“Š Test 4: Testing touch interactions...
ğŸ“Š Touchable elements: [33m18[39m
ğŸ“Š Touch target sizes: [
  { width: [33m114.46875[39m, height: [33m23[39m, area: [33m2632.78125[39m },
  { width: [33m109.75[39m, height: [33m30[39m, area: [33m3292.5[39m },
  { width: [33m27.734375[39m, height: [33m22[39m, area: [33m610.15625[39m },
  { width: [33m148.96875[39m, height: [33m43[39m, area: [33m6405.65625[39m },
  { width: [33m127.9375[39m, height: [33m43[39m, area: [33m5501.3125[39m }
]
ğŸ“Š Adequate touch targets (44x44px+): [33m0[39m
âœ… Responsive design test completed
  âœ“  5 tests/accessibility_ui_ux.spec.ts:372:7 â€º Accessibility and UI/UX â€º Responsive design and mobile compatibility (2.5s)
ğŸ” Starting complete agent creation test...
ğŸ“Š Worker ID: 0
ğŸ“Š Step 0: Resetting database...
[2m[WebServer] [22mWARNING - Resetting database - dropping all tables
âœ… Database reset successful
ğŸ“Š Step 1: Verifying empty state...
ğŸ“Š Initial agent count: [33m0[39m
ğŸ“Š Step 2: Creating agent via API...
ğŸ“Š Agent creation status: [33m201[39m
ğŸ“Š Created agent ID: [33m1[39m
ğŸ“Š Created agent name: Test Agent Worker 0
ğŸ“Š Step 3: Verifying agent appears in list...
ğŸ“Š Updated agent count: [33m1[39m
âœ… Agent found in list with correct data
ğŸ“Š Step 5: Testing UI integration...
ğŸ“Š Create buttons found: [33m2[39m
ğŸ“Š Test agent created: [33m2[39m
ğŸ“Š Agent visible in dashboard: [33mfalse[39m
ğŸ“Š Canvas workflow elements: { canvas: [33m0[39m, agentShelf: [33m0[39m, toolPalette: [33m0[39m }
ğŸ“Š User workflow steps completed: [33m3[39m
ğŸ“Š Total workflow time: [33m1640[39m ms
ğŸ“Š Average step time: [33m547[39m ms
âœ… User workflow is responsive
ğŸ“Š Test 2: Testing error recovery...
ğŸ“Š Agent visible in UI: [33mtrue[39m
âœ… Agent successfully appears in UI
ğŸ“Š Step 6: Creating second agent for isolation test...
ğŸ“Š Second agent created with ID: [33m3[39m
ğŸ“Š Step 7: Verifying agent isolation...
ğŸ“Š Final agent count: [33m3[39m
ğŸ“Š Worker-specific agent count: [33m2[39m
âœ… Complete agent creation and isolation test passed!
  âœ“  7 tests/agent_creation_full.spec.ts:15:7 â€º Agent Creation Full Workflow â€º Complete agent creation and isolation test (4.4s)
ğŸš€ Starting complete canvas workflow test...
ğŸ“Š Worker ID: 0
ğŸ“Š Step 1: Creating test agent...
âœ… Test agent created with ID: [33m4[39m
ğŸ“Š Step 2: Navigating to application...
ğŸ“Š Recovery elements found: [33m0[39m
âœ… User workflow usability test completed
  âœ“  6 tests/accessibility_ui_ux.spec.ts:467:7 â€º Accessibility and UI/UX â€º User workflow usability testing (6.6s)
ğŸ” Starting comprehensive debug test...
ğŸ“Š Worker ID: 1
ğŸ“Š NODE_ENV: test
ğŸ” Test 1: Basic connectivity
ğŸ“Š Basic connectivity status: [33m200[39m
âœ… Backend is accessible
ğŸ” Test 2: Header transmission
ğŸ“Š Header transmission status: [33m200[39m
âœ… Headers can be sent
ğŸ” Test 3: Agent GET endpoint
ğŸ“Š Agent GET status: [33m200[39m
ğŸ“Š Agent GET count: [33m1[39m
âœ… Agent GET endpoint working
ğŸ” Test 4: Testing different database operations
ğŸ“Š Testing user endpoint...
ğŸ“Š User endpoint status: [33m200[39m
ğŸ“Š User data available: [33mtrue[39m
ğŸ” Test 5: Workflow creation test
ğŸ“Š Workflow creation status: [33m422[39m
âŒ Workflow creation failed: {"detail":[{"type":"missing","loc":["body","canvas_data"],"msg":"Field required","input":{"name":"Test Workflow 1","description":"Test workflow for debugging"}}]}
ğŸ” Test 6: Minimal agent creation
ğŸ“Š Minimal agent creation status: [33m201[39m
ğŸ“Š Minimal agent created ID: [33m2[39m
âœ… Agent creation working with mock model
ğŸ” Test 7: Database introspection
ğŸ“Š System health status: [33m404[39m
âœ… Comprehensive debug test complete
  âœ“  9 tests/comprehensive_debug.spec.ts:15:7 â€º Comprehensive Debug â€º Complete system debug and diagnosis (365ms)
ğŸš€ Starting data persistence test...
ğŸ“Š Worker ID: 0
ğŸ“Š Step 0: Resetting database...
[2m[WebServer] [22mWARNING - Resetting database - dropping all tables
âœ… Database reset successful
ğŸ“Š Test 1: Creating persistent data...
ğŸ“Š Created agent ID: [33m5[39m
ğŸ“Š Step 3: Verifying agent in dashboard...
ğŸ“Š Agent visible in dashboard: [33mtrue[39m
ğŸ“Š Step 4: Navigating to canvas...
ğŸ“Š Canvas visible: [33mfalse[39m
âœ… Complete canvas workflow test finished
ğŸ“Š Summary: Basic navigation and UI structure validated
ğŸ“Š Next: UI implementation needed for full drag-and-drop workflow
  âœ“  8 tests/canvas_complete_workflow.spec.ts:17:7 â€º Complete Canvas Workflow â€º End-to-end canvas workflow with agent and tool execution (5.6s)
ğŸš€ Starting auto-save test...
ğŸ“Š Test 1: Looking for auto-save functionality...
ğŸ“Š Form elements found: [33m8[39m
ğŸ“Š Auto-save indicators: [33m0[39m
ğŸ“Š Test 2: Testing data recovery after refresh...
ğŸ“Š Visible input fields found: [33m0[39m
ğŸ“Š No visible input fields found for draft recovery test
âœ… Auto-save test completed
  âœ“  11 tests/data_persistence_recovery.spec.ts:145:7 â€º Data Persistence and Recovery â€º Auto-save and draft recovery (1.4s)
ğŸš€ Starting data consistency test...
ğŸ“Š Test 1: Testing data relationships...
ğŸ“Š Created agent for consistency test: [33m6[39m
ğŸ“Š Created workflow with agent reference: [33m2[39m
ğŸ“Š Test 2: Testing data integrity...
ğŸ“Š Initial agent count: [33m6[39m
ğŸ“Š After creation agent count: [33m7[39m
âœ… Data integrity maintained during operations
âœ… Data consistency test completed
  âœ“  12 tests/data_persistence_recovery.spec.ts:218:7 â€º Data Persistence and Recovery â€º Data consistency and integrity (681ms)
ğŸš€ Starting export/import test...
ğŸ“Š Test 1: Looking for export functionality...
ğŸ“Š Agent row visible in UI: [33mfalse[39m
ğŸ“Š Agent name visible in UI: [33mfalse[39m
ğŸ“Š Agent in table by name: [33mfalse[39m
ğŸ“Š Any agents visible in table: [33mtrue[39m
ğŸ“Š Test 2: Simulating session restart...
ğŸ“Š Export buttons found: [33m0[39m
ğŸ“Š Download buttons found: [33m0[39m
ğŸ“Š Backup buttons found: [33m0[39m
ğŸ“Š No export UI elements found (may be in different location)
ğŸ“Š Test 2: Looking for import functionality...
ğŸ“Š Import buttons found: [33m0[39m
ğŸ“Š Upload buttons found: [33m0[39m
ğŸ“Š File inputs found: [33m0[39m
ğŸ“Š No import UI elements found (may be in different location)
ğŸ“Š Test 3: API data integrity verification...
ğŸ“Š Created test agent for export: [33m8[39m
ğŸ“Š Data integrity on retrieval: [33mtrue[39m
âœ… Data maintains integrity during storage/retrieval
âœ… Export/import test completed
  âœ“  13 tests/data_persistence_recovery.spec.ts:339:7 â€º Data Persistence and Recovery â€º Data export and import integrity (1.4s)
ğŸš€ Starting data corruption recovery test...
ğŸ“Š Test 1: Invalid data format recovery...
ğŸ“Š Corrupt data response status: [33m422[39m
âœ… Invalid data properly rejected
ğŸ“Š Error details provided: [33mtrue[39m
ğŸ“Š Test 2: System state recovery...
ğŸ“Š Recovery creation status: [33m201[39m
âœ… System recovered and accepts valid data after corruption attempt
ğŸ“Š Test 3: UI state recovery...
ğŸ“Š UI loaded successfully: [33mtrue[39m
ğŸ“Š UI error count: [33m0[39m
âœ… UI recovered successfully
âœ… Data corruption recovery test completed
  âœ“  14 tests/data_persistence_recovery.spec.ts:429:7 â€º Data Persistence and Recovery â€º Recovery from data corruption scenarios (1.5s)
ğŸš€ Starting API error handling test...
ğŸ“Š Worker ID: 0
ğŸ“Š Test 1: Invalid agent creation - missing fields
ğŸ“Š Invalid agent creation status: [33m422[39m
ğŸ“Š Validation error structure: [33mtrue[39m
âœ… Validation errors properly returned
ğŸ“Š Test 2: Invalid JSON payload
ğŸ“Š Invalid JSON status: [33m422[39m
âœ… Invalid JSON properly rejected
ğŸ“Š Test 3: Large payload handling
ğŸ“Š Large payload status: [33m201[39m
âœ… Large payload accepted (system handles large data)
ğŸ“Š Test 4: Invalid HTTP methods
ğŸ“Š Invalid method status: [33m405[39m
âœ… Invalid HTTP methods properly rejected
ğŸ“Š Test 5: Non-existent resource access
ğŸ“Š Non-existent resource status: [33m404[39m
âœ… Non-existent resources return 404
âœ… API error handling test completed
  âœ“  15 tests/error_handling_edge_cases.spec.ts:18:7 â€º Error Handling and Edge Cases â€º API error handling with invalid data (47ms)
ğŸš€ Starting database constraint test...
ğŸ“Š Test 1: Duplicate name handling
ğŸ“Š First agent created: [33m11[39m
ğŸ“Š Duplicate creation status: [33m201[39m
âœ… Duplicate names allowed (system permits duplicates)
ğŸ“Š Test 2: Field length validation
ğŸ“Š Long field status: [33m201[39m
âœ… Long fields accepted (no length limits)
âœ… Database constraint test completed
  âœ“  16 tests/error_handling_edge_cases.spec.ts:126:7 â€º Error Handling and Edge Cases â€º Database constraint and data integrity (38ms)
ğŸš€ Starting concurrency test...
ğŸ“Š Test 1: Concurrent agent creation
ğŸ“Š Concurrent creation success: [33m5[39m
ğŸ“Š Concurrent creation errors: [33m0[39m
âœ… Concurrent operations handled well
ğŸ“Š Test 2: Rapid-fire GET requests
ğŸ“Š Rapid requests success: [33m10[39m
âœ… Rapid requests handled well
âœ… Concurrency test completed
  âœ“  17 tests/error_handling_edge_cases.spec.ts:201:7 â€º Error Handling and Edge Cases â€º Concurrent operations and race conditions (678ms)
ğŸš€ Starting UI error state test...
ğŸ“Š Test 1: Network connectivity simulation
ğŸ“Š Error indicators found: [33m0[39m
âœ… Network connectivity simulation completed
ğŸ“Š Test 2: Invalid navigation handling
ğŸ“Š Agent persisted in database: [33mtrue[39m
ğŸ“Š Total agents in database: [33m18[39m
ğŸ“Š Agent visible after restart: [33mfalse[39m
âš ï¸  Agent exists in DB but not visible in UI - checking table rows...
ğŸ“Š Table rows count: [33m1[39m
âœ… Data persistence test completed
  âœ“  10 tests/data_persistence_recovery.spec.ts:19:7 â€º Data Persistence and Recovery â€º Data persistence across sessions (14.0s)
ğŸš€ Starting multi-user data isolation test...
ğŸ“Š Created 3 user sessions
ğŸ“Š Test 1: Creating isolated data per user...
ğŸ“Š Invalid route page title: AI Agent Platform
ğŸ“Š Error content present: [33mfalse[39m
ğŸ“Š Test 3: JavaScript error monitoring
ğŸ“Š User 0 created agent: [33m1[39m
ğŸ“Š User 2 created agent: [33m1[39m
ğŸ“Š User 1 created agent: [33m1[39m
ğŸ“Š Successful agent creations: [33m3[39m / [33m3[39m
ğŸ“Š Test 2: Verifying data isolation...
ğŸ“Š User 0 sees own agent: [33mtrue[39m
ğŸ“Š User 0 sees other users' agents: [33mtrue[39m
ğŸ“Š User 1 sees own agent: [33mtrue[39m
ğŸ“Š User 1 sees other users' agents: [33mtrue[39m
ğŸ“Š User 2 sees own agent: [33mtrue[39m
ğŸ“Š User 2 sees other users' agents: [33mtrue[39m
ğŸ“Š Users with proper data isolation: [33m0[39m / [33m3[39m
âš ï¸  Data isolation may need improvement
âœ… Multi-user data isolation test completed
  âœ“  19 tests/multi_user_concurrency.spec.ts:18:7 â€º Multi-User and Concurrency â€º Multiple user sessions with data isolation (2.1s)
ğŸš€ Starting concurrent workflow execution test...
ğŸ“Š Created 3 workflow sessions
ğŸ“Š Test 1: Creating workflows concurrently...
ğŸ“Š User 0 created workflow: [33m1[39m
ğŸ“Š User 1 created workflow: [33m1[39m
ğŸ“Š User 2 created workflow: [33m1[39m
ğŸ“Š Successful workflow creations: [33m3[39m / [33m3[39m
ğŸ“Š Concurrent workflow creation time: [33m319[39m ms
ğŸ“Š Test 2: Executing workflows concurrently...
[2m[WebServer] [22mERROR - [AgentRunner] Exception during runnable.ainvoke: Error code: 404 - {'error': {'message': 'The model `gpt-mock` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
[2m[WebServer] [22mTraceback (most recent call last):
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/managers/agent_runner.py", line 137, in run_thread
[2m[WebServer] [22m    updated_messages = await self._runnable.ainvoke(original_msgs, config)
[2m[WebServer] [22m                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2850, in ainvoke
[2m[WebServer] [22m    async for chunk in self.astream(
[2m[WebServer] [22m    ...<13 lines>...
[2m[WebServer] [22m            chunks.append(chunk)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2732, in astream
[2m[WebServer] [22m    async for _ in runner.atick(
[2m[WebServer] [22m    ...<7 lines>...
[2m[WebServer] [22m            yield o
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 256, in agent_executor
[2m[WebServer] [22m    return _agent_executor_sync(messages, previous=previous)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 248, in _agent_executor_sync
[2m[WebServer] [22m    return asyncio.run(_agent_executor_async(messages, previous=previous))
[2m[WebServer] [22m           ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/runners.py", line 194, in run
[2m[WebServer] [22m    return runner.run(main)
[2m[WebServer] [22m           ~~~~~~~~~~^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/runners.py", line 118, in run
[2m[WebServer] [22m    return self._loop.run_until_complete(task)
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/base_events.py", line 720, in run_until_complete
[2m[WebServer] [22m    return future.result()
[2m[WebServer] [22m           ~~~~~~~~~~~~~^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 208, in _agent_executor_async
[2m[WebServer] [22m    llm_response = await _call_model_async(current_messages)
[2m[WebServer] [22m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 134, in _call_model_async
[2m[WebServer] [22m    return await asyncio.to_thread(_call_model_sync, messages)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/threads.py", line 25, in to_thread
[2m[WebServer] [22m    return await loop.run_in_executor(None, func_call)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/thread.py", line 59, in run
[2m[WebServer] [22m    result = self.fn(*self.args, **self.kwargs)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 127, in _call_model_sync
[2m[WebServer] [22m    return llm_with_tools.invoke(messages)
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/runnables/base.py", line 5416, in invoke
[2m[WebServer] [22m    return self.bound.invoke(
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        input,
[2m[WebServer] [22m        ^^^^^^
[2m[WebServer] [22m        self._merge_configs(config),
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m        **{**self.kwargs, **kwargs},
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 369, in invoke
[2m[WebServer] [22m    self.generate_prompt(
[2m[WebServer] [22m    ~~~~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        [self._convert_input(input)],
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<6 lines>...
[2m[WebServer] [22m        **kwargs,
[2m[WebServer] [22m        ^^^^^^^^^
[2m[WebServer] [22m    ).generations[0][0],
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 946, in generate_prompt
[2m[WebServer] [22m    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
[2m[WebServer] [22m           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 765, in generate
[2m[WebServer] [22m    self._generate_with_cache(
[2m[WebServer] [22m    ~~~~~~~~~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        m,
[2m[WebServer] [22m        ^^
[2m[WebServer] [22m    ...<2 lines>...
[2m[WebServer] [22m        **kwargs,
[2m[WebServer] [22m        ^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 1011, in _generate_with_cache
[2m[WebServer] [22m    result = self._generate(
[2m[WebServer] [22m        messages, stop=stop, run_manager=run_manager, **kwargs
[2m[WebServer] [22m    )
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py", line 956, in _generate
[2m[WebServer] [22m    return generate_from_stream(stream_iter)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 153, in generate_from_stream
[2m[WebServer] [22m    generation = next(stream, None)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py", line 907, in _stream
[2m[WebServer] [22m    response = self.client.create(**payload)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_utils/_utils.py", line 287, in wrapper
[2m[WebServer] [22m    return func(*args, **kwargs)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py", line 925, in create
[2m[WebServer] [22m    return self._post(
[2m[WebServer] [22m           ~~~~~~~~~~^
[2m[WebServer] [22m        "/chat/completions",
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<43 lines>...
[2m[WebServer] [22m        stream_cls=Stream[ChatCompletionChunk],
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_base_client.py", line 1239, in post
[2m[WebServer] [22m    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
[2m[WebServer] [22m                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_base_client.py", line 1034, in request
[2m[WebServer] [22m    raise self._make_status_error_from_response(err.response) from None
[2m[WebServer] [22mopenai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `gpt-mock` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
[2m[WebServer] [22mDuring task with name 'agent_executor' and id 'a3a61c4f-842b-ea8f-7f56-45a175cacb1e'
[2m[WebServer] [22mERROR - [AgentNode] Exception in agent node agent-1 (agent_id=1): Error code: 404 - {'error': {'message': 'The model `gpt-mock` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
[2m[WebServer] [22mTraceback (most recent call last):
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/services/langgraph_workflow_engine.py", line 729, in agent_node
[2m[WebServer] [22m    created_messages = await runner.run_thread(db, thread)
[2m[WebServer] [22m                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/managers/agent_runner.py", line 137, in run_thread
[2m[WebServer] [22m    updated_messages = await self._runnable.ainvoke(original_msgs, config)
[2m[WebServer] [22m                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2850, in ainvoke
[2m[WebServer] [22m    async for chunk in self.astream(
[2m[WebServer] [22m    ...<13 lines>...
[2m[WebServer] [22m            chunks.append(chunk)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2732, in astream
[2m[WebServer] [22m    async for _ in runner.atick(
[2m[WebServer] [22m    ...<7 lines>...
[2m[WebServer] [22m            yield o
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 256, in agent_executor
[2m[WebServer] [22m    return _agent_executor_sync(messages, previous=previous)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 248, in _agent_executor_sync
[2m[WebServer] [22m    return asyncio.run(_agent_executor_async(messages, previous=previous))
[2m[WebServer] [22m           ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/runners.py", line 194, in run
[2m[WebServer] [22m    return runner.run(main)
[2m[WebServer] [22m           ~~~~~~~~~~^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/runners.py", line 118, in run
[2m[WebServer] [22m    return self._loop.run_until_complete(task)
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/base_events.py", line 720, in run_until_complete
[2m[WebServer] [22m    return future.result()
[2m[WebServer] [22m           ~~~~~~~~~~~~~^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 208, in _agent_executor_async
[2m[WebServer] [22m    llm_response = await _call_model_async(current_messages)
[2m[WebServer] [22m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 134, in _call_model_async
[2m[WebServer] [22m    return await asyncio.to_thread(_call_model_sync, messages)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/threads.py", line 25, in to_thread
[2m[WebServer] [22m    return await loop.run_in_executor(None, func_call)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/thread.py", line 59, in run
[2m[WebServer] [22m    result = self.fn(*self.args, **self.kwargs)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 127, in _call_model_sync
[2m[WebServer] [22m    return llm_with_tools.invoke(messages)
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/runnables/base.py", line 5416, in invoke
[2m[WebServer] [22m    return self.bound.invoke(
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        input,
[2m[WebServer] [22m        ^^^^^^
[2m[WebServer] [22m        self._merge_configs(config),
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m        **{**self.kwargs, **kwargs},
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 369, in invoke
[2m[WebServer] [22m    self.generate_prompt(
[2m[WebServer] [22m    ~~~~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        [self._convert_input(input)],
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<6 lines>...
[2m[WebServer] [22m        **kwargs,
[2m[WebServer] [22m        ^^^^^^^^^
[2m[WebServer] [22m    ).generations[0][0],
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 946, in generate_prompt
[2m[WebServer] [22m    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
[2m[WebServer] [22m           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 765, in generate
[2m[WebServer] [22m    self._generate_with_cache(
[2m[WebServer] [22m    ~~~~~~~~~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        m,
[2m[WebServer] [22m        ^^
[2m[WebServer] [22m    ...<2 lines>...
[2m[WebServer] [22m        **kwargs,
[2m[WebServer] [22m        ^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 1011, in _generate_with_cache
[2m[WebServer] [22m    result = self._generate(
[2m[WebServer] [22m        messages, stop=stop, run_manager=run_manager, **kwargs
[2m[WebServer] [22m    )
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py", line 956, in _generate
[2m[WebServer] [22m    return generate_from_stream(stream_iter)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 153, in generate_from_stream
[2m[WebServer] [22m    generation = next(stream, None)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py", line 907, in _stream
[2m[WebServer] [22m    response = self.client.create(**payload)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_utils/_utils.py", line 287, in wrapper
[2m[WebServer] [22m    return func(*args, **kwargs)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py", line 925, in create
[2m[WebServer] [22m    return self._post(
[2m[WebServer] [22m           ~~~~~~~~~~^
[2m[WebServer] [22m        "/chat/completions",
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<43 lines>...
[2m[WebServer] [22m        stream_cls=Stream[ChatCompletionChunk],
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_base_client.py", line 1239, in post
[2m[WebServer] [22m    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
[2m[WebServer] [22m                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_base_client.py", line 1034, in request
[2m[WebServer] [22m    raise self._make_status_error_from_response(err.response) from None
[2m[WebServer] [22mopenai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `gpt-mock` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
[2m[WebServer] [22mDuring task with name 'agent_executor' and id 'a3a61c4f-842b-ea8f-7f56-45a175cacb1e'
[2m[WebServer] [22mERROR - [AgentNode] Updated node_state to 'failed' in DB
[2m[WebServer] [22mERROR - [AgentNode] Re-raising exception to fail workflow execution
[2m[WebServer] [22mERROR - [LangGraphEngine] Execution failed â€“ execution_id=1
[2m[WebServer] [22mTraceback (most recent call last):
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/services/langgraph_workflow_engine.py", line 146, in execute_workflow
[2m[WebServer] [22m    await self._execute_workflow_internal(workflow, execution, db)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/services/langgraph_workflow_engine.py", line 214, in _execute_workflow_internal
[2m[WebServer] [22m    async for chunk in graph.astream(initial_state, config):
[2m[WebServer] [22m    ...<36 lines>...
[2m[WebServer] [22m            logger.warning(f"[LangGraphEngine] Received empty chunk #{chunk_count}")
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2732, in astream
[2m[WebServer] [22m    async for _ in runner.atick(
[2m[WebServer] [22m    ...<7 lines>...
[2m[WebServer] [22m            yield o
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/services/langgraph_workflow_engine.py", line 729, in agent_node
[2m[WebServer] [22m    created_messages = await runner.run_thread(db, thread)
[2m[WebServer] [22m                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/managers/agent_runner.py", line 137, in run_thread
[2m[WebServer] [22m    updated_messages = await self._runnable.ainvoke(original_msgs, config)
[2m[WebServer] [22m                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2850, in ainvoke
[2m[WebServer] [22m    async for chunk in self.astream(
[2m[WebServer] [22m    ...<13 lines>...
[2m[WebServer] [22m            chunks.append(chunk)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2732, in astream
[2m[WebServer] [22m    async for _ in runner.atick(
[2m[WebServer] [22m    ...<7 lines>...
[2m[WebServer] [22m            yield o
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 256, in agent_executor
[2m[WebServer] [22m    return _agent_executor_sync(messages, previous=previous)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 248, in _agent_executor_sync
[2m[WebServer] [22m    return asyncio.run(_agent_executor_async(messages, previous=previous))
[2m[WebServer] [22m           ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/runners.py", line 194, in run
[2m[WebServer] [22m    return runner.run(main)
[2m[WebServer] [22m           ~~~~~~~~~~^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/runners.py", line 118, in run
[2m[WebServer] [22m    return self._loop.run_until_complete(task)
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/base_events.py", line 720, in run_until_complete
[2m[WebServer] [22m    return future.result()
[2m[WebServer] [22m           ~~~~~~~~~~~~~^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 208, in _agent_executor_async
[2m[WebServer] [22m    llm_response = await _call_model_async(current_messages)
[2m[WebServer] [22m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 134, in _call_model_async
[2m[WebServer] [22m    return await asyncio.to_thread(_call_model_sync, messages)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/threads.py", line 25, in to_thread
[2m[WebServer] [22m    return await loop.run_in_executor(None, func_call)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/thread.py", line 59, in run
[2m[WebServer] [22m    result = self.fn(*self.args, **self.kwargs)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 127, in _call_model_sync
[2m[WebServer] [22m    return llm_with_tools.invoke(messages)
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/runnables/base.py", line 5416, in invoke
[2m[WebServer] [22m    return self.bound.invoke(
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        input,
[2m[WebServer] [22m        ^^^^^^
[2m[WebServer] [22m        self._merge_configs(config),
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m        **{**self.kwargs, **kwargs},
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 369, in invoke
[2m[WebServer] [22m    self.generate_prompt(
[2m[WebServer] [22m    ~~~~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        [self._convert_input(input)],
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<6 lines>...
[2m[WebServer] [22m        **kwargs,
[2m[WebServer] [22m        ^^^^^^^^^
[2m[WebServer] [22m    ).generations[0][0],
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 946, in generate_prompt
[2m[WebServer] [22m    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
[2m[WebServer] [22m           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 765, in generate
[2m[WebServer] [22m    self._generate_with_cache(
[2m[WebServer] [22m    ~~~~~~~~~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        m,
[2m[WebServer] [22m        ^^
[2m[WebServer] [22m    ...<2 lines>...
[2m[WebServer] [22m        **kwargs,
[2m[WebServer] [22m        ^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 1011, in _generate_with_cache
[2m[WebServer] [22m    result = self._generate(
[2m[WebServer] [22m        messages, stop=stop, run_manager=run_manager, **kwargs
[2m[WebServer] [22m    )
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py", line 956, in _generate
[2m[WebServer] [22m    return generate_from_stream(stream_iter)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 153, in generate_from_stream
[2m[WebServer] [22m    generation = next(stream, None)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py", line 907, in _stream
[2m[WebServer] [22m    response = self.client.create(**payload)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_utils/_utils.py", line 287, in wrapper
[2m[WebServer] [22m    return func(*args, **kwargs)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py", line 925, in create
[2m[WebServer] [22m    return self._post(
[2m[WebServer] [22m           ~~~~~~~~~~^
[2m[WebServer] [22m        "/chat/completions",
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<43 lines>...
[2m[WebServer] [22m        stream_cls=Stream[ChatCompletionChunk],
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_base_client.py", line 1239, in post
[2m[WebServer] [22m    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
[2m[WebServer] [22m                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_base_client.py", line 1034, in request
[2m[WebServer] [22m    raise self._make_status_error_from_response(err.response) from None
[2m[WebServer] [22mopenai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `gpt-mock` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
[2m[WebServer] [22mDuring task with name 'agent_executor' and id 'a3a61c4f-842b-ea8f-7f56-45a175cacb1e'
[2m[WebServer] [22mDuring task with name 'agent-1' and id '1e1253aa-7a76-fc74-67e5-ce645c840031'
[2m[WebServer] [22mERROR - Unhandled exception: Error code: 404 - {'error': {'message': 'The model `gpt-mock` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
[2m[WebServer] [22mTraceback (most recent call last):
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/middleware/errors.py", line 165, in __call__
[2m[WebServer] [22m    await self.app(scope, receive, _send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/middleware/worker_db.py", line 101, in __call__
[2m[WebServer] [22m    await self.app(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/middleware/cors.py", line 85, in __call__
[2m[WebServer] [22m    await self.app(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/middleware/exceptions.py", line 62, in __call__
[2m[WebServer] [22m    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
[2m[WebServer] [22m    raise exc
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
[2m[WebServer] [22m    await app(scope, receive, sender)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/routing.py", line 714, in __call__
[2m[WebServer] [22m    await self.middleware_stack(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/routing.py", line 734, in app
[2m[WebServer] [22m    await route.handle(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/routing.py", line 288, in handle
[2m[WebServer] [22m    await self.app(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/routing.py", line 76, in app
[2m[WebServer] [22m    await wrap_app_handling_exceptions(app, request)(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
[2m[WebServer] [22m    raise exc
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
[2m[WebServer] [22m    await app(scope, receive, sender)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/routing.py", line 73, in app
[2m[WebServer] [22m    response = await f(request)
[2m[WebServer] [22m               ^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/fastapi/routing.py", line 301, in app
[2m[WebServer] [22m    raw_response = await run_endpoint_function(
[2m[WebServer] [22m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<3 lines>...
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/fastapi/routing.py", line 212, in run_endpoint_function
[2m[WebServer] [22m    return await dependant.call(**values)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/routers/workflow_executions.py", line 74, in start_workflow_execution
[2m[WebServer] [22m    execution_id = await langgraph_workflow_engine.execute_workflow(workflow_id)
[2m[WebServer] [22m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/services/langgraph_workflow_engine.py", line 146, in execute_workflow
[2m[WebServer] [22m    await self._execute_workflow_internal(workflow, execution, db)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/services/langgraph_workflow_engine.py", line 214, in _execute_workflow_internal
[2m[WebServer] [22m    async for chunk in graph.astream(initial_state, config):
[2m[WebServer] [22m    ...<36 lines>...
[2m[WebServer] [22m            logger.warning(f"[LangGraphEngine] Received empty chunk #{chunk_count}")
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2732, in astream
[2m[WebServer] [22m    async for _ in runner.atick(
[2m[WebServer] [22m    ...<7 lines>...
[2m[WebServer] [22m            yield o
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/services/langgraph_workflow_engine.py", line 729, in agent_node
[2m[WebServer] [22m    created_messages = await runner.run_thread(db, thread)
[2m[WebServer] [22m                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/managers/agent_runner.py", line 137, in run_thread
[2m[WebServer] [22m    updated_messages = await self._runnable.ainvoke(original_msgs, config)
[2m[WebServer] [22m                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2850, in ainvoke
[2m[WebServer] [22m    async for chunk in self.astream(
[2m[WebServer] [22m    ...<13 lines>...
[2m[WebServer] [22m            chunks.append(chunk)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2732, in astream
[2m[WebServer] [22m    async for _ in runner.atick(
[2m[WebServer] [22m    ...<7 lines>...
[2m[WebServer] [22m            yield o
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 256, in agent_executor
[2m[WebServer] [22m    return _agent_executor_sync(messages, previous=previous)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 248, in _agent_executor_sync
[2m[WebServer] [22m    return asyncio.run(_agent_executor_async(messages, previous=previous))
[2m[WebServer] [22m           ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/runners.py", line 194, in run
[2m[WebServer] [22m    return runner.run(main)
[2m[WebServer] [22m           ~~~~~~~~~~^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/runners.py", line 118, in run
[2m[WebServer] [22m    return self._loop.run_until_complete(task)
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/base_events.py", line 720, in run_until_complete
[2m[WebServer] [22m    return future.result()
[2m[WebServer] [22m           ~~~~~~~~~~~~~^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 208, in _agent_executor_async
[2m[WebServer] [22m    llm_response = await _call_model_async(current_messages)
[2m[WebServer] [22m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 134, in _call_model_async
[2m[WebServer] [22m    return await asyncio.to_thread(_call_model_sync, messages)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/threads.py", line 25, in to_thread
[2m[WebServer] [22m    return await loop.run_in_executor(None, func_call)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/thread.py", line 59, in run
[2m[WebServer] [22m    result = self.fn(*self.args, **self.kwargs)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 127, in _call_model_sync
[2m[WebServer] [22m    return llm_with_tools.invoke(messages)
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/runnables/base.py", line 5416, in invoke
[2m[WebServer] [22m    return self.bound.invoke(
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        input,
[2m[WebServer] [22m        ^^^^^^
[2m[WebServer] [22m        self._merge_configs(config),
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m        **{**self.kwargs, **kwargs},
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 369, in invoke
[2m[WebServer] [22m    self.generate_prompt(
[2m[WebServer] [22m    ~~~~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        [self._convert_input(input)],
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<6 lines>...
[2m[WebServer] [22m        **kwargs,
[2m[WebServer] [22m        ^^^^^^^^^
[2m[WebServer] [22m    ).generations[0][0],
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 946, in generate_prompt
[2m[WebServer] [22m    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
[2m[WebServer] [22m           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 765, [2m[WebServer] [22min generate
[2m[WebServer] [22m    self._generate_with_cache(
[2m[WebServer] [22m    ~~~~~~~~~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        m,
[2m[WebServer] [22m        ^^
[2m[WebServer] [22m    ...<2 lines>...
[2m[WebServer] [22m        **kwargs,
[2m[WebServer] [22m        ^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 1011, in _generate_with_cache
[2m[WebServer] [22m    result = self._generate(
[2m[WebServer] [22m        messages, stop=stop, run_manager=run_manager, **kwargs
[2m[WebServer] [22m    )
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py", line 956, in _generate
[2m[WebServer] [22m    return generate_from_stream(stream_iter)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 153, in generate_from_stream
[2m[WebServer] [22m    generation = next(stream, None)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py", line 907, in _stream
[2m[WebServer] [22m    response = self.client.create(**payload)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_utils/_utils.py", line 287, in wrapper
[2m[WebServer] [22m    return func(*args, **kwargs)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py", line 925, in create
[2m[WebServer] [22m    return self._post(
[2m[WebServer] [22m           ~~~~~~~~~~^
[2m[WebServer] [22m        "/chat/completions",
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<43 lines>...
[2m[WebServer] [22m        stream_cls=Stream[ChatCompletionChunk],
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_base_client.py", line 1239, in post
[2m[WebServer] [22m    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
[2m[WebServer] [22m                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_base_client.py", line 1034, in request
[2m[WebServer] [22m    raise self._make_status_error_from_response(err.response) from None
[2m[WebServer] [22mopenai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `gpt-mock` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
[2m[WebServer] [22mDuring task with name 'agent_executor' and id 'a3a61c4f-842b-ea8f-7f56-45a175cacb1e'
[2m[WebServer] [22mDuring task with name 'agent-1' and id '1e1253aa-7a76-fc74-67e5-ce645c840031'
âŒ User 2 execution failed: [33m500[39m
[2m[WebServer] [22mERROR:    Exception in ASGI application
[2m[WebServer] [22mTraceback (most recent call last):
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/uvicorn/protocols/http/h11_impl.py", line 408, in run_asgi
[2m[WebServer] [22m    result = await app(  # type: ignore[func-returns-value]
[2m[WebServer] [22m             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m        self.scope, self.receive, self.send
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/uvicorn/middleware/proxy_headers.py", line 84, in __call__
[2m[WebServer] [22m    return await self.app(scope, receive, send)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/fastapi/applications.py", line 1054, in __call__
[2m[WebServer] [22m    await super().__call__(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/applications.py", line 112, in __call__
[2m[WebServer] [22m    await self.middleware_stack(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/middleware/errors.py", line 187, in __call__
[2m[WebServer] [22m    raise exc
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/middleware/errors.py", line 165, in __call__
[2m[WebServer] [22m    await self.app(scope, receive, _send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/middleware/worker_db.py", line 101, in __call__
[2m[WebServer] [22m    await self.app(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/middleware/cors.py", line 85, in __call__
[2m[WebServer] [22m    await self.app(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/middleware/exceptions.py", line 62, in __call__
[2m[WebServer] [22m    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
[2m[WebServer] [22m    raise exc
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
[2m[WebServer] [22m    await app(scope, receive, sender)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/routing.py", line 714, in __call__
[2m[WebServer] [22m    await self.middleware_stack(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/routing.py", line 734, in app
[2m[WebServer] [22m    await route.handle(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/routing.py", line 288, in handle
[2m[WebServer] [22m    await self.app(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/routing.py", line 76, in app
[2m[WebServer] [22m    await wrap_app_handling_exceptions(app, request)(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
[2m[WebServer] [22m    raise exc
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
[2m[WebServer] [22m    await app(scope, receive, sender)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/routing.py", line 73, in app
[2m[WebServer] [22m    response = await f(request)
[2m[WebServer] [22m               ^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/fastapi/routing.py", line 301, in app
[2m[WebServer] [22m    raw_response = await run_endpoint_function(
[2m[WebServer] [22m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<3 lines>...
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/fastapi/routing.py", line 212, in run_endpoint_function
[2m[WebServer] [22m    return await dependant.call(**values)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/routers/workflow_executions.py", line 74, in start_workflow_execution
[2m[WebServer] [22m    execution_id = await langgraph_workflow_engine.execute_workflow(workflow_id)
[2m[WebServer] [22m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/services/langgraph_workflow_engine.py", line 146, in execute_workflow
[2m[WebServer] [22m    await self._execute_workflow_internal(workflow, execution, db)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/services/langgraph_workflow_engine.py", line 214, in _execute_workflow_internal
[2m[WebServer] [22m    async for chunk in graph.astream(initial_state, config):
[2m[WebServer] [22m    ...<36 lines>...
[2m[WebServer] [22m            logger.warning(f"[LangGraphEngine] Received empty chunk #{chunk_count}")
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2732, in astream
[2m[WebServer] [22m    async for _ in runner.atick(
[2m[WebServer] [22m    ...<7 lines>...
[2m[WebServer] [22m            yield o
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/services/langgraph_workflow_engine.py", line 729, in agent_node
[2m[WebServer] [22m    created_messages = await runner.run_thread(db, thread)
[2m[WebServer] [22m                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/managers/agent_runner.py", line 137, in run_thread
[2m[WebServer] [22m    updated_messages = await self._runnable.ainvoke(original_msgs, config)
[2m[WebServer] [22m                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2850, in ainvoke
[2m[WebServer] [22m    async for chunk in self.astream(
[2m[WebServer] [22m    ...<13 lines>...
[2m[WebServer] [22m            chunks.append(chunk)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2732, in astream
[2m[WebServer] [22m    async for _ in runner.atick(
[2m[WebServer] [22m    ...<7 lines>...
[2m[WebServer] [22m            yield o
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 256, in agent_executor
[2m[WebServer] [22m    return _agent_executor_sync(messages, previous=previous)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 248, in _agent_executor_sync
[2m[WebServer] [22m    return asyncio.run(_agent_executor_async(messages, previous=previous))
[2m[WebServer] [22m           ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/runners.py", line 194, in run
[2m[WebServer] [22m    return runner.run(main)
[2m[WebServer] [22m           ~~~~~~~~~~^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/runners.py", line 118, in run
[2m[WebServer] [22m    return self._loop.run_until_complete(task)
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/base_events.py", line 720, in run_until_complete
[2m[WebServer] [22m    return future.result()
[2m[WebServer] [22m           ~~~~~~~~~~~~~^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 208, in _agent_executor_async
[2m[WebServer] [22m    llm_response = await _call_model_async(current_messages)
[2m[WebServer] [22m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 134, in _call_model_async
[2m[WebServer] [22m    return await asyncio.to_thread(_call_model_sync, messages)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/threads.py", line 25, in to_thread
[2m[WebServer] [22m    return await loop.run_in_executor(None, func_call)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/thread.py", line 59, in run
[2m[WebServer] [22m    result = self.fn(*self.args, **self.kwargs)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 127, in _call_model_sync
[2m[WebServer] [22m    return llm_with_tools.invoke(messages)
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/runnables/base.py", line 5416, in invoke
[2m[WebServer] [22m    return self.bound.invoke(
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        input,
[2m[WebServer] [22m        ^^^^^^
[2m[WebServer] [22m        self._merge_configs(config),
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^[2m[WebServer] [22m^^^^^^^^^
[2m[WebServer] [22m        **{**self.kwargs, **kwargs},
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 369, in invoke
[2m[WebServer] [22m    self.generate_prompt(
[2m[WebServer] [22m    ~~~~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        [self._convert_input(input)],
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<6 lines>...
[2m[WebServer] [22m        **kwargs,
[2m[WebServer] [22m        ^^^^^^^^^
[2m[WebServer] [22m    ).generations[0][0],
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 946, in generate_prompt
[2m[WebServer] [22m    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
[2m[WebServer] [22m           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 765, in generate
[2m[WebServer] [22m    self._generate_with_cache(
[2m[WebServer] [22m    ~~~~~~~~~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        m,
[2m[WebServer] [22m        ^^
[2m[WebServer] [22m    ...<2 lines>...
[2m[WebServer] [22m        **kwargs,
[2m[WebServer] [22m        ^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 1011, in _generate_with_cache
[2m[WebServer] [22m    result = self._generate(
[2m[WebServer] [22m        messages, stop=stop, run_manager=run_manager, **kwargs
[2m[WebServer] [22m    )
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py", line 956, in _generate
[2m[WebServer] [22m    return generate_from_stream(stream_iter)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 153, in generate_from_stream
[2m[WebServer] [22m    generation = next(stream, None)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py", line 907, in _stream
[2m[WebServer] [22m    response = self.client.create(**payload)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_utils/_utils.py", line 287, in wrapper
[2m[WebServer] [22m    return func(*args, **kwargs)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py", line 925, in create
[2m[WebServer] [22m    return self._post(
[2m[WebServer] [22m           ~~~~~~~~~~^
[2m[WebServer] [22m        "/chat/completions",
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<43 lines>...
[2m[WebServer] [22m        stream_cls=Stream[ChatCompletionChunk],
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_base_client.py", line 1239, in post
[2m[WebServer] [22m    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
[2m[WebServer] [22m                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_base_client.py", line 1034, in request
[2m[WebServer] [22m    raise self._make_status_error_from_response(err.response) from None
[2m[WebServer] [22mopenai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `gpt-mock` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
[2m[WebServer] [22mDuring task with name 'agent_executor' and id 'a3a61c4f-842b-ea8f-7f56-45a175cacb1e'
[2m[WebServer] [22mDuring task with name 'agent-1' and id '1e1253aa-7a76-fc74-67e5-ce645c840031'
[2m[WebServer] [22mERROR - [AgentRunner] Exception during runnable.ainvoke: Error code: 404 - {'error': {'message': 'The model `gpt-mock` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
[2m[WebServer] [22mTraceback (most recent call last):
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/managers/agent_runner.py", line 137, in run_thread
[2m[WebServer] [22m    updated_messages = await self._runnable.ainvoke(original_msgs, config)
[2m[WebServer] [22m                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2850, in ainvoke
[2m[WebServer] [22m    async for chunk in self.astream(
[2m[WebServer] [22m    ...<13 lines>...
[2m[WebServer] [22m            chunks.append(chunk)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2732, in astream
[2m[WebServer] [22m    async for _ in runner.atick(
[2m[WebServer] [22m    ...<7 lines>...
[2m[WebServer] [22m            yield o
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 256, in agent_executor
[2m[WebServer] [22m    return _agent_executor_sync(messages, previous=previous)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 248, in _agent_executor_sync
[2m[WebServer] [22m    return asyncio.run(_agent_executor_async(messages, previous=previous))
[2m[WebServer] [22m           ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/runners.py", line 194, in run
[2m[WebServer] [22m    return runner.run(main)
[2m[WebServer] [22m           ~~~~~~~~~~^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/runners.py", line 118, in run
[2m[WebServer] [22m    return self._loop.run_until_complete(task)
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/base_events.py", line 720, in run_until_complete
[2m[WebServer] [22m    return future.result()
[2m[WebServer] [22m           ~~~~~~~~~~~~~^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 208, in _agent_executor_async
[2m[WebServer] [22m    llm_response = await _call_model_async(current_messages)
[2m[WebServer] [22m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 134, in _call_model_async
[2m[WebServer] [22m    return await asyncio.to_thread(_call_model_sync, messages)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/threads.py", line 25, in to_thread
[2m[WebServer] [22m    return await loop.run_in_executor(None, func_call)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/thread.py", line 59, in run
[2m[WebServer] [22m    result = self.fn(*self.args, **self.kwargs)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 127, in _call_model_sync
[2m[WebServer] [22m    return llm_with_tools.invoke(messages)
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/runnables/base.py", line 5416, in invoke
[2m[WebServer] [22m    return self.bound.invoke(
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        input,
[2m[WebServer] [22m        ^^^^^^
[2m[WebServer] [22m        self._merge_configs(config),
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m        **{**self.kwargs, **kwargs},
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 369, in invoke
[2m[WebServer] [22m    self.generate_prompt(
[2m[WebServer] [22m    ~~~~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        [self._convert_input(input)],
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<6 lines>...
[2m[WebServer] [22m        **kwargs,
[2m[WebServer] [22m        ^^^^^^^^^
[2m[WebServer] [22m    ).generations[0][0],
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 946, in generate_prompt
[2m[WebServer] [22m    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
[2m[WebServer] [22m           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 765, in generate
[2m[WebServer] [22m    self._generate_with_cache(
[2m[WebServer] [22m    ~~~~~~~~~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        m,
[2m[WebServer] [22m        ^^
[2m[WebServer] [22m    ...<2 lines>...
[2m[WebServer] [22m        **kwargs,
[2m[WebServer] [22m        ^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 1011, in _generate_with_cache
[2m[WebServer] [22m    result = self._generate(
[2m[WebServer] [22m        messages, stop=stop, run_manager=run_manager, **kwargs
[2m[WebServer] [22m    )
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py", line 956, in _generate
[2m[WebServer] [22m    return generate_from_stream(stream_iter)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 153, in generate_from_stream
[2m[WebServer] [22m    generation = next(stream, None)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py", line 907, in _stream
[2m[WebServer] [22m    response = self.client.create(**payload)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_utils/_utils.py", line 287, in wrapper
[2m[WebServer] [22m    return func(*args, **kwargs)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py", line 925, in create
[2m[WebServer] [22m    return self._post(
[2m[WebServer] [22m           ~~~~~~~~~~^
[2m[WebServer] [22m        "/chat/completions",
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<43 lines>...
[2m[WebServer] [22m        stream_cls=Stream[ChatCompletionChunk],
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_base_client.py", line 1239, in post
[2m[WebServer] [22m    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
[2m[WebServer] [22m                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_base_client.py", line 1034, in request
[2m[WebServer] [22m    raise self._make_status_error_from_response(err.response) from None
[2m[WebServer] [22mopenai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `gpt-mock` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
[2m[WebServer] [22mDuring task with name 'agent_executor' and id '4d2c0759-78ed-fa70-cbb8-1022469f115a'
[2m[WebServer] [22mERROR - [AgentNode] Exception in agent node agent-1 (agent_id=1): Error code: 404 - {'error': {'message': 'The model `gpt-mock` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
[2m[WebServer] [22mTraceback (most recent call last):
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/services/langgraph_workflow_engine.py", line 729, in agent_node
[2m[WebServer] [22m    created_messages = await runner.run_thread(db, thread)
[2m[WebServer] [22m                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/managers/agent_runner.py", line 137, in run_thread
[2m[WebServer] [22m    updated_messages = await self._runnable.ainvoke(original_msgs, config)
[2m[WebServer] [22m                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2850, in ainvoke
[2m[WebServer] [22m    async for chunk in self.astream(
[2m[WebServer] [22m    ...<13 lines>...
[2m[WebServer] [22m            chunks.append(chunk)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2732, in astream
[2m[WebServer] [22m    async for _ in runner.atick(
[2m[WebServer] [22m    ...<7 lines>...
[2m[WebServer] [22m            yield o
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 256, in agent_executor
[2m[WebServer] [22m    return _agent_executor_sync(messages, previous=previous)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 248, in _agent_executor_sync
[2m[WebServer] [22m    return asyncio.run(_agent_executor_async(messages, previous=previous))
[2m[WebServer] [22m           ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/runners.py", line 194, in run
[2m[WebServer] [22m    return runner.run(main)
[2m[WebServer] [22m           ~~~~~~~~~~^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/runners.py", line 118, in run
[2m[WebServer] [22m    return self._loop.run_until_complete(task)
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/base_events.py", line 720, in run_until_complete
[2m[WebServer] [22m    return future.result()
[2m[WebServer] [22m           ~~~~~~~~~~~~~^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 208, in _agent_executor_async
[2m[WebServer] [22m    llm_response = await _call_model_async(current_messages)
[2m[WebServer] [22m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 134, in _call_model_async
[2m[WebServer] [22m    return await asyncio.to_thread(_call_model_sync, messages)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/threads.py", line 25, in to_thread
[2m[WebServer] [22m    return await loop.run_in_executor(None, func_call)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/thread.py", line 59, in run
[2m[WebServer] [22m    result = self.fn(*self.args, **self.kwargs)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 127, in _call_model_sync
[2m[WebServer] [22m    return llm_with_tools.invoke(messages)
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/runnables/base.py", line 5416, in invoke
[2m[WebServer] [22m    return self.bound.invoke(
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        input,
[2m[WebServer] [22m        ^^^^^^
[2m[WebServer] [22m        self._merge_configs(config),
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m        **{**self.kwargs, **kwargs},
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 369, in invoke
[2m[WebServer] [22m    self.generate_prompt(
[2m[WebServer] [22m    ~~~~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        [self._convert_input(input)],
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<6 lines>...
[2m[WebServer] [22m        **kwargs,
[2m[WebServer] [22m        ^^^^^^^^^
[2m[WebServer] [22m    ).generations[0][0],
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 946, in generate_prompt
[2m[WebServer] [22m    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
[2m[WebServer] [22m           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 765, in generate
[2m[WebServer] [22m    self._generate_with_cache(
[2m[WebServer] [22m    ~~~~~~~~~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        m,
[2m[WebServer] [22m        ^^
[2m[WebServer] [22m    ...<2 lines>...
[2m[WebServer] [22m        **kwargs,
[2m[WebServer] [22m        ^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 1011, in _generate_with_cache
[2m[WebServer] [22m    result = self._generate(
[2m[WebServer] [22m        messages, stop=stop, run_manager=run_manager, **kwargs
[2m[WebServer] [22m    )
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py", line 956, in _generate
[2m[WebServer] [22m    return generate_from_stream(stream_iter)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 153, in generate_from_stream
[2m[WebServer] [22m    generation = next(stream, None)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py", line 907, in _stream
[2m[WebServer] [22m    response = self.client.create(**payload)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_utils/_utils.py", line 287, in wrapper
[2m[WebServer] [22m    return func(*args, **kwargs)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py", line 925, in create
[2m[WebServer] [22m    return self._post(
[2m[WebServer] [22m           ~~~~~~~~~~^
[2m[WebServer] [22m        "/chat/completions",
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<43 lines>...
[2m[WebServer] [22m        stream_cls=Stream[ChatCompletionChunk],
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_base_client.py", line 1239, in post
[2m[WebServer] [22m    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
[2m[WebServer] [22m                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_base_client.py", line 1034, in request
[2m[WebServer] [22m    raise self._make_status_error_from_response(err.response) from None
[2m[WebServer] [22mopenai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `gpt-mock` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
[2m[WebServer] [22mDuring task with name 'agent_executor' and id '4d2c0759-78ed-fa70-cbb8-1022469f115a'
[2m[WebServer] [22mERROR - [AgentNode] Updated node_state to 'failed' in DB
[2m[WebServer] [22mERROR - [AgentNode] Re-raising exception to fail workflow execution
[2m[WebServer] [22mERROR - [LangGraphEngine] Execution failed â€“ execution_id=1
[2m[WebServer] [22mTraceback (most recent call last):
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/services/langgraph_workflow_engine.py", line 146, in execute_workflow
[2m[WebServer] [22m    await self._execute_workflow_internal(workflow, execution, db)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/services/langgraph_workflow_engine.py", line 214, in _execute_workflow_internal
[2m[WebServer] [22m    async for chunk in graph.astream(initial_state, config):
[2m[WebServer] [22m    ...<36 lines>...
[2m[WebServer] [22m            logger.warning(f"[LangGraphEngine] Received empty chunk #{chunk_count}")
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2732, in astream
[2m[WebServer] [22m    async for _ in runner.atick(
[2m[WebServer] [22m    ...<7 lines>...
[2m[WebServer] [22m            yield o
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/services/langgraph_workflow_engine.py", line 729, in agent_node
[2m[WebServer] [22m    created_messages = await runner.run_thread(db, thread)
[2m[WebServer] [22m                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/managers/agent_runner.py", line 137, in run_thread
[2m[WebServer] [22m    updated_messages = await self._runnable.ainvoke(original_msgs, config)
[2m[WebServer] [22m                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2850, in ainvoke
[2m[WebServer] [22m    async for chunk in self.astream(
[2m[WebServer] [22m    ...<13 lines>...
[2m[WebServer] [22m            chunks.append(chunk)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2732, in astream
[2m[WebServer] [22m    async for _ in runner.atick(
[2m[WebServer] [22m    ...<7 lines>...
[2m[WebServer] [22m            yield o
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 256, in agent_executor
[2m[WebServer] [22m    return _agent_executor_sync(messages, previous=previous)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 248, in _agent_executor_sync
[2m[WebServer] [22m    return asyncio.run(_agent_executor_async(messages, previous=previous))
[2m[WebServer] [22m           ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/runners.py", line 194, in run
[2m[WebServer] [22m    return runner.run(main)
[2m[WebServer] [22m           ~~~~~~~~~~^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/runners.py", line 118, in run
[2m[WebServer] [22m    return self._loop.run_until_complete(task)
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/base_events.py", line 720, in run_until_complete
[2m[WebServer] [22m    return future.result()
[2m[WebServer] [22m           ~~~~~~~~~~~~~^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 208, in _agent_executor_async
[2m[WebServer] [22m    llm_response = await _call_model_async(current_messages)
[2m[WebServer] [22m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 134, in _call_model_async
[2m[WebServer] [22m    return await asyncio.to_thread(_call_model_sync, messages)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/threads.py", line 25, in to_thread
[2m[WebServer] [22m    return await loop.run_in_executor(None, func_call)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/thread.py", line 59, in run
[2m[WebServer] [22m    result = self.fn(*self.args, **self.kwargs)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 127, in _call_model_sync
[2m[WebServer] [22m    return llm_with_tools.invoke(messages)
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/runnables/base.py", line 5416, in invoke
[2m[WebServer] [22m    return self.bound.invoke(
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        input,
[2m[WebServer] [22m        ^^^^^^
[2m[WebServer] [22m        self._merge_configs(config),
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m        **{**self.kwargs, **kwargs},
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 369, in invoke
[2m[WebServer] [22m    self.generate_prompt(
[2m[WebServer] [22m    ~~~~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        [self._convert_input(input)],
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<6 lines>...
[2m[WebServer] [22m        **kwargs,
[2m[WebServer] [22m        ^^^^^^^^^
[2m[WebServer] [22m    ).generations[0][0],
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 946, in generate_prompt
[2m[WebServer] [22m    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
[2m[WebServer] [22m           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 765, in generate
[2m[WebServer] [22m    self._generate_with_cache(
[2m[WebServer] [22m    ~~~~~~~~~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        m,
[2m[WebServer] [22m        ^^
[2m[WebServer] [22m    ...<2 lines>...
[2m[WebServer] [22m        **kwargs,
[2m[WebServer] [22m        ^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 1011, in _generate_with_cache
[2m[WebServer] [22m    result = self._generate(
[2m[WebServer] [22m        messages, stop=stop, run_manager=run_manager, **kwargs
[2m[WebServer] [22m    )
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py", line 956, in _generate
[2m[WebServer] [22m    return generate_from_stream(stream_iter)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 153, in generate_from_stream
[2m[WebServer] [22m    generation = next(stream, None)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py", line 907, in _stream
[2m[WebServer] [22m    response = self.client.create(**payload)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_utils/_utils.py", line 287, in wrapper
[2m[WebServer] [22m    return func(*args, **kwargs)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py", line 925, in create
[2m[WebServer] [22m    return self._post(
[2m[WebServer] [22m           ~~~~~~~~~~^
[2m[WebServer] [22m        "/chat/completions",
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<43 lines>...
[2m[WebServer] [22m        stream_cls=Stream[ChatCompletionChunk],
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_base_client.py", line 1239, in post
[2m[WebServer] [22m    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
[2m[WebServer] [22m                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_base_client.py", line 1034, in request
[2m[WebServer] [22m    raise self._make_status_error_from_response(err.response) from None
[2m[WebServer] [22mopenai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `gpt-mock` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
[2m[WebServer] [22mDuring task with name 'agent_executor' and id '4d2c0759-78ed-fa70-cbb8-1022469f115a'
[2m[WebServer] [22mDuring task with name 'agent-1' and id '7045affe-bcd2-ddc5-4470-83487c2e0802'
[2m[WebServer] [22mERROR - Unhandled exception: Error code: 404 - {'error': {'message': 'The model `gpt-mock` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
[2m[WebServer] [22mTraceback (most recent call last):
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/middleware/errors.py", line 165, in __call__
[2m[WebServer] [22m    await self.app(scope, receive, _send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/middleware/worker_db.py", line 101, in __call__
[2m[WebServer] [22m    await self.app(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/middleware/cors.py", line 85, in __call__
[2m[WebServer] [22m    await self.app(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/middleware/exceptions.py", line 62, in __call__
[2m[WebServer] [22m    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
[2m[WebServer] [22m    raise exc
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
[2m[WebServer] [22m    await app(scope, receive, sender)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/routing.py", line 714, in __call__
[2m[WebServer] [22m    await self.middleware_stack(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/routing.py", line 734, in app
[2m[WebServer] [22m    await route.handle(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/routing.py", line 288, in handle
[2m[WebServer] [22m    await self.app(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/routing.py", line 76, in app
[2m[WebServer] [22m    await wrap_app_handling_exceptions(app, request)(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
[2m[WebServer] [22m    raise exc
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
[2m[WebServer] [22m    await app(scope, receive, sender)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/routing.py", line 73, in app
[2m[WebServer] [22m    response = await f(request)
[2m[WebServer] [22m               ^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/fastapi/routing.py", line 301, in app
[2m[WebServer] [22m    raw_response = await run_endpoint_function(
[2m[WebServer] [22m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<3 lines>...
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/fastapi/routing.py", line 212, in run_endpoint_function
[2m[WebServer] [22m    return await dependant.call(**values)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/routers/workflow_executions.py", line 74, in start_workflow_execution
[2m[WebServer] [22m    execution_id = await langgraph_workflow_engine.execute_workflow(workflow_id)
[2m[WebServer] [22m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/services/langgraph_workflow_engine.py", line 146, in execute_workflow
[2m[WebServer] [22m    await self._execute_workflow_internal(workflow, execution, db)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/services/langgraph_workflow_engine.py", line 214, in _execute_workflow_internal
[2m[WebServer] [22m    async for chunk in graph.astream(initial_state, config):
[2m[WebServer] [22m    ...<36 lines>...
[2m[WebServer] [22m            logger.warning(f"[LangGraphEngine] Received empty chunk #{chunk_count}")
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2732, in astream
[2m[WebServer] [22m    async for _ in runner.atick(
[2m[WebServer] [22m    ...<7 lines>...
[2m[WebServer] [22m            yield o
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/services/langgraph_workflow_engine.py", line 729, in agent_node
[2m[WebServer] [22m    created_messages = await runner.run_thread(db, thread)
[2m[WebServer] [22m                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/managers/agent_runner.py", line 137, in run_thread
[2m[WebServer] [22m    updated_messages = await self._runnable.ainvoke(original_msgs, config)
[2m[WebServer] [22m                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2850, in ainvoke
[2m[WebServer] [22m    async for chunk in self.astream(
[2m[WebServer] [22m    ...<13 lines>...
[2m[WebServer] [22m            chunks.append(chunk)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2732, in astream
[2m[WebServer] [22m    async for _ in runner.atick(
[2m[WebServer] [22m    ...<7 lines>...
[2m[WebServer] [22m            yield o
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 256, in agent_executor
[2m[WebServer] [22m    return _agent_executor_sync(messages, previous=previous)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 248, in _agent_executor_sync
[2m[WebServer] [22m    return asyncio.run(_agent_executor_async(messages, previous=previous))
[2m[WebServer] [22m           ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/runners.py", line 194, in run
[2m[WebServer] [22m    return runner.run(main)
[2m[WebServer] [22m           ~~~~~~~~~~^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/runners.py", line 118, in run
[2m[WebServer] [22m    return self._loop.run_until_complete(task)
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/base_events.py", line 720, in run_until_complete
[2m[WebServer] [22m    return future.result()
[2m[WebServer] [22m           ~~~~~~~~~~~~~^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 208, in _agent_executor_async
[2m[WebServer] [22m    llm_response = await _call_model_async(current_messages)
[2m[WebServer] [22m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 134, in _call_model_async
[2m[WebServer] [22m    return await asyncio.to_thread(_call_model_sync, messages)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/threads.py", line 25, in to_thread
[2m[WebServer] [22m    return await loop.run_in_executor(None, func_call)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/thread.py", line 59, in run
[2m[WebServer] [22m    result = self.fn(*self.args, **self.kwargs)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 127, in _call_model_sync
[2m[WebServer] [22m    return llm_with_tools.invoke(messages)
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/runnables/base.py", line 5416, in invoke
[2m[WebServer] [22m    return self.bound.invoke(
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        input,
[2m[WebServer] [22m        ^^^^^^
[2m[WebServer] [22m        self._merge_configs(config),
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m        **{**self.kwargs, **kwargs},
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 369, in invoke
[2m[WebServer] [22m    self.generate_prompt(
[2m[WebServer] [22m    ~~~~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        [self._convert_input(input)],
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<6 lines>...
[2m[WebServer] [22m        **kwargs,
[2m[WebServer] [22m        ^^^^^^^^^
[2m[WebServer] [22m    ).generations[0][0],
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 946, in generate_prompt
[2m[WebServer] [22m    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
[2m[WebServer] [22m           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 765, [2m[WebServer] [22min generate
[2m[WebServer] [22m    self._generate_with_cache(
[2m[WebServer] [22m    ~~~~~~~~~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        m,
[2m[WebServer] [22m        ^^
[2m[WebServer] [22m    ...<2 lines>...
[2m[WebServer] [22m        **kwargs,
[2m[WebServer] [22m        ^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 1011, in _generate_with_cache
[2m[WebServer] [22m    result = self._generate(
[2m[WebServer] [22m        messages, stop=stop, run_manager=run_manager, **kwargs
[2m[WebServer] [22m    )
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py", line 956, in _generate
[2m[WebServer] [22m    return generate_from_stream(stream_iter)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 153, in generate_from_stream
[2m[WebServer] [22m    generation = next(stream, None)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py", line 907, in _stream
[2m[WebServer] [22m    response = self.client.create(**payload)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_utils/_utils.py", line 287, in wrapper
[2m[WebServer] [22m    return func(*args, **kwargs)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py", line 925, in create
[2m[WebServer] [22m    return self._post(
[2m[WebServer] [22m           ~~~~~~~~~~^
[2m[WebServer] [22m        "/chat/completions",
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<43 lines>...
[2m[WebServer] [22m        stream_cls=Stream[ChatCompletionChunk],
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_base_client.py", line 1239, in post
[2m[WebServer] [22m    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
[2m[WebServer] [22m                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_base_client.py", line 1034, in request
[2m[WebServer] [22m    raise self._make_status_error_from_response(err.response) from None
[2m[WebServer] [22mopenai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `gpt-mock` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
[2m[WebServer] [22mDuring task with name 'agent_executor' and id '4d2c0759-78ed-fa70-cbb8-1022469f115a'
[2m[WebServer] [22mDuring task with name 'agent-1' and id '7045affe-bcd2-ddc5-4470-83487c2e0802'
âŒ User 0 execution failed: [33m500[39m
[2m[WebServer] [22mERROR:    Exception in ASGI application
[2m[WebServer] [22mTraceback (most recent call last):
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/uvicorn/protocols/http/h11_impl.py", line 408, in run_asgi
[2m[WebServer] [22m    result = await app(  # type: ignore[func-returns-value]
[2m[WebServer] [22m             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m        self.scope, self.receive, self.send
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/uvicorn/middleware/proxy_headers.py", line 84, in __call__
[2m[WebServer] [22m    return await self.app(scope, receive, send)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/fastapi/applications.py", line 1054, in __call__
[2m[WebServer] [22m    await super().__call__(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/applications.py", line 112, in __call__
[2m[WebServer] [22m    await self.middleware_stack(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/middleware/errors.py", line 187, in __call__
[2m[WebServer] [22m    raise exc
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/middleware/errors.py", line 165, in __call__
[2m[WebServer] [22m    await self.app(scope, receive, _send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/middleware/worker_db.py", line 101, in __call__
[2m[WebServer] [22m    await self.app(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/middleware/cors.py", line 85, in __call__
[2m[WebServer] [22m    await self.app(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/middleware/exceptions.py", line 62, in __call__
[2m[WebServer] [22m    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
[2m[WebServer] [22m    raise exc
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
[2m[WebServer] [22m    await app(scope, receive, sender)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/routing.py", line 714, in __call__
[2m[WebServer] [22m    await self.middleware_stack(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/routing.py", line 734, in app
[2m[WebServer] [22m    await route.handle(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/routing.py", line 288, in handle
[2m[WebServer] [22m    await self.app(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/routing.py", line 76, in app
[2m[WebServer] [22m    await wrap_app_handling_exceptions(app, request)(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
[2m[WebServer] [22m    raise exc
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
[2m[WebServer] [22m    await app(scope, receive, sender)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/routing.py", line 73, in app
[2m[WebServer] [22m    response = await f(request)
[2m[WebServer] [22m               ^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/fastapi/routing.py", line 301, in app
[2m[WebServer] [22m    raw_response = await run_endpoint_function(
[2m[WebServer] [22m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<3 lines>...
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/fastapi/routing.py", line 212, in run_endpoint_function
[2m[WebServer] [22m    return await dependant.call(**values)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/routers/workflow_executions.py", line 74, in start_workflow_execution
[2m[WebServer] [22m    execution_id = await langgraph_workflow_engine.execute_workflow(workflow_id)
[2m[WebServer] [22m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/services/langgraph_workflow_engine.py", line 146, in execute_workflow
[2m[WebServer] [22m    await self._execute_workflow_internal(workflow, execution, db)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/services/langgraph_workflow_engine.py", line 214, in _execute_workflow_internal
[2m[WebServer] [22m    async for chunk in graph.astream(initial_state, config):
[2m[WebServer] [22m    ...<36 lines>...
[2m[WebServer] [22m            logger.warning(f"[LangGraphEngine] Received empty chunk #{chunk_count}")
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2732, in astream
[2m[WebServer] [22m    async for _ in runner.atick(
[2m[WebServer] [22m    ...<7 lines>...
[2m[WebServer] [22m            yield o
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/services/langgraph_workflow_engine.py", line 729, in agent_node
[2m[WebServer] [22m    created_messages = await runner.run_thread(db, thread)
[2m[WebServer] [22m                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/managers/agent_runner.py", line 137, in run_thread
[2m[WebServer] [22m    updated_messages = await self._runnable.ainvoke(original_msgs, config)
[2m[WebServer] [22m                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2850, in ainvoke
[2m[WebServer] [22m    async for chunk in self.astream(
[2m[WebServer] [22m    ...<13 lines>...
[2m[WebServer] [22m            chunks.append(chunk)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2732, in astream
[2m[WebServer] [22m    async for _ in runner.atick(
[2m[WebServer] [22m    ...<7 lines>...
[2m[WebServer] [22m            yield o
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 256, in agent_executor
[2m[WebServer] [22m    return _agent_executor_sync(messages, previous=previous)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 248, in _agent_executor_sync
[2m[WebServer] [22m    return asyncio.run(_agent_executor_async(messages, previous=previous))
[2m[WebServer] [22m           ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/runners.py", line 194, in run
[2m[WebServer] [22m    return runner.run(main)
[2m[WebServer] [22m           ~~~~~~~~~~^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/runners.py", line 118, in run
[2m[WebServer] [22m    return self._loop.run_until_complete(task)
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/base_events.py", line 720, in run_until_complete
[2m[WebServer] [22m    return future.result()
[2m[WebServer] [22m           ~~~~~~~~~~~~~^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 208, in _agent_executor_async
[2m[WebServer] [22m    llm_response = await _call_model_async(current_messages)
[2m[WebServer] [22m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 134, in _call_model_async
[2m[WebServer] [22m    return await asyncio.to_thread(_call_model_sync, messages)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/threads.py", line 25, in to_thread
[2m[WebServer] [22m    return await loop.run_in_executor(None, func_call)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/thread.py", line 59, in run
[2m[WebServer] [22m    result = self.fn(*self.args, **self.kwargs)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 127, in _call_model_sync
[2m[WebServer] [22m    return llm_with_tools.invoke(messages)
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/runnables/base.py", line 5416, in invoke
[2m[WebServer] [22m    return self.bound.invoke(
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        input,
[2m[WebServer] [22m        ^^^^^^
[2m[WebServer] [22m        self._merge_configs(config),
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^[2m[WebServer] [22m^^^^^^^^^
[2m[WebServer] [22m        **{**self.kwargs, **kwargs},
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 369, in invoke
[2m[WebServer] [22m    self.generate_prompt(
[2m[WebServer] [22m    ~~~~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        [self._convert_input(input)],
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<6 lines>...
[2m[WebServer] [22m        **kwargs,
[2m[WebServer] [22m        ^^^^^^^^^
[2m[WebServer] [22m    ).generations[0][0],
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 946, in generate_prompt
[2m[WebServer] [22m    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
[2m[WebServer] [22m           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 765, in generate
[2m[WebServer] [22m    self._generate_with_cache(
[2m[WebServer] [22m    ~~~~~~~~~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        m,
[2m[WebServer] [22m        ^^
[2m[WebServer] [22m    ...<2 lines>...
[2m[WebServer] [22m        **kwargs,
[2m[WebServer] [22m        ^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 1011, in _generate_with_cache
[2m[WebServer] [22m    result = self._generate(
[2m[WebServer] [22m        messages, stop=stop, run_manager=run_manager, **kwargs
[2m[WebServer] [22m    )
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py", line 956, in _generate
[2m[WebServer] [22m    return generate_from_stream(stream_iter)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 153, in generate_from_stream
[2m[WebServer] [22m    generation = next(stream, None)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py", line 907, in _stream
[2m[WebServer] [22m    response = self.client.create(**payload)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_utils/_utils.py", line 287, in wrapper
[2m[WebServer] [22m    return func(*args, **kwargs)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py", line 925, in create
[2m[WebServer] [22m    return self._post(
[2m[WebServer] [22m           ~~~~~~~~~~^
[2m[WebServer] [22m        "/chat/completions",
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<43 lines>...
[2m[WebServer] [22m        stream_cls=Stream[ChatCompletionChunk],
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_base_client.py", line 1239, in post
[2m[WebServer] [22m    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
[2m[WebServer] [22m                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_base_client.py", line 1034, in request
[2m[WebServer] [22m    raise self._make_status_error_from_response(err.response) from None
[2m[WebServer] [22mopenai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `gpt-mock` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
[2m[WebServer] [22mDuring task with name 'agent_executor' and id '4d2c0759-78ed-fa70-cbb8-1022469f115a'
[2m[WebServer] [22mDuring task with name 'agent-1' and id '7045affe-bcd2-ddc5-4470-83487c2e0802'
[2m[WebServer] [22mERROR - [AgentRunner] Exception during runnable.ainvoke: Error code: 404 - {'error': {'message': 'The model `gpt-mock` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
[2m[WebServer] [22mTraceback (most recent call last):
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/managers/agent_runner.py", line 137, in run_thread
[2m[WebServer] [22m    updated_messages = await self._runnable.ainvoke(original_msgs, config)
[2m[WebServer] [22m                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2850, in ainvoke
[2m[WebServer] [22m    async for chunk in self.astream(
[2m[WebServer] [22m    ...<13 lines>...
[2m[WebServer] [22m            chunks.append(chunk)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2732, in astream
[2m[WebServer] [22m    async for _ in runner.atick(
[2m[WebServer] [22m    ...<7 lines>...
[2m[WebServer] [22m            yield o
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 256, in agent_executor
[2m[WebServer] [22m    return _agent_executor_sync(messages, previous=previous)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 248, in _agent_executor_sync
[2m[WebServer] [22m    return asyncio.run(_agent_executor_async(messages, previous=previous))
[2m[WebServer] [22m           ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/runners.py", line 194, in run
[2m[WebServer] [22m    return runner.run(main)
[2m[WebServer] [22m           ~~~~~~~~~~^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/runners.py", line 118, in run
[2m[WebServer] [22m    return self._loop.run_until_complete(task)
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/base_events.py", line 720, in run_until_complete
[2m[WebServer] [22m    return future.result()
[2m[WebServer] [22m           ~~~~~~~~~~~~~^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 208, in _agent_executor_async
[2m[WebServer] [22m    llm_response = await _call_model_async(current_messages)
[2m[WebServer] [22m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 134, in _call_model_async
[2m[WebServer] [22m    return await asyncio.to_thread(_call_model_sync, messages)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/threads.py", line 25, in to_thread
[2m[WebServer] [22m    return await loop.run_in_executor(None, func_call)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/thread.py", line 59, in run
[2m[WebServer] [22m    result = self.fn(*self.args, **self.kwargs)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 127, in _call_model_sync
[2m[WebServer] [22m    return llm_with_tools.invoke(messages)
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/runnables/base.py", line 5416, in invoke
[2m[WebServer] [22m    return self.bound.invoke(
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        input,
[2m[WebServer] [22m        ^^^^^^
[2m[WebServer] [22m        self._merge_configs(config),
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m        **{**self.kwargs, **kwargs},
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 369, in invoke
[2m[WebServer] [22m    self.generate_prompt(
[2m[WebServer] [22m    ~~~~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        [self._convert_input(input)],
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<6 lines>...
[2m[WebServer] [22m        **kwargs,
[2m[WebServer] [22m        ^^^^^^^^^
[2m[WebServer] [22m    ).generations[0][0],
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 946, in generate_prompt
[2m[WebServer] [22m    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
[2m[WebServer] [22m           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 765, in generate
[2m[WebServer] [22m    self._generate_with_cache(
[2m[WebServer] [22m    ~~~~~~~~~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        m,
[2m[WebServer] [22m        ^^
[2m[WebServer] [22m    ...<2 lines>...
[2m[WebServer] [22m        **kwargs,
[2m[WebServer] [22m        ^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 1011, in _generate_with_cache
[2m[WebServer] [22m    result = self._generate(
[2m[WebServer] [22m        messages, stop=stop, run_manager=run_manager, **kwargs
[2m[WebServer] [22m    )
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py", line 956, in _generate
[2m[WebServer] [22m    return generate_from_stream(stream_iter)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 153, in generate_from_stream
[2m[WebServer] [22m    generation = next(stream, None)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py", line 907, in _stream
[2m[WebServer] [22m    response = self.client.create(**payload)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_utils/_utils.py", line 287, in wrapper
[2m[WebServer] [22m    return func(*args, **kwargs)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py", line 925, in create
[2m[WebServer] [22m    return self._post(
[2m[WebServer] [22m           ~~~~~~~~~~^
[2m[WebServer] [22m        "/chat/completions",
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<43 lines>...
[2m[WebServer] [22m        stream_cls=Stream[ChatCompletionChunk],
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_base_client.py", line 1239, in post
[2m[WebServer] [22m    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
[2m[WebServer] [22m                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_base_client.py", line 1034, in request
[2m[WebServer] [22m    raise self._make_status_error_from_response(err.response) from None
[2m[WebServer] [22mopenai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `gpt-mock` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
[2m[WebServer] [22mDuring task with name 'agent_executor' and id 'f30bb81b-ce0e-f73d-81eb-63e9c78e6873'
[2m[WebServer] [22mERROR - [AgentNode] Exception in agent node agent-1 (agent_id=1): Error code: 404 - {'error': {'message': 'The model `gpt-mock` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
[2m[WebServer] [22mTraceback (most recent call last):
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/services/langgraph_workflow_engine.py", line 729, in agent_node
[2m[WebServer] [22m    created_messages = await runner.run_thread(db, thread)
[2m[WebServer] [22m                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/managers/agent_runner.py", line 137, in run_thread
[2m[WebServer] [22m    updated_messages = await self._runnable.ainvoke(original_msgs, config)
[2m[WebServer] [22m                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2850, in ainvoke
[2m[WebServer] [22m    async for chunk in self.astream(
[2m[WebServer] [22m    ...<13 lines>...
[2m[WebServer] [22m            chunks.append(chunk)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2732, in astream
[2m[WebServer] [22m    async for _ in runner.atick(
[2m[WebServer] [22m    ...<7 lines>...
[2m[WebServer] [22m            yield o
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 256, in agent_executor
[2m[WebServer] [22m    return _agent_executor_sync(messages, previous=previous)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 248, in _agent_executor_sync
[2m[WebServer] [22m    return asyncio.run(_agent_executor_async(messages, previous=previous))
[2m[WebServer] [22m           ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/runners.py", line 194, in run
[2m[WebServer] [22m    return runner.run(main)
[2m[WebServer] [22m           ~~~~~~~~~~^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/runners.py", line 118, in run
[2m[WebServer] [22m    return self._loop.run_until_complete(task)
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/base_events.py", line 720, in run_until_complete
[2m[WebServer] [22m    return future.result()
[2m[WebServer] [22m           ~~~~~~~~~~~~~^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 208, in _agent_executor_async
[2m[WebServer] [22m    llm_response = await _call_model_async(current_messages)
[2m[WebServer] [22m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 134, in _call_model_async
[2m[WebServer] [22m    return await asyncio.to_thread(_call_model_sync, messages)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/threads.py", line 25, in to_thread
[2m[WebServer] [22m    return await loop.run_in_executor(None, func_call)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/thread.py", line 59, in run
[2m[WebServer] [22m    result = self.fn(*self.args, **self.kwargs)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 127, in _call_model_sync
[2m[WebServer] [22m    return llm_with_tools.invoke(messages)
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/runnables/base.py", line 5416, in invoke
[2m[WebServer] [22m    return self.bound.invoke(
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        input,
[2m[WebServer] [22m        ^^^^^^
[2m[WebServer] [22m        self._merge_configs(config),
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m        **{**self.kwargs, **kwargs},
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 369, in invoke
[2m[WebServer] [22m    self.generate_prompt(
[2m[WebServer] [22m    ~~~~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        [self._convert_input(input)],
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<6 lines>...
[2m[WebServer] [22m        **kwargs,
[2m[WebServer] [22m        ^^^^^^^^^
[2m[WebServer] [22m    ).generations[0][0],
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 946, in generate_prompt
[2m[WebServer] [22m    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
[2m[WebServer] [22m           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 765, in generate
[2m[WebServer] [22m    self._generate_with_cache(
[2m[WebServer] [22m    ~~~~~~~~~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        m,
[2m[WebServer] [22m        ^^
[2m[WebServer] [22m    ...<2 lines>...
[2m[WebServer] [22m        **kwargs,
[2m[WebServer] [22m        ^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 1011, in _generate_with_cache
[2m[WebServer] [22m    result = self._generate(
[2m[WebServer] [22m        messages, stop=stop, run_manager=run_manager, **kwargs
[2m[WebServer] [22m    )
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py", line 956, in _generate
[2m[WebServer] [22m    return generate_from_stream(stream_iter)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 153, in generate_from_stream
[2m[WebServer] [22m    generation = next(stream, None)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py", line 907, in _stream
[2m[WebServer] [22m    response = self.client.create(**payload)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_utils/_utils.py", line 287, in wrapper
[2m[WebServer] [22m    return func(*args, **kwargs)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py", line 925, in create
[2m[WebServer] [22m    return self._post(
[2m[WebServer] [22m           ~~~~~~~~~~^
[2m[WebServer] [22m        "/chat/completions",
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<43 lines>...
[2m[WebServer] [22m        stream_cls=Stream[ChatCompletionChunk],
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_base_client.py", line 1239, in post
[2m[WebServer] [22m    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
[2m[WebServer] [22m                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_base_client.py", line 1034, in request
[2m[WebServer] [22m    raise self._make_status_error_from_response(err.response) from None
[2m[WebServer] [22mopenai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `gpt-mock` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
[2m[WebServer] [22mDuring task with name 'agent_executor' and id 'f30bb81b-ce0e-f73d-81eb-63e9c78e6873'
[2m[WebServer] [22mERROR - [AgentNode] Updated node_state to 'failed' in DB
[2m[WebServer] [22mERROR - [AgentNode] Re-raising exception to fail workflow execution
[2m[WebServer] [22mERROR - [LangGraphEngine] Execution failed â€“ execution_id=1
[2m[WebServer] [22mTraceback (most recent call last):
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/services/langgraph_workflow_engine.py", line 146, in execute_workflow
[2m[WebServer] [22m    await self._execute_workflow_internal(workflow, execution, db)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/services/langgraph_workflow_engine.py", line 214, in _execute_workflow_internal
[2m[WebServer] [22m    async for chunk in graph.astream(initial_state, config):
[2m[WebServer] [22m    ...<36 lines>...
[2m[WebServer] [22m            logger.warning(f"[LangGraphEngine] Received empty chunk #{chunk_count}")
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2732, in astream
[2m[WebServer] [22m    async for _ in runner.atick(
[2m[WebServer] [22m    ...<7 lines>...
[2m[WebServer] [22m            yield o
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/services/langgraph_workflow_engine.py", line 729, in agent_node
[2m[WebServer] [22m    created_messages = await runner.run_thread(db, thread)
[2m[WebServer] [22m                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/managers/agent_runner.py", line 137, in run_thread
[2m[WebServer] [22m    updated_messages = await self._runnable.ainvoke(original_msgs, config)
[2m[WebServer] [22m                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2850, in ainvoke
[2m[WebServer] [22m    async for chunk in self.astream(
[2m[WebServer] [22m    ...<13 lines>...
[2m[WebServer] [22m            chunks.append(chunk)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2732, in astream
[2m[WebServer] [22m    async for _ in runner.atick(
[2m[WebServer] [22m    ...<7 lines>...
[2m[WebServer] [22m            yield o
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 256, in agent_executor
[2m[WebServer] [22m    return _agent_executor_sync(messages, previous=previous)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 248, in _agent_executor_sync
[2m[WebServer] [22m    return asyncio.run(_agent_executor_async(messages, previous=previous))
[2m[WebServer] [22m           ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/runners.py", line 194, in run
[2m[WebServer] [22m    return runner.run(main)
[2m[WebServer] [22m           ~~~~~~~~~~^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/runners.py", line 118, in run
[2m[WebServer] [22m    return self._loop.run_until_complete(task)
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/base_events.py", line 720, in run_until_complete
[2m[WebServer] [22m    return future.result()
[2m[WebServer] [22m           ~~~~~~~~~~~~~^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 208, in _agent_executor_async
[2m[WebServer] [22m    llm_response = await _call_model_async(current_messages)
[2m[WebServer] [22m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 134, in _call_model_async
[2m[WebServer] [22m    return await asyncio.to_thread(_call_model_sync, messages)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/threads.py", line 25, in to_thread
[2m[WebServer] [22m    return await loop.run_in_executor(None, func_call)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/thread.py", line 59, in run
[2m[WebServer] [22m    result = self.fn(*self.args, **self.kwargs)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 127, in _call_model_sync
[2m[WebServer] [22m    return llm_with_tools.invoke(messages)
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/runnables/base.py", line 5416, in invoke
[2m[WebServer] [22m    return self.bound.invoke(
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        input,
[2m[WebServer] [22m        ^^^^^^
[2m[WebServer] [22m        self._merge_configs(config),
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m        **{**self.kwargs, **kwargs},
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 369, in invoke
[2m[WebServer] [22m    self.generate_prompt(
[2m[WebServer] [22m    ~~~~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        [self._convert_input(input)],
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<6 lines>...
[2m[WebServer] [22m        **kwargs,
[2m[WebServer] [22m        ^^^^^^^^^
[2m[WebServer] [22m    ).generations[0][0],
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 946, in generate_prompt
[2m[WebServer] [22m    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
[2m[WebServer] [22m           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 765, in generate
[2m[WebServer] [22m    self._generate_with_cache(
[2m[WebServer] [22m    ~~~~~~~~~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        m,
[2m[WebServer] [22m        ^^
[2m[WebServer] [22m    ...<2 lines>...
[2m[WebServer] [22m        **kwargs,
[2m[WebServer] [22m        ^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 1011, in _generate_with_cache
[2m[WebServer] [22m    result = self._generate(
[2m[WebServer] [22m        messages, stop=stop, run_manager=run_manager, **kwargs
[2m[WebServer] [22m    )
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py", line 956, in _generate
[2m[WebServer] [22m    return generate_from_stream(stream_iter)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 153, in generate_from_stream
[2m[WebServer] [22m    generation = next(stream, None)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py", line 907, in _stream
[2m[WebServer] [22m    response = self.client.create(**payload)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_utils/_utils.py", line 287, in wrapper
[2m[WebServer] [22m    return func(*args, **kwargs)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py", line 925, in create
[2m[WebServer] [22m    return self._post(
[2m[WebServer] [22m           ~~~~~~~~~~^
[2m[WebServer] [22m        "/chat/completions",
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<43 lines>...
[2m[WebServer] [22m        stream_cls=Stream[ChatCompletionChunk],
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_base_client.py", line 1239, in post
[2m[WebServer] [22m    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
[2m[WebServer] [22m                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_base_client.py", line 1034, in request
[2m[WebServer] [22m    raise self._make_status_error_from_response(err.response) from None
[2m[WebServer] [22mopenai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `gpt-mock` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
[2m[WebServer] [22mDuring task with name 'agent_executor' and id 'f30bb81b-ce0e-f73d-81eb-63e9c78e6873'
[2m[WebServer] [22mDuring task with name 'agent-1' and id 'ebd3f1dd-2ed5-902d-9950-070d4ca83d98'
[2m[WebServer] [22mERROR - Unhandled exception: Error code: 404 - {'error': {'message': 'The model `gpt-mock` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
[2m[WebServer] [22mTraceback (most recent call last):
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/middleware/errors.py", line 165, in __call__
[2m[WebServer] [22m    await self.app(scope, receive, _send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/middleware/worker_db.py", line 101, in __call__
[2m[WebServer] [22m    await self.app(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/middleware/cors.py", line 85, in __call__
[2m[WebServer] [22m    await self.app(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/middleware/exceptions.py", line 62, in __call__
[2m[WebServer] [22m    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
[2m[WebServer] [22m    raise exc
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
[2m[WebServer] [22m    await app(scope, receive, sender)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/routing.py", line 714, in __call__
[2m[WebServer] [22m    await self.middleware_stack(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/routing.py", line 734, in app
[2m[WebServer] [22m    await route.handle(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/routing.py", line 288, in handle
[2m[WebServer] [22m    await self.app(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/routing.py", line 76, in app
[2m[WebServer] [22m    await wrap_app_handling_exceptions(app, request)(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
[2m[WebServer] [22m    raise exc
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
[2m[WebServer] [22m    await app(scope, receive, sender)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/routing.py", line 73, in app
[2m[WebServer] [22m    response = await f(request)
[2m[WebServer] [22m               ^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/fastapi/routing.py", line 301, in app
[2m[WebServer] [22m    raw_response = await run_endpoint_function(
[2m[WebServer] [22m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<3 lines>...
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/fastapi/routing.py", line 212, in run_endpoint_function
[2m[WebServer] [22m    return await dependant.call(**values)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/routers/workflow_executions.py", line 74, in start_workflow_execution
[2m[WebServer] [22m    execution_id = await langgraph_workflow_engine.execute_workflow(workflow_id)
[2m[WebServer] [22m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/services/langgraph_workflow_engine.py", line 146, in execute_workflow
[2m[WebServer] [22m    await self._execute_workflow_internal(workflow, execution, db)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/services/langgraph_workflow_engine.py", line 214, in _execute_workflow_internal
[2m[WebServer] [22m    async for chunk in graph.astream(initial_state, config):
[2m[WebServer] [22m    ...<36 lines>...
[2m[WebServer] [22m            logger.warning(f"[LangGraphEngine] Received empty chunk #{chunk_count}")
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2732, in astream
[2m[WebServer] [22m    async for _ in runner.atick(
[2m[WebServer] [22m    ...<7 lines>...
[2m[WebServer] [22m            yield o
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/services/langgraph_workflow_engine.py", line 729, in agent_node
[2m[WebServer] [22m    created_messages = await runner.run_thread(db, thread)
[2m[WebServer] [22m                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/managers/agent_runner.py", line 137, in run_thread
[2m[WebServer] [22m    updated_messages = await self._runnable.ainvoke(original_msgs, config)
[2m[WebServer] [22m                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2850, in ainvoke
[2m[WebServer] [22m    async for chunk in self.astream(
[2m[WebServer] [22m    ...<13 lines>...
[2m[WebServer] [22m            chunks.append(chunk)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2732, in astream
[2m[WebServer] [22m    async for _ in runner.atick(
[2m[WebServer] [22m    ...<7 lines>...
[2m[WebServer] [22m            yield o
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 256, in agent_executor
[2m[WebServer] [22m    return _agent_executor_sync(messages, previous=previous)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 248, in _agent_executor_sync
[2m[WebServer] [22m    return asyncio.run(_agent_executor_async(messages, previous=previous))
[2m[WebServer] [22m           ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/runners.py", line 194, in run
[2m[WebServer] [22m    return runner.run(main)
[2m[WebServer] [22m           ~~~~~~~~~~^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/runners.py", line 118, in run
[2m[WebServer] [22m    return self._loop.run_until_complete(task)
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/base_events.py", line 720, in run_until_complete
[2m[WebServer] [22m    return future.result()
[2m[WebServer] [22m           ~~~~~~~~~~~~~^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 208, in _agent_executor_async
[2m[WebServer] [22m    llm_response = await _call_model_async(current_messages)
[2m[WebServer] [22m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 134, in _call_model_async
[2m[WebServer] [22m    return await asyncio.to_thread(_call_model_sync, messages)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/threads.py", line 25, in to_thread
[2m[WebServer] [22m    return await loop.run_in_executor(None, func_call)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/thread.py", line 59, in run
[2m[WebServer] [22m    result = self.fn(*self.args, **self.kwargs)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 127, in _call_model_sync
[2m[WebServer] [22m    return llm_with_tools.invoke(messages)
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/runnables/base.py", line 5416, in invoke
[2m[WebServer] [22m    return self.bound.invoke(
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        input,
[2m[WebServer] [22m        ^^^^^^
[2m[WebServer] [22m        self._merge_configs(config),
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m        **{**self.kwargs, **kwargs},
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 369, in invoke
[2m[WebServer] [22m    self.generate_prompt(
[2m[WebServer] [22m    ~~~~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        [self._convert_input(input)],
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<6 lines>...
[2m[WebServer] [22m        **kwargs,
[2m[WebServer] [22m        ^^^^^^^^^
[2m[WebServer] [22m    ).generations[0][0],
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 946, in generate_prompt
[2m[WebServer] [22m    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
[2m[WebServer] [22m           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 765, [2m[WebServer] [22min generate
[2m[WebServer] [22m    self._generate_with_cache(
[2m[WebServer] [22m    ~~~~~~~~~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        m,
[2m[WebServer] [22m        ^^
[2m[WebServer] [22m    ...<2 lines>...
[2m[WebServer] [22m        **kwargs,
[2m[WebServer] [22m        ^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 1011, in _generate_with_cache
[2m[WebServer] [22m    result = self._generate(
[2m[WebServer] [22m        messages, stop=stop, run_manager=run_manager, **kwargs
[2m[WebServer] [22m    )
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py", line 956, in _generate
[2m[WebServer] [22m    return generate_from_stream(stream_iter)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 153, in generate_from_stream
[2m[WebServer] [22m    generation = next(stream, None)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py", line 907, in _stream
[2m[WebServer] [22m    response = self.client.create(**payload)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_utils/_utils.py", line 287, in wrapper
[2m[WebServer] [22m    return func(*args, **kwargs)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py", line 925, in create
[2m[WebServer] [22m    return self._post(
[2m[WebServer] [22m           ~~~~~~~~~~^
[2m[WebServer] [22m        "/chat/completions",
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<43 lines>...
[2m[WebServer] [22m        stream_cls=Stream[ChatCompletionChunk],
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_base_client.py", line 1239, in post
[2m[WebServer] [22m    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
[2m[WebServer] [22m                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_base_client.py", line 1034, in request
[2m[WebServer] [22m    raise self._make_status_error_from_response(err.response) from None
[2m[WebServer] [22mopenai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `gpt-mock` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
[2m[WebServer] [22mDuring task with name 'agent_executor' and id 'f30bb81b-ce0e-f73d-81eb-63e9c78e6873'
[2m[WebServer] [22mDuring task with name 'agent-1' and id 'ebd3f1dd-2ed5-902d-9950-070d4ca83d98'
âŒ User 1 execution failed: [33m500[39m
ğŸ“Š Successful workflow executions: [33m0[39m / [33m3[39m
ğŸ“Š Concurrent execution start time: [33m1140[39m ms
ğŸ“Š Test 3: Monitoring concurrent executions...
[2m[WebServer] [22mERROR:    Exception in ASGI application
[2m[WebServer] [22mTraceback (most recent call last):
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/uvicorn/protocols/http/h11_impl.py", line 408, in run_asgi
[2m[WebServer] [22m    result = await app(  # type: ignore[func-returns-value]
[2m[WebServer] [22m             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m        self.scope, self.receive, self.send
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/uvicorn/middleware/proxy_headers.py", line 84, in __call__
[2m[WebServer] [22m    return await self.app(scope, receive, send)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/fastapi/applications.py", line 1054, in __call__
[2m[WebServer] [22m    await super().__call__(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/applications.py", line 112, in __call__
[2m[WebServer] [22m    await self.middleware_stack(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/middleware/errors.py", line 187, in __call__
[2m[WebServer] [22m    raise exc
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/middleware/errors.py", line 165, in __call__
[2m[WebServer] [22m    await self.app(scope, receive, _send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/middleware/worker_db.py", line 101, in __call__
[2m[WebServer] [22m    await self.app(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/middleware/cors.py", line 85, in __call__
[2m[WebServer] [22m    await self.app(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/middleware/exceptions.py", line 62, in __call__
[2m[WebServer] [22m    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
[2m[WebServer] [22m    raise exc
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
[2m[WebServer] [22m    await app(scope, receive, sender)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/routing.py", line 714, in __call__
[2m[WebServer] [22m    await self.middleware_stack(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/routing.py", line 734, in app
[2m[WebServer] [22m    await route.handle(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/routing.py", line 288, in handle
[2m[WebServer] [22m    await self.app(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/routing.py", line 76, in app
[2m[WebServer] [22m    await wrap_app_handling_exceptions(app, request)(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
[2m[WebServer] [22m    raise exc
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
[2m[WebServer] [22m    await app(scope, receive, sender)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/routing.py", line 73, in app
[2m[WebServer] [22m    response = await f(request)
[2m[WebServer] [22m               ^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/fastapi/routing.py", line 301, in app
[2m[WebServer] [22m    raw_response = await run_endpoint_function(
[2m[WebServer] [22m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<3 lines>...
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/fastapi/routing.py", line 212, in run_endpoint_function
[2m[WebServer] [22m    return await dependant.call(**values)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/routers/workflow_executions.py", line 74, in start_workflow_execution
[2m[WebServer] [22m    execution_id = await langgraph_workflow_engine.execute_workflow(workflow_id)
[2m[WebServer] [22m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/services/langgraph_workflow_engine.py", line 146, in execute_workflow
[2m[WebServer] [22m    await self._execute_workflow_internal(workflow, execution, db)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/services/langgraph_workflow_engine.py", line 214, in _execute_workflow_internal
[2m[WebServer] [22m    async for chunk in graph.astream(initial_state, config):
[2m[WebServer] [22m    ...<36 lines>...
[2m[WebServer] [22m            logger.warning(f"[LangGraphEngine] Received empty chunk #{chunk_count}")
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2732, in astream
[2m[WebServer] [22m    async for _ in runner.atick(
[2m[WebServer] [22m    ...<7 lines>...
[2m[WebServer] [22m            yield o
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/services/langgraph_workflow_engine.py", line 729, in agent_node
[2m[WebServer] [22m    created_messages = await runner.run_thread(db, thread)
[2m[WebServer] [22m                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/managers/agent_runner.py", line 137, in run_thread
[2m[WebServer] [22m    updated_messages = await self._runnable.ainvoke(original_msgs, config)
[2m[WebServer] [22m                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2850, in ainvoke
[2m[WebServer] [22m    async for chunk in self.astream(
[2m[WebServer] [22m    ...<13 lines>...
[2m[WebServer] [22m            chunks.append(chunk)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2732, in astream
[2m[WebServer] [22m    async for _ in runner.atick(
[2m[WebServer] [22m    ...<7 lines>...
[2m[WebServer] [22m            yield o
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 256, in agent_executor
[2m[WebServer] [22m    return _agent_executor_sync(messages, previous=previous)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 248, in _agent_executor_sync
[2m[WebServer] [22m    return asyncio.run(_agent_executor_async(messages, previous=previous))
[2m[WebServer] [22m           ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/runners.py", line 194, in run
[2m[WebServer] [22m    return runner.run(main)
[2m[WebServer] [22m           ~~~~~~~~~~^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/runners.py", line 118, in run
[2m[WebServer] [22m    return self._loop.run_until_complete(task)
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/base_events.py", line 720, in run_until_complete
[2m[WebServer] [22m    return future.result()
[2m[WebServer] [22m           ~~~~~~~~~~~~~^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 208, in _agent_executor_async
[2m[WebServer] [22m    llm_response = await _call_model_async(current_messages)
[2m[WebServer] [22m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 134, in _call_model_async
[2m[WebServer] [22m    return await asyncio.to_thread(_call_model_sync, messages)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/threads.py", line 25, in to_thread
[2m[WebServer] [22m    return await loop.run_in_executor(None, func_call)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/thread.py", line 59, in run
[2m[WebServer] [22m    result = self.fn(*self.args, **self.kwargs)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 127, in _call_model_sync
[2m[WebServer] [22m    return llm_with_tools.invoke(messages)
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/runnables/base.py", line 5416, in invoke
[2m[WebServer] [22m    return self.bound.invoke(
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        input,
[2m[WebServer] [22m        ^^^^^^
[2m[WebServer] [22m        self._merge_configs(config),
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^[2m[WebServer] [22m^^^^^^^^^
[2m[WebServer] [22m        **{**self.kwargs, **kwargs},
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 369, in invoke
[2m[WebServer] [22m    self.generate_prompt(
[2m[WebServer] [22m    ~~~~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        [self._convert_input(input)],
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<6 lines>...
[2m[WebServer] [22m        **kwargs,
[2m[WebServer] [22m        ^^^^^^^^^
[2m[WebServer] [22m    ).generations[0][0],
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 946, in generate_prompt
[2m[WebServer] [22m    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
[2m[WebServer] [22m           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 765, in generate
[2m[WebServer] [22m    self._generate_with_cache(
[2m[WebServer] [22m    ~~~~~~~~~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        m,
[2m[WebServer] [22m        ^^
[2m[WebServer] [22m    ...<2 lines>...
[2m[WebServer] [22m        **kwargs,
[2m[WebServer] [22m        ^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 1011, in _generate_with_cache
[2m[WebServer] [22m    result = self._generate(
[2m[WebServer] [22m        messages, stop=stop, run_manager=run_manager, **kwargs
[2m[WebServer] [22m    )
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py", line 956, in _generate
[2m[WebServer] [22m    return generate_from_stream(stream_iter)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 153, in generate_from_stream
[2m[WebServer] [22m    generation = next(stream, None)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py", line 907, in _stream
[2m[WebServer] [22m    response = self.client.create(**payload)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_utils/_utils.py", line 287, in wrapper
[2m[WebServer] [22m    return func(*args, **kwargs)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py", line 925, in create
[2m[WebServer] [22m    return self._post(
[2m[WebServer] [22m           ~~~~~~~~~~^
[2m[WebServer] [22m        "/chat/completions",
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<43 lines>...
[2m[WebServer] [22m        stream_cls=Stream[ChatCompletionChunk],
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_base_client.py", line 1239, in post
[2m[WebServer] [22m    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
[2m[WebServer] [22m                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_base_client.py", line 1034, in request
[2m[WebServer] [22m    raise self._make_status_error_from_response(err.response) from None
[2m[WebServer] [22mopenai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `gpt-mock` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
[2m[WebServer] [22mDuring task with name 'agent_executor' and id 'f30bb81b-ce0e-f73d-81eb-63e9c78e6873'
[2m[WebServer] [22mDuring task with name 'agent-1' and id 'ebd3f1dd-2ed5-902d-9950-070d4ca83d98'
âœ… Concurrent workflow execution test completed
  âœ“  20 tests/multi_user_concurrency.spec.ts:137:7 â€º Multi-User and Concurrency â€º Concurrent workflow execution (1.5s)
ğŸš€ Starting WebSocket broadcasting test...
ğŸ“Š Created 2 WebSocket monitoring sessions
ğŸ“Š Test 1: Connecting users and monitoring initial messages...
ğŸ“Š JavaScript errors detected: [33m0[39m
âœ… No JavaScript errors during navigation
âœ… UI error state test completed
  âœ“  18 tests/error_handling_edge_cases.spec.ts:261:7 â€º Error Handling and Edge Cases â€º UI error state handling (8.2s)
ğŸš€ Starting resource sharing and conflict resolution test...
ğŸ“Š Created 2 sessions for conflict testing
ğŸ“Š Test 1: Testing concurrent modifications...
ğŸ“Š User 1 WebSocket connected: ws://localhost:8001/api/ws
ğŸ“Š User 0 WebSocket connected: ws://localhost:8001/api/ws
ğŸ“Š User 1 received: user_update
ğŸ“Š User 1 received: ping
ğŸ“Š User 0 received: user_update
ğŸ“Š User 0 received: ping
ğŸ“Š User 0 created agent: [33m1[39m (331ms)
ğŸ“Š User 1 created agent: [33m1[39m (348ms)
ğŸ“Š Successful concurrent operations: [33m2[39m / [33m2[39m
ğŸ“Š Response time range: [33m331[39m ms - [33m348[39m ms
ğŸ“Š Average response time: [33m340[39m ms
âœ… Concurrent operations have similar response times
ğŸ“Š Test 2: Verifying database consistency...
ğŸ“Š User 0 sees 1 agents
ğŸ“Š User 1 sees 1 agents
ğŸ“Š Test 3: Testing resource contention...
ğŸ“Š User 0 created workflow referencing shared agent: [33m1[39m
ğŸ“Š User 1 created workflow referencing shared agent: [33m1[39m
ğŸ“Š Successful resource sharing operations: [33m2[39m / [33m2[39m
âœ… Resource sharing handles concurrent access well
âœ… Resource sharing and conflict resolution test completed
  âœ“  22 tests/multi_user_concurrency.spec.ts:511:7 â€º Multi-User and Concurrency â€º Resource sharing and conflict resolution (710ms)
ğŸš€ Starting session management test...
ğŸ“Š Test 1: Testing session lifecycle...
ğŸ“Š Test 2: Testing cross-session message broadcasting...
ğŸ“Š Created agent in primary session: [33m1[39m
ğŸ“Š Created agent in session 1: [33m1[39m
ğŸ“Š Closed session 1
ğŸ“Š Test 2: Testing data persistence after session closure...
ğŸ“Š Agent persisted after session closure: [33mtrue[39m
âœ… Data persists correctly after session closure
ğŸ“Š Test 3: Verifying session isolation...
ğŸ“Š Created agent in session 2: [33m1[39m
ğŸ“Š Session 2 sees session 1 data: [33mtrue[39m
ğŸ“Š Session 2 sees own data: [33mtrue[39m
ğŸ“Š Sessions share data (may be intended behavior)
ğŸ“Š Test 4: Testing cleanup mechanisms...
ğŸ“Š Created temporary agent: [33m1[39m
ğŸ“Š User 0 received 1 agent-related messages
âœ… User 0 received WebSocket notifications
ğŸ“Š User 1 received 1 agent-related messages
âœ… User 1 received WebSocket notifications
ğŸ“Š Test 3: Testing session isolation in WebSocket messages...
ğŸ“Š Primary session message types: []
ğŸ“Š Secondary session message types: []
ğŸ“Š Cross-session messages in secondary: [33m0[39m
âœ… WebSocket messages properly isolated between sessions
ğŸ“Š Test 4: Testing high-frequency message handling...
ğŸ“Š Cleanup verification completed (manual inspection may be needed)
âœ… Session management test completed
  âœ“  23 tests/multi_user_concurrency.spec.ts:666:7 â€º Multi-User and Concurrency â€º Session management and cleanup (4.0s)
ğŸš€ Starting UI responsiveness test...
ğŸ“Š Worker ID: 0
ğŸ“Š Test 1: Page load performance...
ğŸ“Š Rapid operations completed: [33m5[39m / [33m5[39m
ğŸ“Š Rapid operations time: [33m313[39m ms
ğŸ“Š Page load time: [33m1014[39m ms
âœ… Page loads within acceptable time (< 3s)
ğŸ“Š Test 2: Navigation performance...
ğŸ“Š Dashboard navigation time: [33m146[39m ms
âœ… Dashboard navigation is responsive (< 500ms)
ğŸ“Š Canvas navigation time: [33m202[39m ms
âœ… Canvas navigation is responsive (< 500ms)
ğŸ“Š Test 3: UI interaction responsiveness...
ğŸ“Š Interactive elements found: [33m113[39m
ğŸ“Š User 0 received 0 messages during rapid operations
ğŸ“Š User 1 received 0 messages during rapid operations
âœ… WebSocket broadcasting test completed
  âœ“  21 tests/multi_user_concurrency.spec.ts:351:7 â€º Multi-User and Concurrency â€º WebSocket message broadcasting and isolation (8.3s)
ğŸš€ Starting API performance test...
ğŸ“Š Test 1: Single API request performance...
ğŸ“Š GET /api/agents response time: [33m4[39m ms
ğŸ“Š GET /api/agents status: [33m200[39m
âœ… GET /api/agents is very fast (< 200ms)
ğŸ“Š GET /api/workflows response time: [33m3[39m ms
ğŸ“Š GET /api/workflows status: [33m200[39m
âœ… GET /api/workflows is very fast (< 200ms)
ğŸ“Š GET /api/users/me response time: [33m2[39m ms
ğŸ“Š GET /api/users/me status: [33m200[39m
âœ… GET /api/users/me is very fast (< 200ms)
ğŸ“Š Test 2: Batch API request performance...
ğŸ“Š Batch requests completed: [33m10[39m / [33m10[39m
ğŸ“Š Batch total time: [33m331[39m ms
ğŸ“Š Average per request: [33m33[39m ms
âœ… Batch API performance is good
âœ… API performance test completed
  âœ“  25 tests/performance_load_testing.spec.ts:94:7 â€º Performance and Load Testing â€º API response time benchmarking (375ms)
ğŸš€ Starting database performance test...
ğŸ“Š Test 1: Creating large dataset...
ğŸ“Š Agents created successfully: [33m50[39m / [33m50[39m
ğŸ“Š Creation time: [33m637[39m ms
ğŸ“Š Average creation time: [33m13[39m ms per agent
âœ… Large dataset creation successful
ğŸ“Š Test 2: Query performance with large dataset...
ğŸ“Š Total agents retrieved: [33m68[39m
ğŸ“Š Query time: [33m7[39m ms
âœ… Large dataset query performance is good (< 1s)
ğŸ“Š Test 3: Testing pagination performance...
ğŸ“Š Pagination query status: [33m200[39m
ğŸ“Š Pagination query time: [33m3[39m ms
ğŸ“Š Paginated results returned: [33m10[39m
âœ… Pagination performance is excellent
âœ… Database performance test completed
  âœ“  26 tests/performance_load_testing.spec.ts:161:7 â€º Performance and Load Testing â€º Database performance with large datasets (683ms)
ğŸš€ Starting memory usage test...
ğŸ“Š Test 1: Establishing memory baseline...
ğŸ“Š Initial memory usage: { used: [33m10000000[39m, total: [33m10000000[39m, limit: [33m3760000000[39m }
ğŸ“Š Page timing: { domContentLoaded: [33m514[39m, fullyLoaded: [33m560[39m }
ğŸ“Š Test 2: Memory usage during intensive operations...
ğŸ“Š Hover test skipped (element not interactive)
âœ… UI responsiveness test completed
  âœ“  24 tests/performance_load_testing.spec.ts:18:7 â€º Performance and Load Testing â€º UI responsiveness benchmarking (6.4s)
ğŸš€ Starting concurrent user simulation...
ğŸ“Š Test 1: Simulating 5 concurrent users...
ğŸ“Š Memory usage after operations: { used: [33m10000000[39m, total: [33m10000000[39m }
ğŸ“Š Memory increase: [33m0[39m %
âœ… Memory usage increase is reasonable
ğŸ“Š Test 3: Memory leak detection...
ğŸ“Š Memory usage after GC: { used: [33m10000000[39m, total: [33m10000000[39m }
ğŸ“Š Memory freed by GC: [33m0[39m bytes
âœ… Memory usage test completed
  âœ“  27 tests/performance_load_testing.spec.ts:256:7 â€º Performance and Load Testing â€º Memory usage and resource monitoring (5.0s)
ğŸ“Š User 0 agent creation: success
ğŸš€ Starting large workflow performance test...
ğŸ“Š Test 1: Creating agents for large workflow...
ğŸ“Š Created agent 0: [33m79[39m
ğŸ“Š Created agent 1: [33m80[39m
ğŸ“Š Created agent 2: [33m81[39m
ğŸ“Š Created agent 3: [33m82[39m
ğŸ“Š Created agent 4: [33m83[39m
ğŸ“Š Created agent 5: [33m84[39m
ğŸ“Š Created agent 6: [33m85[39m
ğŸ“Š Created agent 7: [33m86[39m
ğŸ“Š Created agent 8: [33m87[39m
ğŸ“Š Created agent 9: [33m88[39m
ğŸ“Š Total agents for large workflow: [33m10[39m
ğŸ“Š Test 2: Creating large workflow...
ğŸ“Š User 4 agent creation: success
ğŸ“Š User 2 agent creation: success
ğŸ“Š Large workflow creation status: [33m200[39m
ğŸ“Š Large workflow creation time: [33m307[39m ms
ğŸ“Š Workflow nodes: [33m16[39m
ğŸ“Š Workflow connections: [33m16[39m
ğŸ“Š Large workflow created with ID: [33m3[39m
ğŸ“Š Large workflow retrieval time: [33m1[39m ms
âœ… Large workflow performance is acceptable
âœ… Large workflow performance test completed
  âœ“  29 tests/performance_load_testing.spec.ts:444:7 â€º Performance and Load Testing â€º Large workflow performance (383ms)
ğŸš€ Starting WebSocket monitoring test...
ğŸ“Š Worker ID: 0
ğŸ“Š Step 1: Connecting to application...
ğŸ“Š User 1 agent creation: success
ğŸ“Š User 3 agent creation: success
ğŸ“Š Concurrent users completed successfully: [33m5[39m / [33m5[39m
ğŸ“Š Total simulation time: [33m4090[39m ms
ğŸ“Š Average time per user: [33m818[39m ms
âœ… Concurrent user handling is robust
âœ… Concurrent user simulation completed
  âœ“  28 tests/performance_load_testing.spec.ts:371:7 â€º Performance and Load Testing â€º Concurrent user simulation (4.1s)
ğŸš€ Starting tool palette discovery test...
ğŸ“Š Worker ID: 0
ğŸ“Š Step 2: Monitoring WebSocket activity...
ğŸ“Š Step 3: Creating agent to trigger updates...
âœ… Agent created, waiting for WebSocket updates...
ğŸ“Š Test 1: Locating tool palette...
ğŸ“Š Tool palette visible: [33mfalse[39m
âš ï¸  Tool palette not visible - checking alternative locations...
ğŸ“Š Alternative tool containers found: [33m0[39m
âœ… Tool palette discovery completed
  âœ“  31 tests/tool_palette_node_connections.spec.ts:18:7 â€º Tool Palette and Node Connections â€º Tool palette discovery and cataloging (3.6s)
ğŸš€ Starting tool drag-and-drop test...
ğŸ“Š Created test agent: [33m90[39m
ğŸ“Š Step 4: Navigating to trigger more WebSocket events...
ğŸ“Š Step 5: Analyzing WebSocket messages...
ğŸ“Š Total WebSocket messages received: [33m0[39m
âš ï¸  No WebSocket messages received - may need connection investigation
ğŸ“Š Step 6: Testing real-time UI updates...
ğŸ“Š Test 1: Identifying drag-and-drop targets...
ğŸ“Š Canvas container visible: [33mfalse[39m
âœ… Tool drag-and-drop test completed
  âœ“  32 tests/tool_palette_node_connections.spec.ts:84:7 â€º Tool Palette and Node Connections â€º Tool drag-and-drop from palette to canvas (3.7s)
ğŸš€ Starting node connection test...
ğŸ“Š Agent visible in dashboard: [33mfalse[39m
ğŸ“Š Step 7: Checking for real-time status indicators...
ğŸ“Š Status indicators found: [33m0[39m
ğŸ“Š Online indicators found: [33m0[39m
ğŸ“Š Activity indicators found: [33m0[39m
âœ… WebSocket monitoring test completed
ğŸ“Š Summary: Real-time WebSocket communication validated
  âœ“  30 tests/realtime_websocket_monitoring.spec.ts:15:7 â€º Real-time WebSocket Monitoring â€º WebSocket event monitoring and real-time updates (8.6s)
ğŸš€ Starting complex workflow topology test...
ğŸ“Š Test 1: Creating multiple agents...
ğŸ“Š Created agent 1: [33m92[39m
ğŸ“Š Created agent 2: [33m93[39m
ğŸ“Š Created agent 3: [33m94[39m
ğŸ“Š Total agents created: [33m3[39m
ğŸ“Š Test 2: Creating complex workflow topology...
ğŸ“Š Complex workflow created: [33m4[39m
ğŸ“Š Test 3: Verifying topology integrity...
âœ… Complex workflow topology test completed
  âœ“  34 tests/tool_palette_node_connections.spec.ts:309:7 â€º Tool Palette and Node Connections â€º Complex workflow topology creation (660ms)
ğŸš€ Starting connection validation test...
ğŸ“Š Test 1: Testing valid connection topology...
ğŸ“Š Valid workflow creation status: [33m200[39m
âœ… Valid connection topology accepted
ğŸ“Š Test 2: Testing invalid connection scenarios...
ğŸ“Š Circular workflow creation status: [33m200[39m
ğŸ“Š Circular references allowed (system permits cycles)
ğŸ“Š Test 3: Testing non-existent node references...
ğŸ“Š Invalid node workflow status: [33m200[39m
âœ… Connection validation test completed
  âœ“  35 tests/tool_palette_node_connections.spec.ts:458:7 â€º Tool Palette and Node Connections â€º Connection validation and constraint checking (954ms)
ğŸš€ Starting workflow execution test...
ğŸ“Š Worker ID: 1
ğŸ“Š Step 1: Creating test agent...
âœ… Test agent created with ID: [33m1[39m
ğŸ“Š Step 2: Attempting workflow creation...
âœ… Workflow created with ID: [33m2[39m
ğŸ“Š Step 3: Executing workflow...
[2m[WebServer] [22mERROR - [AgentRunner] Exception during runnable.ainvoke: Error code: 404 - {'error': {'message': 'The model `gpt-mock` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
[2m[WebServer] [22mTraceback (most recent call last):
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/managers/agent_runner.py", line 137, in run_thread
[2m[WebServer] [22m    updated_messages = await self._runnable.ainvoke(original_msgs, config)
[2m[WebServer] [22m                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2850, in ainvoke
[2m[WebServer] [22m    async for chunk in self.astream(
[2m[WebServer] [22m    ...<13 lines>...
[2m[WebServer] [22m            chunks.append(chunk)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2732, in astream
[2m[WebServer] [22m    async for _ in runner.atick(
[2m[WebServer] [22m    ...<7 lines>...
[2m[WebServer] [22m            yield o
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 256, in agent_executor
[2m[WebServer] [22m    return _agent_executor_sync(messages, previous=previous)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 248, in _agent_executor_sync
[2m[WebServer] [22m    return asyncio.run(_agent_executor_async(messages, previous=previous))
[2m[WebServer] [22m           ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/runners.py", line 194, in run
[2m[WebServer] [22m    return runner.run(main)
[2m[WebServer] [22m           ~~~~~~~~~~^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/runners.py", line 118, in run
[2m[WebServer] [22m    return self._loop.run_until_complete(task)
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/base_events.py", line 720, in run_until_complete
[2m[WebServer] [22m    return future.result()
[2m[WebServer] [22m           ~~~~~~~~~~~~~^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 208, in _agent_executor_async
[2m[WebServer] [22m    llm_response = await _call_model_async(current_messages)
[2m[WebServer] [22m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 134, in _call_model_async
[2m[WebServer] [22m    return await asyncio.to_thread(_call_model_sync, messages)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/threads.py", line 25, in to_thread
[2m[WebServer] [22m    return await loop.run_in_executor(None, func_call)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/thread.py", line 59, in run
[2m[WebServer] [22m    result = self.fn(*self.args, **self.kwargs)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 127, in _call_model_sync
[2m[WebServer] [22m    return llm_with_tools.invoke(messages)
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/runnables/base.py", line 5416, in invoke
[2m[WebServer] [22m    return self.bound.invoke(
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        input,
[2m[WebServer] [22m        ^^^^^^
[2m[WebServer] [22m        self._merge_configs(config),
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m        **{**self.kwargs, **kwargs},
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 369, in invoke
[2m[WebServer] [22m    self.generate_prompt(
[2m[WebServer] [22m    ~~~~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        [self._convert_input(input)],
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<6 lines>...
[2m[WebServer] [22m        **kwargs,
[2m[WebServer] [22m        ^^^^^^^^^
[2m[WebServer] [22m    ).generations[0][0],
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 946, in generate_prompt
[2m[WebServer] [22m    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
[2m[WebServer] [22m           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 765, in generate
[2m[WebServer] [22m    self._generate_with_cache(
[2m[WebServer] [22m    ~~~~~~~~~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        m,
[2m[WebServer] [22m        ^^
[2m[WebServer] [22m    ...<2 lines>...
[2m[WebServer] [22m        **kwargs,
[2m[WebServer] [22m        ^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 1011, in _generate_with_cache
[2m[WebServer] [22m    result = self._generate(
[2m[WebServer] [22m        messages, stop=stop, run_manager=run_manager, **kwargs
[2m[WebServer] [22m    )
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py", line 956, in _generate
[2m[WebServer] [22m    return generate_from_stream(stream_iter)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 153, in generate_from_stream
[2m[WebServer] [22m    generation = next(stream, None)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py", line 907, in _stream
[2m[WebServer] [22m    response = self.client.create(**payload)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_utils/_utils.py", line 287, in wrapper
[2m[WebServer] [22m    return func(*args, **kwargs)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py", line 925, in create
[2m[WebServer] [22m    return self._post(
[2m[WebServer] [22m           ~~~~~~~~~~^
[2m[WebServer] [22m        "/chat/completions",
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<43 lines>...
[2m[WebServer] [22m        stream_cls=Stream[ChatCompletionChunk],
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_base_client.py", line 1239, in post
[2m[WebServer] [22m    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
[2m[WebServer] [22m                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_base_client.py", line 1034, in request
[2m[WebServer] [22m    raise self._make_status_error_from_response(err.response) from None
[2m[WebServer] [22mopenai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `gpt-mock` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
[2m[WebServer] [22mDuring task with name 'agent_executor' and id '39b2a477-5bbe-f7cd-0304-eed1a79e0365'
[2m[WebServer] [22mERROR - [AgentNode] Exception in agent node agent-1 (agent_id=1): Error code: 404 - {'error': {'message': 'The model `gpt-mock` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
[2m[WebServer] [22mTraceback (most recent call last):
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/services/langgraph_workflow_engine.py", line 729, in agent_node
[2m[WebServer] [22m    created_messages = await runner.run_thread(db, thread)
[2m[WebServer] [22m                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/managers/agent_runner.py", line 137, in run_thread
[2m[WebServer] [22m    updated_messages = await self._runnable.ainvoke(original_msgs, config)
[2m[WebServer] [22m                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2850, in ainvoke
[2m[WebServer] [22m    async for chunk in self.astream(
[2m[WebServer] [22m    ...<13 lines>...
[2m[WebServer] [22m            chunks.append(chunk)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2732, in astream
[2m[WebServer] [22m    async for _ in runner.atick(
[2m[WebServer] [22m    ...<7 lines>...
[2m[WebServer] [22m            yield o
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 256, in agent_executor
[2m[WebServer] [22m    return _agent_executor_sync(messages, previous=previous)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 248, in _agent_executor_sync
[2m[WebServer] [22m    return asyncio.run(_agent_executor_async(messages, previous=previous))
[2m[WebServer] [22m           ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/runners.py", line 194, in run
[2m[WebServer] [22m    return runner.run(main)
[2m[WebServer] [22m           ~~~~~~~~~~^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/runners.py", line 118, in run
[2m[WebServer] [22m    return self._loop.run_until_complete(task)
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/base_events.py", line 720, in run_until_complete
[2m[WebServer] [22m    return future.result()
[2m[WebServer] [22m           ~~~~~~~~~~~~~^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 208, in _agent_executor_async
[2m[WebServer] [22m    llm_response = await _call_model_async(current_messages)
[2m[WebServer] [22m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 134, in _call_model_async
[2m[WebServer] [22m    return await asyncio.to_thread(_call_model_sync, messages)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/threads.py", line 25, in to_thread
[2m[WebServer] [22m    return await loop.run_in_executor(None, func_call)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/thread.py", line 59, in run
[2m[WebServer] [22m    result = self.fn(*self.args, **self.kwargs)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 127, in _call_model_sync
[2m[WebServer] [22m    return llm_with_tools.invoke(messages)
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/runnables/base.py", line 5416, in invoke
[2m[WebServer] [22m    return self.bound.invoke(
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        input,
[2m[WebServer] [22m        ^^^^^^
[2m[WebServer] [22m        self._merge_configs(config),
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m        **{**self.kwargs, **kwargs},
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 369, in invoke
[2m[WebServer] [22m    self.generate_prompt(
[2m[WebServer] [22m    ~~~~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        [self._convert_input(input)],
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<6 lines>...
[2m[WebServer] [22m        **kwargs,
[2m[WebServer] [22m        ^^^^^^^^^
[2m[WebServer] [22m    ).generations[0][0],
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 946, in generate_prompt
[2m[WebServer] [22m    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
[2m[WebServer] [22m           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 765, in generate
[2m[WebServer] [22m    self._generate_with_cache(
[2m[WebServer] [22m    ~~~~~~~~~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        m,
[2m[WebServer] [22m        ^^
[2m[WebServer] [22m    ...<2 lines>...
[2m[WebServer] [22m        **kwargs,
[2m[WebServer] [22m        ^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 1011, in _generate_with_cache
[2m[WebServer] [22m    result = self._generate(
[2m[WebServer] [22m        messages, stop=stop, run_manager=run_manager, **kwargs
[2m[WebServer] [22m    )
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py", line 956, in _generate
[2m[WebServer] [22m    return generate_from_stream(stream_iter)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 153, in generate_from_stream
[2m[WebServer] [22m    generation = next(stream, None)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py", line 907, in _stream
[2m[WebServer] [22m    response = self.client.create(**payload)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_utils/_utils.py", line 287, in wrapper
[2m[WebServer] [22m    return func(*args, **kwargs)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py", line 925, in create
[2m[WebServer] [22m    return self._post(
[2m[WebServer] [22m           ~~~~~~~~~~^
[2m[WebServer] [22m        "/chat/completions",
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<43 lines>...
[2m[WebServer] [22m        stream_cls=Stream[ChatCompletionChunk],
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_base_client.py", line 1239, in post
[2m[WebServer] [22m    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
[2m[WebServer] [22m                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_base_client.py", line 1034, in request
[2m[WebServer] [22m    raise self._make_status_error_from_response(err.response) from None
[2m[WebServer] [22mopenai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `gpt-mock` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
[2m[WebServer] [22mDuring task with name 'agent_executor' and id '39b2a477-5bbe-f7cd-0304-eed1a79e0365'
[2m[WebServer] [22mERROR - [AgentNode] Updated node_state to 'failed' in DB
[2m[WebServer] [22mERROR - [AgentNode] Re-raising exception to fail workflow execution
[2m[WebServer] [22mERROR - [LangGraphEngine] Execution failed â€“ execution_id=1
[2m[WebServer] [22mTraceback (most recent call last):
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/services/langgraph_workflow_engine.py", line 146, in execute_workflow
[2m[WebServer] [22m    await self._execute_workflow_internal(workflow, execution, db)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/services/langgraph_workflow_engine.py", line 214, in _execute_workflow_internal
[2m[WebServer] [22m    async for chunk in graph.astream(initial_state, config):
[2m[WebServer] [22m    ...<36 lines>...
[2m[WebServer] [22m            logger.warning(f"[LangGraphEngine] Received empty chunk #{chunk_count}")
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2732, in astream
[2m[WebServer] [22m    async for _ in runner.atick(
[2m[WebServer] [22m    ...<7 lines>...
[2m[WebServer] [22m            yield o
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/services/langgraph_workflow_engine.py", line 729, in agent_node
[2m[WebServer] [22m    created_messages = await runner.run_thread(db, thread)
[2m[WebServer] [22m                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/managers/agent_runner.py", line 137, in run_thread
[2m[WebServer] [22m    updated_messages = await self._runnable.ainvoke(original_msgs, config)
[2m[WebServer] [22m                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2850, in ainvoke
[2m[WebServer] [22m    async for chunk in self.astream(
[2m[WebServer] [22m    ...<13 lines>...
[2m[WebServer] [22m            chunks.append(chunk)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2732, in astream
[2m[WebServer] [22m    async for _ in runner.atick(
[2m[WebServer] [22m    ...<7 lines>...
[2m[WebServer] [22m            yield o
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 256, in agent_executor
[2m[WebServer] [22m    return _agent_executor_sync(messages, previous=previous)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 248, in _agent_executor_sync
[2m[WebServer] [22m    return asyncio.run(_agent_executor_async(messages, previous=previous))
[2m[WebServer] [22m           ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/runners.py", line 194, in run
[2m[WebServer] [22m    return runner.run(main)
[2m[WebServer] [22m           ~~~~~~~~~~^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/runners.py", line 118, in run
[2m[WebServer] [22m    return self._loop.run_until_complete(task)
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/base_events.py", line 720, in run_until_complete
[2m[WebServer] [22m    return future.result()
[2m[WebServer] [22m           ~~~~~~~~~~~~~^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 208, in _agent_executor_async
[2m[WebServer] [22m    llm_response = await _call_model_async(current_messages)
[2m[WebServer] [22m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 134, in _call_model_async
[2m[WebServer] [22m    return await asyncio.to_thread(_call_model_sync, messages)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/threads.py", line 25, in to_thread
[2m[WebServer] [22m    return await loop.run_in_executor(None, func_call)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/thread.py", line 59, in run
[2m[WebServer] [22m    result = self.fn(*self.args, **self.kwargs)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 127, in _call_model_sync
[2m[WebServer] [22m    return llm_with_tools.invoke(messages)
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/runnables/base.py", line 5416, in invoke
[2m[WebServer] [22m    return self.bound.invoke(
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        input,
[2m[WebServer] [22m        ^^^^^^
[2m[WebServer] [22m        self._merge_configs(config),
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m        **{**self.kwargs, **kwargs},
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 369, in invoke
[2m[WebServer] [22m    self.generate_prompt(
[2m[WebServer] [22m    ~~~~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        [self._convert_input(input)],
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<6 lines>...
[2m[WebServer] [22m        **kwargs,
[2m[WebServer] [22m        ^^^^^^^^^
[2m[WebServer] [22m    ).generations[0][0],
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 946, in generate_prompt
[2m[WebServer] [22m    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
[2m[WebServer] [22m           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 765, in generate
[2m[WebServer] [22m    self._generate_with_cache(
[2m[WebServer] [22m    ~~~~~~~~~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        m,
[2m[WebServer] [22m        ^^
[2m[WebServer] [22m    ...<2 lines>...
[2m[WebServer] [22m        **kwargs,
[2m[WebServer] [22m        ^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 1011, in _generate_with_cache
[2m[WebServer] [22m    result = self._generate(
[2m[WebServer] [22m        messages, stop=stop, run_manager=run_manager, **kwargs
[2m[WebServer] [22m    )
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py", line 956, in _generate
[2m[WebServer] [22m    return generate_from_stream(stream_iter)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 153, in generate_from_stream
[2m[WebServer] [22m    generation = next(stream, None)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py", line 907, in _stream
[2m[WebServer] [22m    response = self.client.create(**payload)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_utils/_utils.py", line 287, in wrapper
[2m[WebServer] [22m    return func(*args, **kwargs)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py", line 925, in create
[2m[WebServer] [22m    return self._post(
[2m[WebServer] [22m           ~~~~~~~~~~^
[2m[WebServer] [22m        "/chat/completions",
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<43 lines>...
[2m[WebServer] [22m        stream_cls=Stream[ChatCompletionChunk],
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_base_client.py", line 1239, in post
[2m[WebServer] [22m    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
[2m[WebServer] [22m                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_base_client.py", line 1034, in request
[2m[WebServer] [22m    raise self._make_status_error_from_response(err.response) from None
[2m[WebServer] [22mopenai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `gpt-mock` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
[2m[WebServer] [22mDuring task with name 'agent_executor' and id '39b2a477-5bbe-f7cd-0304-eed1a79e0365'
[2m[WebServer] [22mDuring task with name 'agent-1' and id 'f81e95f1-9391-261b-9cc8-e6e647888306'
[2m[WebServer] [22mERROR - Unhandled exception: Error code: 404 - {'error': {'message': 'The model `gpt-mock` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
[2m[WebServer] [22mTraceback (most recent call last):
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/middleware/errors.py", line 165, in __call__
[2m[WebServer] [22m    await self.app(scope, receive, _send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/middleware/worker_db.py", line 101, in __call__
[2m[WebServer] [22m    await self.app(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/middleware/cors.py", line 85, in __call__
[2m[WebServer] [22m    await self.app(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/middleware/exceptions.py", line 62, in __call__
[2m[WebServer] [22m    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
[2m[WebServer] [22m    raise exc
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
[2m[WebServer] [22m    await app(scope, receive, sender)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/routing.py", line 714, in __call__
[2m[WebServer] [22m    await self.middleware_stack(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/routing.py", line 734, in app
[2m[WebServer] [22m    await route.handle(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/routing.py", line 288, in handle
[2m[WebServer] [22m    await self.app(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/routing.py", line 76, in app
[2m[WebServer] [22m    await wrap_app_handling_exceptions(app, request)(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
[2m[WebServer] [22m    raise exc
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
[2m[WebServer] [22m    await app(scope, receive, sender)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/routing.py", line 73, in app
[2m[WebServer] [22m    response = await f(request)
[2m[WebServer] [22m               ^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/fastapi/routing.py", line 301, in app
[2m[WebServer] [22m    raw_response = await run_endpoint_function(
[2m[WebServer] [22m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<3 lines>...
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/fastapi/routing.py", line 212, in run_endpoint_function
[2m[WebServer] [22m    return await dependant.call(**values)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/routers/workflow_executions.py", line 74, in start_workflow_execution
[2m[WebServer] [22m    execution_id = await langgraph_workflow_engine.execute_workflow(workflow_id)
[2m[WebServer] [22m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/services/langgraph_workflow_engine.py", line 146, in execute_workflow
[2m[WebServer] [22m    await self._execute_workflow_internal(workflow, execution, db)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/services/langgraph_workflow_engine.py", line 214, in _execute_workflow_internal
[2m[WebServer] [22m    async for chunk in graph.astream(initial_state, config):
[2m[WebServer] [22m    ...<36 lines>...
[2m[WebServer] [22m            logger.warning(f"[LangGraphEngine] Received empty chunk #{chunk_count}")
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2732, in astream
[2m[WebServer] [22m    async for _ in runner.atick(
[2m[WebServer] [22m    ...<7 lines>...
[2m[WebServer] [22m            yield o
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/services/langgraph_workflow_engine.py", line 729, in agent_node
[2m[WebServer] [22m    created_messages = await runner.run_thread(db, thread)
[2m[WebServer] [22m                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/managers/agent_runner.py", line 137, in run_thread
[2m[WebServer] [22m    updated_messages = await self._runnable.ainvoke(original_msgs, config)
[2m[WebServer] [22m                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2850, in ainvoke
[2m[WebServer] [22m    async for chunk in self.astream(
[2m[WebServer] [22m    ...<13 lines>...
[2m[WebServer] [22m            chunks.append(chunk)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2732, in astream
[2m[WebServer] [22m    async for _ in runner.atick(
[2m[WebServer] [22m    ...<7 lines>...
[2m[WebServer] [22m            yield o
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 256, in agent_executor
[2m[WebServer] [22m    return _agent_executor_sync(messages, previous=previous)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 248, in _agent_executor_sync
[2m[WebServer] [22m    return asyncio.run(_agent_executor_async(messages, previous=previous))
[2m[WebServer] [22m           ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/runners.py", line 194, in run
[2m[WebServer] [22m    return runner.run(main)
[2m[WebServer] [22m           ~~~~~~~~~~^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/runners.py", line 118, in run
[2m[WebServer] [22m    return self._loop.run_until_complete(task)
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/base_events.py", line 720, in run_until_complete
[2m[WebServer] [22m    return future.result()
[2m[WebServer] [22m           ~~~~~~~~~~~~~^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 208, in _agent_executor_async
[2m[WebServer] [22m    llm_response = await _call_model_async(current_messages)
[2m[WebServer] [22m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 134, in _call_model_async
[2m[WebServer] [22m    return await asyncio.to_thread(_call_model_sync, messages)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/threads.py", line 25, in to_thread
[2m[WebServer] [22m    return await loop.run_in_executor(None, func_call)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/thread.py", line 59, in run
[2m[WebServer] [22m    result = self.fn(*self.args, **self.kwargs)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 127, in _call_model_sync
[2m[WebServer] [22m    return llm_with_tools.invoke(messages)
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/runnables/base.py", line 5416, in invoke
[2m[WebServer] [22m    return self.bound.invoke(
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        input,
[2m[WebServer] [22m        ^^^^^^
[2m[WebServer] [22m        self._merge_configs(config),
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m        **{**self.kwargs, **kwargs},
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 369, in invoke
[2m[WebServer] [22m    self.generate_prompt(
[2m[WebServer] [22m    ~~~~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        [self._convert_input(input)],
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<6 lines>...
[2m[WebServer] [22m        **kwargs,
[2m[WebServer] [22m        ^^^^^^^^^
[2m[WebServer] [22m    ).generations[0][0],
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 946, in generate_prompt
[2m[WebServer] [22m    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
[2m[WebServer] [22m           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 765, [2m[WebServer] [22min generate
[2m[WebServer] [22m    self._generate_with_cache(
[2m[WebServer] [22m    ~~~~~~~~~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        m,
[2m[WebServer] [22m        ^^
[2m[WebServer] [22m    ...<2 lines>...
[2m[WebServer] [22m        **kwargs,
[2m[WebServer] [22m        ^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 1011, in _generate_with_cache
[2m[WebServer] [22m    result = self._generate(
[2m[WebServer] [22m        messages, stop=stop, run_manager=run_manager, **kwargs
[2m[WebServer] [22m    )
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py", line 956, in _generate
[2m[WebServer] [22m    return generate_from_stream(stream_iter)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 153, in generate_from_stream
[2m[WebServer] [22m    generation = next(stream, None)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py", line 907, in _stream
[2m[WebServer] [22m    response = self.client.create(**payload)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_utils/_utils.py", line 287, in wrapper
[2m[WebServer] [22m    return func(*args, **kwargs)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py", line 925, in create
[2m[WebServer] [22m    return self._post(
[2m[WebServer] [22m           ~~~~~~~~~~^
[2m[WebServer] [22m        "/chat/completions",
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<43 lines>...
[2m[WebServer] [22m        stream_cls=Stream[ChatCompletionChunk],
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_base_client.py", line 1239, in post
[2m[WebServer] [22m    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
[2m[WebServer] [22m                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_base_client.py", line 1034, in request
[2m[WebServer] [22m    raise self._make_status_error_from_response(err.response) from None
[2m[WebServer] [22mopenai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `gpt-mock` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
[2m[WebServer] [22mDuring task with name 'agent_executor' and id '39b2a477-5bbe-f7cd-0304-eed1a79e0365'
[2m[WebServer] [22mDuring task with name 'agent-1' and id 'f81e95f1-9391-261b-9cc8-e6e647888306'
âŒ Workflow execution failed: [33m500[39m
ğŸ“Š Step 5: Testing direct HTTP tool usage...
[2m[WebServer] [22mERROR:    Exception in ASGI application
[2m[WebServer] [22mTraceback (most recent call last):
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/uvicorn/protocols/http/h11_impl.py", line 408, in run_asgi
[2m[WebServer] [22m    result = await app(  # type: ignore[func-returns-value]
[2m[WebServer] [22m             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m        self.scope, self.receive, self.send
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/uvicorn/middleware/proxy_headers.py", line 84, in __call__
[2m[WebServer] [22m    return await self.app(scope, receive, send)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/fastapi/applications.py", line 1054, in __call__
[2m[WebServer] [22m    await super().__call__(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/applications.py", line 112, in __call__
[2m[WebServer] [22m    await self.middleware_stack(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/middleware/errors.py", line 187, in __call__
[2m[WebServer] [22m    raise exc
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/middleware/errors.py", line 165, in __call__
[2m[WebServer] [22m    await self.app(scope, receive, _send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/middleware/worker_db.py", line 101, in __call__
[2m[WebServer] [22m    await self.app(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/middleware/cors.py", line 85, in __call__
[2m[WebServer] [22m    await self.app(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/middleware/exceptions.py", line 62, in __call__
[2m[WebServer] [22m    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
[2m[WebServer] [22m    raise exc
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
[2m[WebServer] [22m    await app(scope, receive, sender)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/routing.py", line 714, in __call__
[2m[WebServer] [22m    await self.middleware_stack(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/routing.py", line 734, in app
[2m[WebServer] [22m    await route.handle(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/routing.py", line 288, in handle
[2m[WebServer] [22m    await self.app(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/routing.py", line 76, in app
[2m[WebServer] [22m    await wrap_app_handling_exceptions(app, request)(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
[2m[WebServer] [22m    raise exc
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
[2m[WebServer] [22m    await app(scope, receive, sender)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/routing.py", line 73, in app
[2m[WebServer] [22m    response = await f(request)
[2m[WebServer] [22m               ^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/fastapi/routing.py", line 301, in app
[2m[WebServer] [22m    raw_response = await run_endpoint_function(
[2m[WebServer] [22m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<3 lines>...
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/fastapi/routing.py", line 212, in run_endpoint_function
[2m[WebServer] [22m    return await dependant.call(**values)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/routers/workflow_executions.py", line 74, in start_workflow_execution
[2m[WebServer] [22m    execution_id = await langgraph_workflow_engine.execute_workflow(workflow_id)
[2m[WebServer] [22m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/services/langgraph_workflow_engine.py", line 146, in execute_workflow
[2m[WebServer] [22m    await self._execute_workflow_internal(workflow, execution, db)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/services/langgraph_workflow_engine.py", line 214, in _execute_workflow_internal
[2m[WebServer] [22m    async for chunk in graph.astream(initial_state, config):
[2m[WebServer] [22m    ...<36 lines>...
[2m[WebServer] [22m            logger.warning(f"[LangGraphEngine] Received empty chunk #{chunk_count}")
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2732, in astream
[2m[WebServer] [22m    async for _ in runner.atick(
[2m[WebServer] [22m    ...<7 lines>...
[2m[WebServer] [22m            yield o
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/services/langgraph_workflow_engine.py", line 729, in agent_node
[2m[WebServer] [22m    created_messages = await runner.run_thread(db, thread)
[2m[WebServer] [22m                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/managers/agent_runner.py", line 137, in run_thread
[2m[WebServer] [22m    updated_messages = await self._runnable.ainvoke(original_msgs, config)
[2m[WebServer] [22m                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2850, in ainvoke
[2m[WebServer] [22m    async for chunk in self.astream(
[2m[WebServer] [22m    ...<13 lines>...
[2m[WebServer] [22m            chunks.append(chunk)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2732, in astream
[2m[WebServer] [22m    async for _ in runner.atick(
[2m[WebServer] [22m    ...<7 lines>...
[2m[WebServer] [22m            yield o
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 256, in agent_executor
[2m[WebServer] [22m    return _agent_executor_sync(messages, previous=previous)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 248, in _agent_executor_sync
[2m[WebServer] [22m    return asyncio.run(_agent_executor_async(messages, previous=previous))
[2m[WebServer] [22m           ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/runners.py", line 194, in run
[2m[WebServer] [22m    return runner.run(main)
[2m[WebServer] [22m           ~~~~~~~~~~^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/runners.py", line 118, in run
[2m[WebServer] [22m    return self._loop.run_until_complete(task)
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/base_events.py", line 720, in run_until_complete
[2m[WebServer] [22m    return future.result()
[2m[WebServer] [22m           ~~~~~~~~~~~~~^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 208, in _agent_executor_async
[2m[WebServer] [22m    llm_response = await _call_model_async(current_messages)
[2m[WebServer] [22m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 134, in _call_model_async
[2m[WebServer] [22m    return await asyncio.to_thread(_call_model_sync, messages)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/threads.py", line 25, in to_thread
[2m[WebServer] [22m    return await loop.run_in_executor(None, func_call)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/thread.py", line 59, in run
[2m[WebServer] [22m    result = self.fn(*self.args, **self.kwargs)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 127, in _call_model_sync
[2m[WebServer] [22m    return llm_with_tools.invoke(messages)
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/runnables/base.py", line 5416, in invoke
[2m[WebServer] [22m    return self.bound.invoke(
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        input,
[2m[WebServer] [22m        ^^^^^^
[2m[WebServer] [22m        self._merge_configs(config),
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^[2m[WebServer] [22m^^^^^^^^^
[2m[WebServer] [22m        **{**self.kwargs, **kwargs},
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 369, in invoke
[2m[WebServer] [22m    self.generate_prompt(
[2m[WebServer] [22m    ~~~~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        [self._convert_input(input)],
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<6 lines>...
[2m[WebServer] [22m        **kwargs,
[2m[WebServer] [22m        ^^^^^^^^^
[2m[WebServer] [22m    ).generations[0][0],
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 946, in generate_prompt
[2m[WebServer] [22m    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
[2m[WebServer] [22m           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 765, in generate
[2m[WebServer] [22m    self._generate_with_cache(
[2m[WebServer] [22m    ~~~~~~~~~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        m,
[2m[WebServer] [22m        ^^
[2m[WebServer] [22m    ...<2 lines>...
[2m[WebServer] [22m        **kwargs,
[2m[WebServer] [22m        ^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 1011, in _generate_with_cache
[2m[WebServer] [22m    result = self._generate(
[2m[WebServer] [22m        messages, stop=stop, run_manager=run_manager, **kwargs
[2m[WebServer] [22m    )
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py", line 956, in _generate
[2m[WebServer] [22m    return generate_from_stream(stream_iter)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 153, in generate_from_stream
[2m[WebServer] [22m    generation = next(stream, None)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py", line 907, in _stream
[2m[WebServer] [22m    response = self.client.create(**payload)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_utils/_utils.py", line 287, in wrapper
[2m[WebServer] [22m    return func(*args, **kwargs)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py", line 925, in create
[2m[WebServer] [22m    return self._post(
[2m[WebServer] [22m           ~~~~~~~~~~^
[2m[WebServer] [22m        "/chat/completions",
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<43 lines>...
[2m[WebServer] [22m        stream_cls=Stream[ChatCompletionChunk],
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_base_client.py", line 1239, in post
[2m[WebServer] [22m    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
[2m[WebServer] [22m                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_base_client.py", line 1034, in request
[2m[WebServer] [22m    raise self._make_status_error_from_response(err.response) from None
[2m[WebServer] [22mopenai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `gpt-mock` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
[2m[WebServer] [22mDuring task with name 'agent_executor' and id '39b2a477-5bbe-f7cd-0304-eed1a79e0365'
[2m[WebServer] [22mDuring task with name 'agent-1' and id 'f81e95f1-9391-261b-9cc8-e6e647888306'
ğŸ“Š Tools endpoint not available or error: apiRequestContext.get: read ECONNRESET
Call log:
[2m  - â†’ GET http://localhost:8001/api/tools[22m
[2m    - user-agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/136.0.7103.25 Safari/537.36[22m
[2m    - accept: */*[22m
[2m    - accept-encoding: gzip,deflate,br[22m
[2m    - X-Test-Worker: 1[22m

ğŸ“Š Step 6: Checking UI for workflow execution...
ğŸ“Š Test 1: Detecting canvas nodes...
ğŸ“Š Existing nodes on canvas: [33m0[39m
ğŸ“Š No existing nodes - attempting to create nodes for connection test...
ğŸ“Š Test 2: Detecting connection handles...
ğŸ“Š Connection handles found: [33m0[39m
âš ï¸  No connection handles detected - may need UI implementation
âœ… Node connection test completed
  âœ“  33 tests/tool_palette_node_connections.spec.ts:180:7 â€º Tool Palette and Node Connections â€º Node connection handle detection and interaction (3.7s)
ğŸ“Š Execute buttons found: [33m0[39m
ğŸ“Š Run buttons found: [33m0[39m
ğŸ“Š Workflow elements found: [33m0[39m
âœ… Workflow execution test completed
ğŸ“Š Summary: Workflow execution infrastructure validated
  âœ“  36 tests/workflow_execution_http.spec.ts:15:7 â€º Workflow Execution with HTTP Tools â€º Execute workflow with HTTP tool and verify requests (2.9s)
ğŸ§¹ Starting test environment cleanup...
âœ… Test database cleanup completed
âœ… Test environment cleanup completed

  36 passed (1.1m)
