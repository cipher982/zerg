[1A[2K[2m[WebServer] [22m[build-only] 🔧 building frontend (debug)…

[1A[2K[2m[WebServer] [22m[build-only] 🏗  wasm-pack build …

[1A[2K[2m[WebServer] [22m[INFO]: 🎯  Checking for the Wasm target...

[1A[2K[2m[WebServer] [22m[INFO]: 🌀  Compiling to Wasm...

[1A[2K[2m[WebServer] [22mwarning: unused import: `ws_manager::init_chat_view_ws`
[2m[WebServer] [22m --> src/components/chat/mod.rs:2:9
[2m[WebServer] [22m  |
[2m[WebServer] [22m2 | pub use ws_manager::init_chat_view_ws;
[2m[WebServer] [22m  |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  

[1A[2K[2m[WebServer] [22m|
[2m[WebServer] [22m  = note: `#[warn(unused_imports)]` on by default
[2m[WebServer] [22m
[2m[WebServer] [22mwarning: unused import: `super::*`
[2m[WebServer] [22m  --> src/generated/tool_definitions.rs:83:9
[2m[WebServer] [22m   |
[2m[WebServer] [22m83 |     use super::*;
[2m[WebServer] [22m   |         ^^^^^^^^
[2m[WebServer] [22m

[1A[2K[2m[WebServer] [22mwarning: `agent-platform-frontend` (lib) generated 2 warnings (run `cargo fix --lib -p agent-platform-frontend` to apply 2 suggestions)
[2m[WebServer] [22m    Finished `dev` profile [unoptimized + debuginfo] target(s) in 0.03s

[1A[2K[2m[WebServer] [22m[INFO]: ⬇️  Installing wasm-bindgen...

[1A[2K[2m[WebServer] [22m[INFO]: Optional fields missing from Cargo.toml: 'description', 'repository', and 'license'. These are not necessary, but recommended

[1A[2K[2m[WebServer] [22m[INFO]: ✨   Done in 0.48s
[2m[WebServer] [22m[INFO]: 📦   Your wasm pkg is ready to publish at /Users/davidrose/git/zerg/frontend/pkg.

[1A[2K[2m[WebServer] [22m[build-only] 📦 copying WASM artifacts to www...

[1A[2K[2m[WebServer] [22m[build-only] ✍️  writing bootstrap.js …

[1A[2K[2m[WebServer] [22m[build-only] ✍️  writing config.js …

[1A[2K[2m[WebServer] [22m[build-only] ✅ build complete (output in frontend/www/)


Running 36 tests using 2 workers

[1A[2K[1/36] tests/accessibility_ui_ux.spec.ts:113:7 › Accessibility and UI/UX › Keyboard navigation functionality
[1A[2K[2/36] tests/accessibility_ui_ux.spec.ts:18:7 › Accessibility and UI/UX › WCAG compliance and semantic markup
[1A[2Ktests/accessibility_ui_ux.spec.ts:18:7 › Accessibility and UI/UX › WCAG compliance and semantic markup
🚀 Starting WCAG compliance test...

[1A[2Ktests/accessibility_ui_ux.spec.ts:113:7 › Accessibility and UI/UX › Keyboard navigation functionality
🚀 Starting keyboard navigation test...

[1A[2Ktests/accessibility_ui_ux.spec.ts:18:7 › Accessibility and UI/UX › WCAG compliance and semantic markup
📊 Worker ID: 0

[1A[2Ktests/accessibility_ui_ux.spec.ts:113:7 › Accessibility and UI/UX › Keyboard navigation functionality
📊 Test 1: Testing tab order...

[1A[2K📊 Tab 1: BUTTON [create-agent-btn]

[1A[2K📊 Tab 2: BUTTON [reset-db-btn]

[1A[2K📊 Tab 3: BUTTON

[1A[2K📊 Tab 4: BUTTON [global-dashboard-tab]

[1A[2K📊 Tab 5: BUTTON [global-canvas-tab]

[1A[2K📊 Tab 6: BODY

[1A[2K📊 Tab 7: BUTTON [create-agent-btn]

[1A[2Ktests/accessibility_ui_ux.spec.ts:18:7 › Accessibility and UI/UX › WCAG compliance and semantic markup
📊 Test 1: Checking semantic structure...

[1A[2Ktests/accessibility_ui_ux.spec.ts:113:7 › Accessibility and UI/UX › Keyboard navigation functionality
📊 Tab 8: BUTTON [reset-db-btn]

[1A[2Ktests/accessibility_ui_ux.spec.ts:18:7 › Accessibility and UI/UX › WCAG compliance and semantic markup
📊 Semantic elements found: {
  header: [33m0[39m,
  nav: [33m0[39m,
  main: [33m0[39m,
  section: [33m0[39m,
  article: [33m0[39m,
  aside: [33m0[39m,
  footer: [33m0[39m
}

[1A[2K⚠️  Consider adding semantic HTML elements

[1A[2K📊 Test 2: Checking heading hierarchy...

[1A[2K📊 Heading structure: { h1: [33m1[39m, h2: [33m1[39m, h3: [33m0[39m, h4: [33m0[39m, h5: [33m0[39m, h6: [33m0[39m }

[1A[2K✅ Page has primary heading (h1)

[1A[2K📊 Test 3: Checking ARIA attributes...

[1A[2K📊 ARIA attributes found: {
  [32m'aria-label'[39m: [33m1[39m,
  [32m'aria-labelledby'[39m: [33m0[39m,
  [32m'aria-describedby'[39m: [33m0[39m,
  [32m'aria-hidden'[39m: [33m1[39m,
  role: [33m1[39m,
  [32m'aria-expanded'[39m: [33m0[39m
}

[1A[2K✅ ARIA attributes are being used

[1A[2K📊 Test 4: Checking form accessibility...

[1A[2K📊 Form elements found: [33m11[39m

[1A[2K📊 Labeled form elements: [33m2[39m

[1A[2K✅ Form elements have labels

[1A[2K✅ WCAG compliance test completed

[1A[2K[3/36] tests/accessibility_ui_ux.spec.ts:196:7 › Accessibility and UI/UX › Screen reader compatibility
[1A[2Ktests/accessibility_ui_ux.spec.ts:196:7 › Accessibility and UI/UX › Screen reader compatibility
🚀 Starting screen reader compatibility test...

[1A[2Ktests/accessibility_ui_ux.spec.ts:113:7 › Accessibility and UI/UX › Keyboard navigation functionality
📊 Tab 9: BUTTON

[1A[2K📊 Tab 10: BUTTON [global-dashboard-tab]

[1A[2K📊 Unique focusable elements: [33m6[39m

[1A[2K✅ Multiple elements are keyboard accessible

[1A[2K📊 Test 2: Testing escape key functionality...

[1A[2K✅ Escape key press handled

[1A[2K📊 Test 3: Testing enter key activation...

[1A[2K✅ Enter key activation tested

[1A[2K📊 Test 4: Testing arrow key navigation...

[1A[2K✅ Keyboard navigation test completed

[1A[2K[4/36] tests/accessibility_ui_ux.spec.ts:274:7 › Accessibility and UI/UX › Color contrast and visual accessibility
[1A[2Ktests/accessibility_ui_ux.spec.ts:274:7 › Accessibility and UI/UX › Color contrast and visual accessibility
🚀 Starting color contrast test...

[1A[2Ktests/accessibility_ui_ux.spec.ts:196:7 › Accessibility and UI/UX › Screen reader compatibility
📊 Test 1: Checking page title and structure...

[1A[2K📊 Page title: AI Agent Platform

[1A[2K✅ Page has a descriptive title

[1A[2K📊 Test 2: Checking image alt text...

[1A[2K📊 Total images: [33m0[39m

[1A[2K📊 Images with alt text: [33m0[39m

[1A[2K📊 Decorative images (empty alt): [33m0[39m

[1A[2K📊 No images found on page

[1A[2K📊 Test 3: Checking link accessibility...

[1A[2K📊 Total links: [33m0[39m

[1A[2K📊 Test 4: Checking live regions...

[1A[2K📊 Live regions found: [33m0[39m

[1A[2K📊 Status/alert elements: [33m0[39m

[1A[2K📊 No live regions found (may not be needed)

[1A[2K✅ Screen reader compatibility test completed

[1A[2K[5/36] tests/accessibility_ui_ux.spec.ts:372:7 › Accessibility and UI/UX › Responsive design and mobile compatibility
[1A[2Ktests/accessibility_ui_ux.spec.ts:372:7 › Accessibility and UI/UX › Responsive design and mobile compatibility
🚀 Starting responsive design test...

[1A[2K📊 Test 1: Testing mobile viewport...

[1A[2Ktests/accessibility_ui_ux.spec.ts:274:7 › Accessibility and UI/UX › Color contrast and visual accessibility
📊 Test 1: Analyzing color usage...

[1A[2K📊 Color-based indicators: [33m1[39m

[1A[2K📊 Icon-based indicators: [33m0[39m

[1A[2K⚠️  Consider adding icons or text to supplement color information

[1A[2K📊 Test 2: Checking focus indicators...

[1A[2K📊 Focus styles: {
  outline: [32m'rgb(0, 95, 204) auto 1px'[39m,
  outlineColor: [32m'rgb(0, 95, 204)'[39m,
  outlineWidth: [32m'1px'[39m,
  boxShadow: [32m'none'[39m,
  border: [32m'0px none rgb(10, 10, 15)'[39m
}

[1A[2K✅ Focus indicators are visible

[1A[2K📊 Test 3: Testing text scalability...

[1A[2K📊 Original text sizes: [
  { fontSize: [32m'14px'[39m, lineHeight: [32m'normal'[39m },
  { fontSize: [32m'14px'[39m, lineHeight: [32m'normal'[39m },
  { fontSize: [32m'14px'[39m, lineHeight: [32m'normal'[39m }
]

[1A[2K📊 Scaled text sizes: [
  { fontSize: [32m'19.2px'[39m, lineHeight: [32m'normal'[39m },
  { fontSize: [32m'19.2px'[39m, lineHeight: [32m'normal'[39m },
  { fontSize: [32m'19.2px'[39m, lineHeight: [32m'normal'[39m }
]

[1A[2K✅ Text scalability tested

[1A[2K✅ Color contrast test completed

[1A[2K[6/36] tests/accessibility_ui_ux.spec.ts:467:7 › Accessibility and UI/UX › User workflow usability testing
[1A[2Ktests/accessibility_ui_ux.spec.ts:467:7 › Accessibility and UI/UX › User workflow usability testing
🚀 Starting user workflow usability test...

[1A[2K📊 Test 1: Testing agent creation workflow...

[1A[2Ktests/accessibility_ui_ux.spec.ts:372:7 › Accessibility and UI/UX › Responsive design and mobile compatibility
📊 Mobile layout: {
  bodyWidth: [33m375[39m,
  hasHorizontalScroll: [33mtrue[39m,
  navigationVisible: [33mfalse[39m,
  mainContentVisible: [33mfalse[39m
}

[1A[2K⚠️  Page has horizontal scroll on mobile

[1A[2K📊 Test 2: Testing tablet viewport...

[1A[2K📊 Tablet layout: { bodyWidth: [33m768[39m, hasHorizontalScroll: [33mfalse[39m }

[1A[2K📊 Test 3: Testing desktop viewport...

[1A[2K📊 Desktop layout: { bodyWidth: [33m1920[39m, hasHorizontalScroll: [33mfalse[39m }

[1A[2K📊 Test 4: Testing touch interactions...

[1A[2K📊 Touchable elements: [33m18[39m

[1A[2K📊 Touch target sizes: [
  { width: [33m114.46875[39m, height: [33m23[39m, area: [33m2632.78125[39m },
  { width: [33m109.75[39m, height: [33m30[39m, area: [33m3292.5[39m },
  { width: [33m27.734375[39m, height: [33m22[39m, area: [33m610.15625[39m },
  { width: [33m148.96875[39m, height: [33m43[39m, area: [33m6405.65625[39m },
  { width: [33m127.9375[39m, height: [33m43[39m, area: [33m5501.3125[39m }
]

[1A[2K📊 Adequate touch targets (44x44px+): [33m0[39m

[1A[2K✅ Responsive design test completed

[1A[2K[7/36] tests/agent_creation_full.spec.ts:15:7 › Agent Creation Full Workflow › Complete agent creation and isolation test
[1A[2Ktests/agent_creation_full.spec.ts:15:7 › Agent Creation Full Workflow › Complete agent creation and isolation test
🔍 Starting complete agent creation test...

[1A[2K📊 Worker ID: 0

[1A[2K📊 Step 0: Resetting database...

[1A[2K[2m[WebServer] [22mWARNING - Resetting database - dropping all tables

[1A[2K✅ Database reset successful

[1A[2K📊 Step 1: Verifying empty state...

[1A[2K📊 Initial agent count: [33m0[39m

[1A[2K📊 Step 2: Creating agent via API...

[1A[2K📊 Agent creation status: [33m201[39m

[1A[2K📊 Created agent ID: [33m1[39m

[1A[2K📊 Created agent name: Test Agent Worker 0

[1A[2K📊 Step 3: Verifying agent appears in list...

[1A[2K📊 Updated agent count: [33m1[39m

[1A[2K✅ Agent found in list with correct data

[1A[2K📊 Step 5: Testing UI integration...

[1A[2Ktests/accessibility_ui_ux.spec.ts:467:7 › Accessibility and UI/UX › User workflow usability testing
📊 Create buttons found: [33m2[39m

[1A[2K📊 Test agent created: [33m2[39m

[1A[2K📊 Agent visible in dashboard: [33mfalse[39m

[1A[2K📊 Canvas workflow elements: { canvas: [33m0[39m, agentShelf: [33m0[39m, toolPalette: [33m0[39m }

[1A[2K📊 User workflow steps completed: [33m3[39m

[1A[2K📊 Total workflow time: [33m1616[39m ms

[1A[2K📊 Average step time: [33m539[39m ms

[1A[2K✅ User workflow is responsive

[1A[2K📊 Test 2: Testing error recovery...

[1A[2Ktests/agent_creation_full.spec.ts:15:7 › Agent Creation Full Workflow › Complete agent creation and isolation test
📊 Agent visible in UI: [33mtrue[39m

[1A[2K✅ Agent successfully appears in UI

[1A[2K📊 Step 6: Creating second agent for isolation test...

[1A[2K📊 Second agent created with ID: [33m3[39m

[1A[2K📊 Step 7: Verifying agent isolation...

[1A[2K📊 Final agent count: [33m3[39m

[1A[2K📊 Worker-specific agent count: [33m2[39m

[1A[2K✅ Complete agent creation and isolation test passed!

[1A[2K[8/36] tests/canvas_complete_workflow.spec.ts:17:7 › Complete Canvas Workflow › End-to-end canvas workflow with agent and tool execution
[1A[2Ktests/canvas_complete_workflow.spec.ts:17:7 › Complete Canvas Workflow › End-to-end canvas workflow with agent and tool execution
🚀 Starting complete canvas workflow test...

[1A[2K📊 Worker ID: 0

[1A[2K📊 Step 1: Creating test agent...

[1A[2K✅ Test agent created with ID: [33m4[39m

[1A[2K📊 Step 2: Navigating to application...

[1A[2Ktests/accessibility_ui_ux.spec.ts:467:7 › Accessibility and UI/UX › User workflow usability testing
📊 Recovery elements found: [33m0[39m

[1A[2K✅ User workflow usability test completed

[1A[2K[9/36] tests/comprehensive_debug.spec.ts:15:7 › Comprehensive Debug › Complete system debug and diagnosis
[1A[2Ktests/comprehensive_debug.spec.ts:15:7 › Comprehensive Debug › Complete system debug and diagnosis
🔍 Starting comprehensive debug test...

[1A[2K📊 Worker ID: 1

[1A[2K📊 NODE_ENV: test

[1A[2K🔍 Test 1: Basic connectivity

[1A[2K📊 Basic connectivity status: [33m200[39m

[1A[2K✅ Backend is accessible

[1A[2K🔍 Test 2: Header transmission

[1A[2K📊 Header transmission status: [33m200[39m

[1A[2K✅ Headers can be sent

[1A[2K🔍 Test 3: Agent GET endpoint

[1A[2K📊 Agent GET status: [33m200[39m

[1A[2K📊 Agent GET count: [33m1[39m

[1A[2K✅ Agent GET endpoint working

[1A[2K🔍 Test 4: Testing different database operations

[1A[2K📊 Testing user endpoint...

[1A[2K📊 User endpoint status: [33m200[39m

[1A[2K📊 User data available: [33mtrue[39m

[1A[2K🔍 Test 5: Workflow creation test

[1A[2K📊 Workflow creation status: [33m422[39m

[1A[2K❌ Workflow creation failed: {"detail":[{"type":"missing","loc":["body","canvas_data"],"msg":"Field required","input":{"name":"Test Workflow 1","description":"Test workflow for debugging"}}]}

[1A[2K🔍 Test 6: Minimal agent creation

[1A[2K📊 Minimal agent creation status: [33m201[39m

[1A[2K📊 Minimal agent created ID: [33m2[39m

[1A[2K✅ Agent creation working with mock model

[1A[2K🔍 Test 7: Database introspection

[1A[2K📊 System health status: [33m404[39m

[1A[2K✅ Comprehensive debug test complete

[1A[2K[10/36] tests/data_persistence_recovery.spec.ts:19:7 › Data Persistence and Recovery › Data persistence across sessions
[1A[2Ktests/data_persistence_recovery.spec.ts:19:7 › Data Persistence and Recovery › Data persistence across sessions
🚀 Starting data persistence test...

[1A[2K📊 Worker ID: 0

[1A[2K📊 Step 0: Resetting database...

[1A[2K[2m[WebServer] [22mWARNING - Resetting database - dropping all tables

[1A[2K✅ Database reset successful

[1A[2K📊 Test 1: Creating persistent data...

[1A[2K📊 Created agent ID: [33m5[39m

[1A[2Ktests/canvas_complete_workflow.spec.ts:17:7 › Complete Canvas Workflow › End-to-end canvas workflow with agent and tool execution
📊 Step 3: Verifying agent in dashboard...

[1A[2K📊 Agent visible in dashboard: [33mtrue[39m

[1A[2K📊 Step 4: Navigating to canvas...

[1A[2K📊 Canvas visible: [33mfalse[39m

[1A[2K✅ Complete canvas workflow test finished

[1A[2K📊 Summary: Basic navigation and UI structure validated

[1A[2K📊 Next: UI implementation needed for full drag-and-drop workflow

[1A[2K[11/36] tests/data_persistence_recovery.spec.ts:127:7 › Data Persistence and Recovery › Auto-save and draft recovery
[1A[2Ktests/data_persistence_recovery.spec.ts:127:7 › Data Persistence and Recovery › Auto-save and draft recovery
🚀 Starting auto-save test...

[1A[2K📊 Test 1: Looking for auto-save functionality...

[1A[2K📊 Form elements found: [33m8[39m

[1A[2K📊 Auto-save indicators: [33m0[39m

[1A[2K📊 Test 2: Testing data recovery after refresh...

[1A[2Ktests/data_persistence_recovery.spec.ts:19:7 › Data Persistence and Recovery › Data persistence across sessions
📊 Agent row visible in UI: [33mfalse[39m

[1A[2K📊 Agent name visible in UI: [33mfalse[39m

[1A[2K📊 Agent in table by name: [33mfalse[39m

[1A[2K📊 Any agents visible in table: [33mtrue[39m

[1A[2K📊 Test 2: Simulating session restart...

[1A[2Ktests/data_persistence_recovery.spec.ts:127:7 › Data Persistence and Recovery › Auto-save and draft recovery
📊 Draft recovery test error: locator.fill: Timeout 5000ms exceeded.
Call log:
[2m  - waiting for locator('input[type="text"], textarea').first()[22m
[2m    - locator resolved to <input type="text" id="agent-name" data-testid="agent-name-input" placeholder="Enter agent name..."/>[22m
[2m    - fill("Recovery test data 1752145640692")[22m
[2m  - attempting fill action[22m
[2m    2 × waiting for element to be visible, enabled and editable[22m
[2m      - element is not visible[22m
[2m    - retrying fill action[22m
[2m    - waiting 20ms[22m
[2m    2 × waiting for element to be visible, enabled and editable[22m
[2m      - element is not visible[22m
[2m    - retrying fill action[22m
[2m      - waiting 100ms[22m
[2m    10 × waiting for element to be visible, enabled and editable[22m
[2m       - element is not visible[22m
[2m     - retrying fill action[22m
[2m       - waiting 500ms[22m


[1A[2K✅ Auto-save test completed

[1A[2K[12/36] tests/data_persistence_recovery.spec.ts:192:7 › Data Persistence and Recovery › Data consistency and integrity
[1A[2Ktests/data_persistence_recovery.spec.ts:192:7 › Data Persistence and Recovery › Data consistency and integrity
🚀 Starting data consistency test...

[1A[2K📊 Test 1: Testing data relationships...

[1A[2Ktests/data_persistence_recovery.spec.ts:19:7 › Data Persistence and Recovery › Data persistence across sessions
📊 Agent visible after restart: [33mfalse[39m

[1A[2K  1) tests/data_persistence_recovery.spec.ts:19:7 › Data Persistence and Recovery › Data persistence across sessions 

    Error: [2mexpect([22m[31mreceived[39m[2m).[22mtoBe[2m([22m[32mexpected[39m[2m) // Object.is equality[22m

    Expected: [32mtrue[39m
    Received: [31mfalse[39m

      108 |     const agentStillVisible = await newPage.locator(`text=${testAgentName}`).isVisible();
      109 |     console.log('📊 Agent visible after restart:', agentStillVisible);
    > 110 |     expect(agentStillVisible).toBe(true);
          |                               ^
      111 |     
      112 |     // Verify via API as well
      113 |     const persistedResponse = await newPage.request.get('http://localhost:8001/api/agents', {
        at /Users/davidrose/git/zerg/e2e/tests/data_persistence_recovery.spec.ts:110:31

    Error Context: test-results/data_persistence_recovery--09f15-persistence-across-sessions/error-context.md


[1A[2Ktests/data_persistence_recovery.spec.ts:192:7 › Data Persistence and Recovery › Data consistency and integrity
📊 Created agent for consistency test: [33m6[39m

[1A[2K[13/36] tests/data_persistence_recovery.spec.ts:313:7 › Data Persistence and Recovery › Data export and import integrity
[1A[2K📊 Created workflow with agent reference: [33m2[39m

[1A[2K📊 Test 2: Testing data integrity...

[1A[2K📊 Initial agent count: [33m6[39m

[1A[2K📊 After creation agent count: [33m7[39m

[1A[2K✅ Data integrity maintained during operations

[1A[2K✅ Data consistency test completed

[1A[2K[14/36] tests/data_persistence_recovery.spec.ts:403:7 › Data Persistence and Recovery › Recovery from data corruption scenarios
[1A[2Ktests/data_persistence_recovery.spec.ts:313:7 › Data Persistence and Recovery › Data export and import integrity
🚀 Starting export/import test...

[1A[2K📊 Test 1: Looking for export functionality...

[1A[2Ktests/data_persistence_recovery.spec.ts:403:7 › Data Persistence and Recovery › Recovery from data corruption scenarios
🚀 Starting data corruption recovery test...

[1A[2K📊 Test 1: Invalid data format recovery...

[1A[2K📊 Corrupt data response status: [33m422[39m

[1A[2K✅ Invalid data properly rejected

[1A[2K📊 Error details provided: [33mtrue[39m

[1A[2K📊 Test 2: System state recovery...

[1A[2K📊 Recovery creation status: [33m201[39m

[1A[2K✅ System recovered and accepts valid data after corruption attempt

[1A[2K📊 Test 3: UI state recovery...

[1A[2Ktests/data_persistence_recovery.spec.ts:313:7 › Data Persistence and Recovery › Data export and import integrity
📊 Export buttons found: [33m0[39m

[1A[2K📊 Download buttons found: [33m0[39m

[1A[2K📊 Backup buttons found: [33m0[39m

[1A[2K📊 No export UI elements found (may be in different location)

[1A[2K📊 Test 2: Looking for import functionality...

[1A[2K📊 Import buttons found: [33m0[39m

[1A[2K📊 Upload buttons found: [33m0[39m

[1A[2K📊 File inputs found: [33m0[39m

[1A[2K📊 No import UI elements found (may be in different location)

[1A[2K📊 Test 3: API data integrity verification...

[1A[2Ktests/data_persistence_recovery.spec.ts:403:7 › Data Persistence and Recovery › Recovery from data corruption scenarios
📊 UI loaded successfully: [33mtrue[39m

[1A[2K📊 UI error count: [33m0[39m

[1A[2K✅ UI recovered successfully

[1A[2K✅ Data corruption recovery test completed

[1A[2K[15/36] tests/error_handling_edge_cases.spec.ts:18:7 › Error Handling and Edge Cases › API error handling with invalid data
[1A[2Ktests/error_handling_edge_cases.spec.ts:18:7 › Error Handling and Edge Cases › API error handling with invalid data
🚀 Starting API error handling test...

[1A[2K📊 Worker ID: 0

[1A[2K📊 Test 1: Invalid agent creation - missing fields

[1A[2K📊 Invalid agent creation status: [33m422[39m

[1A[2K📊 Validation error structure: [33mtrue[39m

[1A[2K✅ Validation errors properly returned

[1A[2K📊 Test 2: Invalid JSON payload

[1A[2K📊 Invalid JSON status: [33m422[39m

[1A[2K✅ Invalid JSON properly rejected

[1A[2K📊 Test 3: Large payload handling

[1A[2K📊 Large payload status: [33m201[39m

[1A[2K✅ Large payload accepted (system handles large data)

[1A[2K📊 Test 4: Invalid HTTP methods

[1A[2K📊 Invalid method status: [33m405[39m

[1A[2K✅ Invalid HTTP methods properly rejected

[1A[2K📊 Test 5: Non-existent resource access

[1A[2K📊 Non-existent resource status: [33m404[39m

[1A[2K✅ Non-existent resources return 404

[1A[2K✅ API error handling test completed

[1A[2K[16/36] tests/error_handling_edge_cases.spec.ts:126:7 › Error Handling and Edge Cases › Database constraint and data integrity
[1A[2Ktests/error_handling_edge_cases.spec.ts:126:7 › Error Handling and Edge Cases › Database constraint and data integrity
🚀 Starting database constraint test...

[1A[2K📊 Test 1: Duplicate name handling

[1A[2K📊 First agent created: [33m10[39m

[1A[2K📊 Duplicate creation status: [33m201[39m

[1A[2K✅ Duplicate names allowed (system permits duplicates)

[1A[2K📊 Test 2: Field length validation

[1A[2K📊 Long field status: [33m201[39m

[1A[2K✅ Long fields accepted (no length limits)

[1A[2K✅ Database constraint test completed

[1A[2K[17/36] tests/error_handling_edge_cases.spec.ts:201:7 › Error Handling and Edge Cases › Concurrent operations and race conditions
[1A[2Ktests/error_handling_edge_cases.spec.ts:201:7 › Error Handling and Edge Cases › Concurrent operations and race conditions
🚀 Starting concurrency test...

[1A[2K📊 Test 1: Concurrent agent creation

[1A[2Ktests/data_persistence_recovery.spec.ts:313:7 › Data Persistence and Recovery › Data export and import integrity
📊 Created test agent for export: [33m14[39m

[1A[2K📊 Data integrity on retrieval: [33mtrue[39m

[1A[2K✅ Data maintains integrity during storage/retrieval

[1A[2K✅ Export/import test completed

[1A[2K[18/36] tests/error_handling_edge_cases.spec.ts:261:7 › Error Handling and Edge Cases › UI error state handling
[1A[2Ktests/error_handling_edge_cases.spec.ts:261:7 › Error Handling and Edge Cases › UI error state handling
🚀 Starting UI error state test...

[1A[2Ktests/error_handling_edge_cases.spec.ts:201:7 › Error Handling and Edge Cases › Concurrent operations and race conditions
📊 Concurrent creation success: [33m5[39m

[1A[2K📊 Concurrent creation errors: [33m0[39m

[1A[2K✅ Concurrent operations handled well

[1A[2K📊 Test 2: Rapid-fire GET requests

[1A[2K📊 Rapid requests success: [33m10[39m

[1A[2K✅ Rapid requests handled well

[1A[2K✅ Concurrency test completed

[1A[2K[19/36] tests/multi_user_concurrency.spec.ts:18:7 › Multi-User and Concurrency › Multiple user sessions with data isolation
[1A[2Ktests/multi_user_concurrency.spec.ts:18:7 › Multi-User and Concurrency › Multiple user sessions with data isolation
🚀 Starting multi-user data isolation test...

[1A[2K📊 Created 3 user sessions

[1A[2K📊 Test 1: Creating isolated data per user...

[1A[2Ktests/error_handling_edge_cases.spec.ts:261:7 › Error Handling and Edge Cases › UI error state handling
📊 Test 1: Network connectivity simulation

[1A[2Ktests/multi_user_concurrency.spec.ts:18:7 › Multi-User and Concurrency › Multiple user sessions with data isolation
📊 User 2 created agent: [33m1[39m

[1A[2K📊 User 0 created agent: [33m1[39m

[1A[2Ktests/error_handling_edge_cases.spec.ts:261:7 › Error Handling and Edge Cases › UI error state handling
📊 Error indicators found: [33m0[39m

[1A[2Ktests/multi_user_concurrency.spec.ts:18:7 › Multi-User and Concurrency › Multiple user sessions with data isolation
📊 User 1 created agent: [33m1[39m

[1A[2K📊 Successful agent creations: [33m3[39m / [33m3[39m

[1A[2K📊 Test 2: Verifying data isolation...

[1A[2K📊 User 0 sees own agent: [33mtrue[39m

[1A[2K📊 User 0 sees other users' agents: [33mtrue[39m

[1A[2K📊 User 2 sees own agent: [33mtrue[39m

[1A[2K📊 User 2 sees other users' agents: [33mtrue[39m

[1A[2K📊 User 1 sees own agent: [33mtrue[39m

[1A[2K📊 User 1 sees other users' agents: [33mtrue[39m

[1A[2K📊 Users with proper data isolation: [33m0[39m / [33m3[39m

[1A[2K⚠️  Data isolation may need improvement

[1A[2K✅ Multi-user data isolation test completed

[1A[2K[20/36] tests/multi_user_concurrency.spec.ts:137:7 › Multi-User and Concurrency › Concurrent workflow execution
[1A[2Ktests/multi_user_concurrency.spec.ts:137:7 › Multi-User and Concurrency › Concurrent workflow execution
🚀 Starting concurrent workflow execution test...

[1A[2K📊 Created 3 workflow sessions

[1A[2K📊 Test 1: Creating workflows concurrently...

[1A[2K📊 User 2 created workflow: [33m1[39m

[1A[2K📊 User 1 created workflow: [33m1[39m

[1A[2K📊 User 0 created workflow: [33m1[39m

[1A[2K📊 Successful workflow creations: [33m3[39m / [33m3[39m

[1A[2K📊 Concurrent workflow creation time: [33m11[39m ms

[1A[2K📊 Test 2: Executing workflows concurrently...

[1A[2Ktests/error_handling_edge_cases.spec.ts:261:7 › Error Handling and Edge Cases › UI error state handling
✅ Network connectivity simulation completed

[1A[2K📊 Test 2: Invalid navigation handling

[1A[2K[2m[WebServer] [22mERROR - [AgentRunner] Exception during runnable.ainvoke: Error code: 404 - {'error': {'message': 'The model `gpt-mock` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
[2m[WebServer] [22mTraceback (most recent call last):
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/managers/agent_runner.py", line 137, in run_thread
[2m[WebServer] [22m    updated_messages = await self._runnable.ainvoke(original_msgs, config)
[2m[WebServer] [22m                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2850, in ainvoke
[2m[WebServer] [22m    async for chunk in self.astream(
[2m[WebServer] [22m    ...<13 lines>...
[2m[WebServer] [22m            chunks.append(chunk)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2732, in astream
[2m[WebServer] [22m    async for _ in runner.atick(
[2m[WebServer] [22m    ...<7 lines>...
[2m[WebServer] [22m            yield o
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 256, in agent_executor
[2m[WebServer] [22m    return _agent_executor_sync(messages, previous=previous)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 248, in _agent_executor_sync
[2m[WebServer] [22m    return asyncio.run(_agent_executor_async(messages, previous=previous))
[2m[WebServer] [22m           ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/runners.py", line 194, in run
[2m[WebServer] [22m    return runner.run(main)
[2m[WebServer] [22m           ~~~~~~~~~~^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/runners.py", line 118, in run
[2m[WebServer] [22m    return self._loop.run_until_complete(task)
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/base_events.py", line 720, in run_until_complete
[2m[WebServer] [22m    return future.result()
[2m[WebServer] [22m           ~~~~~~~~~~~~~^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 208, in _agent_executor_async
[2m[WebServer] [22m    llm_response = await _call_model_async(current_messages)
[2m[WebServer] [22m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 134, in _call_model_async
[2m[WebServer] [22m    return await asyncio.to_thread(_call_model_sync, messages)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/threads.py", line 25, in to_thread
[2m[WebServer] [22m    return await loop.run_in_executor(None, func_call)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/thread.py", line 59, in run
[2m[WebServer] [22m    result = self.fn(*self.args, **self.kwargs)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 127, in _call_model_sync
[2m[WebServer] [22m    return llm_with_tools.invoke(messages)
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/runnables/base.py", line 5416, in invoke
[2m[WebServer] [22m    return self.bound.invoke(
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        input,
[2m[WebServer] [22m        ^^^^^^
[2m[WebServer] [22m        self._merge_configs(config),
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m        **{**self.kwargs, **kwargs},
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 369, in invoke
[2m[WebServer] [22m    self.generate_prompt(
[2m[WebServer] [22m    ~~~~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        [self._convert_input(input)],
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<6 lines>...
[2m[WebServer] [22m        **kwargs,
[2m[WebServer] [22m        ^^^^^^^^^
[2m[WebServer] [22m    ).generations[0][0],
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 946, in generate_prompt
[2m[WebServer] [22m    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
[2m[WebServer] [22m           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 765, in generate
[2m[WebServer] [22m    self._generate_with_cache(
[2m[WebServer] [22m    ~~~~~~~~~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        m,
[2m[WebServer] [22m        ^^
[2m[WebServer] [22m    ...<2 lines>...
[2m[WebServer] [22m        **kwargs,
[2m[WebServer] [22m        ^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 1011, in _generate_with_cache
[2m[WebServer] [22m    result = self._generate(
[2m[WebServer] [22m        messages, stop=stop, run_manager=run_manager, **kwargs
[2m[WebServer] [22m    )
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py", line 991, in _generate
[2m[WebServer] [22m    response = self.client.create(**payload)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_utils/_utils.py", line 287, in wrapper
[2m[WebServer] [22m    return func(*args, **kwargs)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py", line 925, in create
[2m[WebServer] [22m    return self._post(
[2m[WebServer] [22m           ~~~~~~~~~~^
[2m[WebServer] [22m        "/chat/completions",
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<43 lines>...
[2m[WebServer] [22m        stream_cls=Stream[ChatCompletionChunk],
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_base_client.py", line 1239, in post
[2m[WebServer] [22m    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
[2m[WebServer] [22m                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_base_client.py", line 1034, in request
[2m[WebServer] [22m    raise self._make_status_error_from_response(err.response) from None
[2m[WebServer] [22mopenai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `gpt-mock` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
[2m[WebServer] [22mDuring task with name 'agent_executor' and id '1ddafec4-5f06-a162-b73f-0a5794ef9643'

[1A[2K[2m[WebServer] [22mERROR - [AgentNode] Exception in agent node agent-1 (agent_id=1): Error code: 404 - {'error': {'message': 'The model `gpt-mock` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
[2m[WebServer] [22mTraceback (most recent call last):
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/services/langgraph_workflow_engine.py", line 729, in agent_node
[2m[WebServer] [22m    created_messages = await runner.run_thread(db, thread)
[2m[WebServer] [22m                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/managers/agent_runner.py", line 137, in run_thread
[2m[WebServer] [22m    updated_messages = await self._runnable.ainvoke(original_msgs, config)
[2m[WebServer] [22m                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2850, in ainvoke
[2m[WebServer] [22m    async for chunk in self.astream(
[2m[WebServer] [22m    ...<13 lines>...
[2m[WebServer] [22m            chunks.append(chunk)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2732, in astream
[2m[WebServer] [22m    async for _ in runner.atick(
[2m[WebServer] [22m    ...<7 lines>...
[2m[WebServer] [22m            yield o
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 256, in agent_executor
[2m[WebServer] [22m    return _agent_executor_sync(messages, previous=previous)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 248, in _agent_executor_sync
[2m[WebServer] [22m    return asyncio.run(_agent_executor_async(messages, previous=previous))
[2m[WebServer] [22m           ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/runners.py", line 194, in run
[2m[WebServer] [22m    return runner.run(main)
[2m[WebServer] [22m           ~~~~~~~~~~^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/runners.py", line 118, in run
[2m[WebServer] [22m    return self._loop.run_until_complete(task)
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/base_events.py", line 720, in run_until_complete
[2m[WebServer] [22m    return future.result()
[2m[WebServer] [22m           ~~~~~~~~~~~~~^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 208, in _agent_executor_async
[2m[WebServer] [22m    llm_response = await _call_model_async(current_messages)
[2m[WebServer] [22m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 134, in _call_model_async
[2m[WebServer] [22m    return await asyncio.to_thread(_call_model_sync, messages)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/threads.py", line 25, in to_thread
[2m[WebServer] [22m    return await loop.run_in_executor(None, func_call)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/thread.py", line 59, in run
[2m[WebServer] [22m    result = self.fn(*self.args, **self.kwargs)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 127, in _call_model_sync
[2m[WebServer] [22m    return llm_with_tools.invoke(messages)
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/runnables/base.py", line 5416, in invoke
[2m[WebServer] [22m    return self.bound.invoke(
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        input,
[2m[WebServer] [22m        ^^^^^^
[2m[WebServer] [22m        self._merge_configs(config),
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m        **{**self.kwargs, **kwargs},
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 369, in invoke
[2m[WebServer] [22m    self.generate_prompt(
[2m[WebServer] [22m    ~~~~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        [self._convert_input(input)],
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<6 lines>...
[2m[WebServer] [22m        **kwargs,
[2m[WebServer] [22m        ^^^^^^^^^
[2m[WebServer] [22m    ).generations[0][0],
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 946, in generate_prompt
[2m[WebServer] [22m    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
[2m[WebServer] [22m           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 765, in generate
[2m[WebServer] [22m    self._generate_with_cache(
[2m[WebServer] [22m    ~~~~~~~~~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        m,
[2m[WebServer] [22m        ^^
[2m[WebServer] [22m    ...<2 lines>...
[2m[WebServer] [22m        **kwargs,
[2m[WebServer] [22m        ^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 1011, in _generate_with_cache
[2m[WebServer] [22m    result = self._generate(
[2m[WebServer] [22m        messages, stop=stop, run_manager=run_manager, **kwargs
[2m[WebServer] [22m    )
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py", line 991, in _generate
[2m[WebServer] [22m    response = self.client.create(**payload)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_utils/_utils.py", line 287, in wrapper
[2m[WebServer] [22m    return func(*args, **kwargs)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py", line 925, in create
[2m[WebServer] [22m    return self._post(
[2m[WebServer] [22m           ~~~~~~~~~~^
[2m[WebServer] [22m        "/chat/completions",
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<43 lines>...
[2m[WebServer] [22m        stream_cls=Stream[ChatCompletionChunk],
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_base_client.py", line 1239, in post
[2m[WebServer] [22m    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
[2m[WebServer] [22m                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_base_client.py", line 1034, in request
[2m[WebServer] [22m    raise self._make_status_error_from_response(err.response) from None
[2m[WebServer] [22mopenai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `gpt-mock` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
[2m[WebServer] [22mDuring task with name 'agent_executor' and id '1ddafec4-5f06-a162-b73f-0a5794ef9643'

[1A[2K[2m[WebServer] [22mERROR - [AgentNode] Updated node_state to 'failed' in DB

[1A[2K[2m[WebServer] [22mERROR - [AgentNode] Re-raising exception to fail workflow execution

[1A[2K[2m[WebServer] [22mERROR - [LangGraphEngine] Execution failed – execution_id=1
[2m[WebServer] [22mTraceback (most recent call last):
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/services/langgraph_workflow_engine.py", line 146, in execute_workflow
[2m[WebServer] [22m    await self._execute_workflow_internal(workflow, execution, db)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/services/langgraph_workflow_engine.py", line 214, in _execute_workflow_internal
[2m[WebServer] [22m    async for chunk in graph.astream(initial_state, config):
[2m[WebServer] [22m    ...<36 lines>...
[2m[WebServer] [22m            logger.warning(f"[LangGraphEngine] Received empty chunk #{chunk_count}")
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2732, in astream
[2m[WebServer] [22m    async for _ in runner.atick(
[2m[WebServer] [22m    ...<7 lines>...
[2m[WebServer] [22m            yield o
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/services/langgraph_workflow_engine.py", line 729, in agent_node
[2m[WebServer] [22m    created_messages = await runner.run_thread(db, thread)
[2m[WebServer] [22m                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/managers/agent_runner.py", line 137, in run_thread
[2m[WebServer] [22m    updated_messages = await self._runnable.ainvoke(original_msgs, config)
[2m[WebServer] [22m                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2850, in ainvoke
[2m[WebServer] [22m    async for chunk in self.astream(
[2m[WebServer] [22m    ...<13 lines>...
[2m[WebServer] [22m            chunks.append(chunk)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2732, in astream
[2m[WebServer] [22m    async for _ in runner.atick(
[2m[WebServer] [22m    ...<7 lines>...
[2m[WebServer] [22m            yield o
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 256, in agent_executor
[2m[WebServer] [22m    return _agent_executor_sync(messages, previous=previous)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 248, in _agent_executor_sync
[2m[WebServer] [22m    return asyncio.run(_agent_executor_async(messages, previous=previous))
[2m[WebServer] [22m           ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/runners.py", line 194, in run
[2m[WebServer] [22m    return runner.run(main)
[2m[WebServer] [22m           ~~~~~~~~~~^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/runners.py", line 118, in run
[2m[WebServer] [22m    return self._loop.run_until_complete(task)
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/base_events.py", line 720, in run_until_complete
[2m[WebServer] [22m    return future.result()
[2m[WebServer] [22m           ~~~~~~~~~~~~~^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 208, in _agent_executor_async
[2m[WebServer] [22m    llm_response = await _call_model_async(current_messages)
[2m[WebServer] [22m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 134, in _call_model_async
[2m[WebServer] [22m    return await asyncio.to_thread(_call_model_sync, messages)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/threads.py", line 25, in to_thread
[2m[WebServer] [22m    return await loop.run_in_executor(None, func_call)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/thread.py", line 59, in run
[2m[WebServer] [22m    result = self.fn(*self.args, **self.kwargs)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 127, in _call_model_sync
[2m[WebServer] [22m    return llm_with_tools.invoke(messages)
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/runnables/base.py", line 5416, in invoke
[2m[WebServer] [22m    return self.bound.invoke(
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        input,
[2m[WebServer] [22m        ^^^^^^
[2m[WebServer] [22m        self._merge_configs(config),
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m        **{**self.kwargs, **kwargs},
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 369, in invoke
[2m[WebServer] [22m    self.generate_prompt(
[2m[WebServer] [22m    ~~~~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        [self._convert_input(input)],
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<6 lines>...
[2m[WebServer] [22m        **kwargs,
[2m[WebServer] [22m        ^^^^^^^^^
[2m[WebServer] [22m    ).generations[0][0],
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 946, in generate_prompt
[2m[WebServer] [22m    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
[2m[WebServer] [22m           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 765, in generate
[2m[WebServer] [22m    self._generate_with_cache(
[2m[WebServer] [22m    ~~~~~~~~~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        m,
[2m[WebServer] [22m        ^^
[2m[WebServer] [22m    ...<2 lines>...
[2m[WebServer] [22m        **kwargs,
[2m[WebServer] [22m        ^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 1011, in _generate_with_cache
[2m[WebServer] [22m    result = self._generate(
[2m[WebServer] [22m        messages, stop=stop, run_manager=run_manager, **kwargs
[2m[WebServer] [22m    )
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py", line 991, in _generate
[2m[WebServer] [22m    response = self.client.create(**payload)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_utils/_utils.py", line 287, in wrapper
[2m[WebServer] [22m    return func(*args, **kwargs)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py", line 925, in create
[2m[WebServer] [22m    return self._post(
[2m[WebServer] [22m           ~~~~~~~~~~^
[2m[WebServer] [22m        "/chat/completions",
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<43 lines>...
[2m[WebServer] [22m        stream_cls=Stream[ChatCompletionChunk],
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_base_client.py", line 1239, in post
[2m[WebServer] [22m    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
[2m[WebServer] [22m                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_base_client.py", line 1034, in request
[2m[WebServer] [22m    raise self._make_status_error_from_response(err.response) from None
[2m[WebServer] [22mopenai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `gpt-mock` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
[2m[WebServer] [22mDuring task with name 'agent_executor' and id '1ddafec4-5f06-a162-b73f-0a5794ef9643'
[2m[WebServer] [22mDuring task with name 'agent-1' and id '87437cbe-c5b1-168e-5158-e1f052752888'

[1A[2K[2m[WebServer] [22mERROR - Unhandled exception: Error code: 404 - {'error': {'message': 'The model `gpt-mock` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
[2m[WebServer] [22mTraceback (most recent call last):
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/middleware/errors.py", line 165, in __call__
[2m[WebServer] [22m    await self.app(scope, receive, _send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/middleware/worker_db.py", line 101, in __call__
[2m[WebServer] [22m    await self.app(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/middleware/cors.py", line 85, in __call__
[2m[WebServer] [22m    await self.app(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/middleware/exceptions.py", line 62, in __call__
[2m[WebServer] [22m    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
[2m[WebServer] [22m    raise exc
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
[2m[WebServer] [22m    await app(scope, receive, sender)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/routing.py", line 714, in __call__
[2m[WebServer] [22m    await self.middleware_stack(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/routing.py", line 734, in app
[2m[WebServer] [22m    await route.handle(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/routing.py", line 288, in handle
[2m[WebServer] [22m    await self.app(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/routing.py", line 76, in app
[2m[WebServer] [22m    await wrap_app_handling_exceptions(app, request)(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
[2m[WebServer] [22m    raise exc
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
[2m[WebServer] [22m    await app(scope, receive, sender)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/routing.py", line 73, in app
[2m[WebServer] [22m    response = await f(request)
[2m[WebServer] [22m               ^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/fastapi/routing.py", line 301, in app
[2m[WebServer] [22m    raw_response = await run_endpoint_function(
[2m[WebServer] [22m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<3 lines>...
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/fastapi/routing.py", line 212, in run_endpoint_function
[2m[WebServer] [22m    return await dependant.call(**values)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/routers/workflow_executions.py", line 74, in start_workflow_execution
[2m[WebServer] [22m    execution_id = await langgraph_workflow_engine.execute_workflow(workflow_id)
[2m[WebServer] [22m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/services/langgraph_workflow_engine.py", line 146, in execute_workflow
[2m[WebServer] [22m    await self._execute_workflow_internal(workflow, execution, db)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/services/langgraph_workflow_engine.py", line 214, in _execute_workflow_internal
[2m[WebServer] [22m    async for chunk in graph.astream(initial_state, config):
[2m[WebServer] [22m    ...<36 lines>...
[2m[WebServer] [22m            logger.warning(f"[LangGraphEngine] Received empty chunk #{chunk_count}")
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2732, in astream
[2m[WebServer] [22m    async for _ in runner.atick(
[2m[WebServer] [22m    ...<7 lines>...
[2m[WebServer] [22m            yield o
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/services/langgraph_workflow_engine.py", line 729, in agent_node
[2m[WebServer] [22m    created_messages = await runner.run_thread(db, thread)
[2m[WebServer] [22m                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/managers/agent_runner.py", line 137, in run_thread
[2m[WebServer] [22m    updated_messages = await self._runnable.ainvoke(original_msgs, config)
[2m[WebServer] [22m                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2850, in ainvoke
[2m[WebServer] [22m    async for chunk in self.astream(
[2m[WebServer] [22m    ...<13 lines>...
[2m[WebServer] [22m            chunks.append(chunk)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2732, in astream
[2m[WebServer] [22m    async for _ in runner.atick(
[2m[WebServer] [22m    ...<7 lines>...
[2m[WebServer] [22m            yield o
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 256, in agent_executor
[2m[WebServer] [22m    return _agent_executor_sync(messages, previous=previous)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 248, in _agent_executor_sync
[2m[WebServer] [22m    return asyncio.run(_agent_executor_async(messages, previous=previous))
[2m[WebServer] [22m           ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/runners.py", line 194, in run
[2m[WebServer] [22m    return runner.run(main)
[2m[WebServer] [22m           ~~~~~~~~~~^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/runners.py", line 118, in run
[2m[WebServer] [22m    return self._loop.run_until_complete(task)
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/base_events.py", line 720, in run_until_complete
[2m[WebServer] [22m    return future.result()
[2m[WebServer] [22m           ~~~~~~~~~~~~~^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 208, in _agent_executor_async
[2m[WebServer] [22m    llm_response = await _call_model_async(current_messages)
[2m[WebServer] [22m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 134, in _call_model_async
[2m[WebServer] [22m    return await asyncio.to_thread(_call_model_sync, messages)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/threads.py", line 25, in to_thread
[2m[WebServer] [22m    return await loop.run_in_executor(None, func_call)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/thread.py", line 59, in run
[2m[WebServer] [22m    result = self.fn(*self.args, **self.kwargs)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 127, in _call_model_sync
[2m[WebServer] [22m    return llm_with_tools.invoke(messages)
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/runnables/base.py", line 5416, in invoke
[2m[WebServer] [22m    return self.bound.invoke(
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        input,
[2m[WebServer] [22m        ^^^^^^
[2m[WebServer] [22m        self._merge_configs(config),
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m        **{**self.kwargs, **kwargs},
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 369, in invoke
[2m[WebServer] [22m    self.generate_prompt(
[2m[WebServer] [22m    ~~~~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        [self._convert_input(input)],
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<6 lines>...
[2m[WebServer] [22m        **kwargs,
[2m[WebServer] [22m        ^^^^^^^^^
[2m[WebServer] [22m    ).generations[0][0],
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 946, in generate_prompt
[2m[WebServer] [22m    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
[2m[WebServer] [22m           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 765, 

[1A[2K[2m[WebServer] [22min generate
[2m[WebServer] [22m    self._generate_with_cache(
[2m[WebServer] [22m    ~~~~~~~~~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        m,
[2m[WebServer] [22m        ^^
[2m[WebServer] [22m    ...<2 lines>...
[2m[WebServer] [22m        **kwargs,
[2m[WebServer] [22m        ^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 1011, in _generate_with_cache
[2m[WebServer] [22m    result = self._generate(
[2m[WebServer] [22m        messages, stop=stop, run_manager=run_manager, **kwargs
[2m[WebServer] [22m    )
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py", line 991, in _generate
[2m[WebServer] [22m    response = self.client.create(**payload)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_utils/_utils.py", line 287, in wrapper
[2m[WebServer] [22m    return func(*args, **kwargs)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py", line 925, in create
[2m[WebServer] [22m    return self._post(
[2m[WebServer] [22m           ~~~~~~~~~~^
[2m[WebServer] [22m        "/chat/completions",
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<43 lines>...
[2m[WebServer] [22m        stream_cls=Stream[ChatCompletionChunk],
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_base_client.py", line 1239, in post
[2m[WebServer] [22m    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
[2m[WebServer] [22m                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_base_client.py", line 1034, in request
[2m[WebServer] [22m    raise self._make_status_error_from_response(err.response) from None
[2m[WebServer] [22mopenai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `gpt-mock` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
[2m[WebServer] [22mDuring task with name 'agent_executor' and id '1ddafec4-5f06-a162-b73f-0a5794ef9643'
[2m[WebServer] [22mDuring task with name 'agent-1' and id '87437cbe-c5b1-168e-5158-e1f052752888'

[1A[2Ktests/multi_user_concurrency.spec.ts:137:7 › Multi-User and Concurrency › Concurrent workflow execution
❌ User 0 execution failed: [33m500[39m

[1A[2K[2m[WebServer] [22mERROR:    Exception in ASGI application
[2m[WebServer] [22mTraceback (most recent call last):
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/uvicorn/protocols/http/h11_impl.py", line 408, in run_asgi
[2m[WebServer] [22m    result = await app(  # type: ignore[func-returns-value]
[2m[WebServer] [22m             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m        self.scope, self.receive, self.send
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/uvicorn/middleware/proxy_headers.py", line 84, in __call__
[2m[WebServer] [22m    return await self.app(scope, receive, send)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/fastapi/applications.py", line 1054, in __call__
[2m[WebServer] [22m    await super().__call__(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/applications.py", line 112, in __call__
[2m[WebServer] [22m    await self.middleware_stack(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/middleware/errors.py", line 187, in __call__
[2m[WebServer] [22m    raise exc
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/middleware/errors.py", line 165, in __call__
[2m[WebServer] [22m    await self.app(scope, receive, _send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/middleware/worker_db.py", line 101, in __call__
[2m[WebServer] [22m    await self.app(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/middleware/cors.py", line 85, in __call__
[2m[WebServer] [22m    await self.app(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/middleware/exceptions.py", line 62, in __call__
[2m[WebServer] [22m    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
[2m[WebServer] [22m    raise exc
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
[2m[WebServer] [22m    await app(scope, receive, sender)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/routing.py", line 714, in __call__
[2m[WebServer] [22m    await self.middleware_stack(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/routing.py", line 734, in app
[2m[WebServer] [22m    await route.handle(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/routing.py", line 288, in handle
[2m[WebServer] [22m    await self.app(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/routing.py", line 76, in app
[2m[WebServer] [22m    await wrap_app_handling_exceptions(app, request)(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
[2m[WebServer] [22m    raise exc
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
[2m[WebServer] [22m    await app(scope, receive, sender)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/routing.py", line 73, in app
[2m[WebServer] [22m    response = await f(request)
[2m[WebServer] [22m               ^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/fastapi/routing.py", line 301, in app
[2m[WebServer] [22m    raw_response = await run_endpoint_function(
[2m[WebServer] [22m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<3 lines>...
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/fastapi/routing.py", line 212, in run_endpoint_function
[2m[WebServer] [22m    return await dependant.call(**values)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/routers/workflow_executions.py", line 74, in start_workflow_execution
[2m[WebServer] [22m    execution_id = await langgraph_workflow_engine.execute_workflow(workflow_id)
[2m[WebServer] [22m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/services/langgraph_workflow_engine.py", line 146, in execute_workflow
[2m[WebServer] [22m    await self._execute_workflow_internal(workflow, execution, db)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/services/langgraph_workflow_engine.py", line 214, in _execute_workflow_internal
[2m[WebServer] [22m    async for chunk in graph.astream(initial_state, config):
[2m[WebServer] [22m    ...<36 lines>...
[2m[WebServer] [22m            logger.warning(f"[LangGraphEngine] Received empty chunk #{chunk_count}")
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2732, in astream
[2m[WebServer] [22m    async for _ in runner.atick(
[2m[WebServer] [22m    ...<7 lines>...
[2m[WebServer] [22m            yield o
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/services/langgraph_workflow_engine.py", line 729, in agent_node
[2m[WebServer] [22m    created_messages = await runner.run_thread(db, thread)
[2m[WebServer] [22m                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/managers/agent_runner.py", line 137, in run_thread
[2m[WebServer] [22m    updated_messages = await self._runnable.ainvoke(original_msgs, config)
[2m[WebServer] [22m                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2850, in ainvoke
[2m[WebServer] [22m    async for chunk in self.astream(
[2m[WebServer] [22m    ...<13 lines>...
[2m[WebServer] [22m            chunks.append(chunk)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2732, in astream
[2m[WebServer] [22m    async for _ in runner.atick(
[2m[WebServer] [22m    ...<7 lines>...
[2m[WebServer] [22m            yield o
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 256, in agent_executor
[2m[WebServer] [22m    return _agent_executor_sync(messages, previous=previous)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 248, in _agent_executor_sync
[2m[WebServer] [22m    return asyncio.run(_agent_executor_async(messages, previous=previous))
[2m[WebServer] [22m           ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/runners.py", line 194, in run
[2m[WebServer] [22m    return runner.run(main)
[2m[WebServer] [22m           ~~~~~~~~~~^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/runners.py", line 118, in run
[2m[WebServer] [22m    return self._loop.run_until_complete(task)
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/base_events.py", line 720, in run_until_complete
[2m[WebServer] [22m    return future.result()
[2m[WebServer] [22m           ~~~~~~~~~~~~~^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 208, in _agent_executor_async
[2m[WebServer] [22m    llm_response = await _call_model_async(current_messages)
[2m[WebServer] [22m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 134, in _call_model_async
[2m[WebServer] [22m    return await asyncio.to_thread(_call_model_sync, messages)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/threads.py", line 25, in to_thread
[2m[WebServer] [22m    return await loop.run_in_executor(None, func_call)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/thread.py", line 59, in run
[2m[WebServer] [22m    result = self.fn(*self.args, **self.kwargs)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 127, in _call_model_sync
[2m[WebServer] [22m    return llm_with_tools.invoke(messages)
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/runnables/base.py", line 5416, in invoke
[2m[WebServer] [22m    return self.bound.invoke(
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        input,
[2m[WebServer] [22m        ^^^^^^
[2m[WebServer] [22m        self._merge_configs(config),
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^

[1A[2K[2m[WebServer] [22m^^^^^^^^^
[2m[WebServer] [22m        **{**self.kwargs, **kwargs},
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 369, in invoke
[2m[WebServer] [22m    self.generate_prompt(
[2m[WebServer] [22m    ~~~~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        [self._convert_input(input)],
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<6 lines>...
[2m[WebServer] [22m        **kwargs,
[2m[WebServer] [22m        ^^^^^^^^^
[2m[WebServer] [22m    ).generations[0][0],
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 946, in generate_prompt
[2m[WebServer] [22m    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
[2m[WebServer] [22m           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 765, in generate
[2m[WebServer] [22m    self._generate_with_cache(
[2m[WebServer] [22m    ~~~~~~~~~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        m,
[2m[WebServer] [22m        ^^
[2m[WebServer] [22m    ...<2 lines>...
[2m[WebServer] [22m        **kwargs,
[2m[WebServer] [22m        ^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 1011, in _generate_with_cache
[2m[WebServer] [22m    result = self._generate(
[2m[WebServer] [22m        messages, stop=stop, run_manager=run_manager, **kwargs
[2m[WebServer] [22m    )
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py", line 991, in _generate
[2m[WebServer] [22m    response = self.client.create(**payload)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_utils/_utils.py", line 287, in wrapper
[2m[WebServer] [22m    return func(*args, **kwargs)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py", line 925, in create
[2m[WebServer] [22m    return self._post(
[2m[WebServer] [22m           ~~~~~~~~~~^
[2m[WebServer] [22m        "/chat/completions",
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<43 lines>...
[2m[WebServer] [22m        stream_cls=Stream[ChatCompletionChunk],
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_base_client.py", line 1239, in post
[2m[WebServer] [22m    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
[2m[WebServer] [22m                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_base_client.py", line 1034, in request
[2m[WebServer] [22m    raise self._make_status_error_from_response(err.response) from None
[2m[WebServer] [22mopenai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `gpt-mock` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
[2m[WebServer] [22mDuring task with name 'agent_executor' and id '1ddafec4-5f06-a162-b73f-0a5794ef9643'
[2m[WebServer] [22mDuring task with name 'agent-1' and id '87437cbe-c5b1-168e-5158-e1f052752888'

[1A[2K[2m[WebServer] [22mERROR - [AgentRunner] Exception during runnable.ainvoke: Error code: 404 - {'error': {'message': 'The model `gpt-mock` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
[2m[WebServer] [22mTraceback (most recent call last):
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/managers/agent_runner.py", line 137, in run_thread
[2m[WebServer] [22m    updated_messages = await self._runnable.ainvoke(original_msgs, config)
[2m[WebServer] [22m                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2850, in ainvoke
[2m[WebServer] [22m    async for chunk in self.astream(
[2m[WebServer] [22m    ...<13 lines>...
[2m[WebServer] [22m            chunks.append(chunk)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2732, in astream
[2m[WebServer] [22m    async for _ in runner.atick(
[2m[WebServer] [22m    ...<7 lines>...
[2m[WebServer] [22m            yield o
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 256, in agent_executor
[2m[WebServer] [22m    return _agent_executor_sync(messages, previous=previous)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 248, in _agent_executor_sync
[2m[WebServer] [22m    return asyncio.run(_agent_executor_async(messages, previous=previous))
[2m[WebServer] [22m           ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/runners.py", line 194, in run
[2m[WebServer] [22m    return runner.run(main)
[2m[WebServer] [22m           ~~~~~~~~~~^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/runners.py", line 118, in run
[2m[WebServer] [22m    return self._loop.run_until_complete(task)
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/base_events.py", line 720, in run_until_complete
[2m[WebServer] [22m    return future.result()
[2m[WebServer] [22m           ~~~~~~~~~~~~~^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 208, in _agent_executor_async
[2m[WebServer] [22m    llm_response = await _call_model_async(current_messages)
[2m[WebServer] [22m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 134, in _call_model_async
[2m[WebServer] [22m    return await asyncio.to_thread(_call_model_sync, messages)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/threads.py", line 25, in to_thread
[2m[WebServer] [22m    return await loop.run_in_executor(None, func_call)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/thread.py", line 59, in run
[2m[WebServer] [22m    result = self.fn(*self.args, **self.kwargs)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 127, in _call_model_sync
[2m[WebServer] [22m    return llm_with_tools.invoke(messages)
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/runnables/base.py", line 5416, in invoke
[2m[WebServer] [22m    return self.bound.invoke(
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        input,
[2m[WebServer] [22m        ^^^^^^
[2m[WebServer] [22m        self._merge_configs(config),
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m        **{**self.kwargs, **kwargs},
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 369, in invoke
[2m[WebServer] [22m    self.generate_prompt(
[2m[WebServer] [22m    ~~~~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        [self._convert_input(input)],
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<6 lines>...
[2m[WebServer] [22m        **kwargs,
[2m[WebServer] [22m        ^^^^^^^^^
[2m[WebServer] [22m    ).generations[0][0],
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 946, in generate_prompt
[2m[WebServer] [22m    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
[2m[WebServer] [22m           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 765, in generate
[2m[WebServer] [22m    self._generate_with_cache(
[2m[WebServer] [22m    ~~~~~~~~~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        m,
[2m[WebServer] [22m        ^^
[2m[WebServer] [22m    ...<2 lines>...
[2m[WebServer] [22m        **kwargs,
[2m[WebServer] [22m        ^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 1011, in _generate_with_cache
[2m[WebServer] [22m    result = self._generate(
[2m[WebServer] [22m        messages, stop=stop, run_manager=run_manager, **kwargs
[2m[WebServer] [22m    )
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py", line 991, in _generate
[2m[WebServer] [22m    response = self.client.create(**payload)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_utils/_utils.py", line 287, in wrapper
[2m[WebServer] [22m    return func(*args, **kwargs)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py", line 925, in create
[2m[WebServer] [22m    return self._post(
[2m[WebServer] [22m           ~~~~~~~~~~^
[2m[WebServer] [22m        "/chat/completions",
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<43 lines>...
[2m[WebServer] [22m        stream_cls=Stream[ChatCompletionChunk],
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_base_client.py", line 1239, in post
[2m[WebServer] [22m    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
[2m[WebServer] [22m                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_base_client.py", line 1034, in request
[2m[WebServer] [22m    raise self._make_status_error_from_response(err.response) from None
[2m[WebServer] [22mopenai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `gpt-mock` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
[2m[WebServer] [22mDuring task with name 'agent_executor' and id '6ff4f630-2b91-0afe-11f6-a9a249d7bb7d'

[1A[2K[2m[WebServer] [22mERROR - [AgentNode] Exception in agent node agent-1 (agent_id=1): Error code: 404 - {'error': {'message': 'The model `gpt-mock` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
[2m[WebServer] [22mTraceback (most recent call last):
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/services/langgraph_workflow_engine.py", line 729, in agent_node
[2m[WebServer] [22m    created_messages = await runner.run_thread(db, thread)
[2m[WebServer] [22m                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/managers/agent_runner.py", line 137, in run_thread
[2m[WebServer] [22m    updated_messages = await self._runnable.ainvoke(original_msgs, config)
[2m[WebServer] [22m                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2850, in ainvoke
[2m[WebServer] [22m    async for chunk in self.astream(
[2m[WebServer] [22m    ...<13 lines>...
[2m[WebServer] [22m            chunks.append(chunk)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2732, in astream
[2m[WebServer] [22m    async for _ in runner.atick(
[2m[WebServer] [22m    ...<7 lines>...
[2m[WebServer] [22m            yield o
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 256, in agent_executor
[2m[WebServer] [22m    return _agent_executor_sync(messages, previous=previous)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 248, in _agent_executor_sync
[2m[WebServer] [22m    return asyncio.run(_agent_executor_async(messages, previous=previous))
[2m[WebServer] [22m           ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/runners.py", line 194, in run
[2m[WebServer] [22m    return runner.run(main)
[2m[WebServer] [22m           ~~~~~~~~~~^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/runners.py", line 118, in run
[2m[WebServer] [22m    return self._loop.run_until_complete(task)
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/base_events.py", line 720, in run_until_complete
[2m[WebServer] [22m    return future.result()
[2m[WebServer] [22m           ~~~~~~~~~~~~~^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 208, in _agent_executor_async
[2m[WebServer] [22m    llm_response = await _call_model_async(current_messages)
[2m[WebServer] [22m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 134, in _call_model_async
[2m[WebServer] [22m    return await asyncio.to_thread(_call_model_sync, messages)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/threads.py", line 25, in to_thread
[2m[WebServer] [22m    return await loop.run_in_executor(None, func_call)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/thread.py", line 59, in run
[2m[WebServer] [22m    result = self.fn(*self.args, **self.kwargs)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 127, in _call_model_sync
[2m[WebServer] [22m    return llm_with_tools.invoke(messages)
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/runnables/base.py", line 5416, in invoke
[2m[WebServer] [22m    return self.bound.invoke(
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        input,
[2m[WebServer] [22m        ^^^^^^
[2m[WebServer] [22m        self._merge_configs(config),
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m        **{**self.kwargs, **kwargs},
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 369, in invoke
[2m[WebServer] [22m    self.generate_prompt(
[2m[WebServer] [22m    ~~~~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        [self._convert_input(input)],
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<6 lines>...
[2m[WebServer] [22m        **kwargs,
[2m[WebServer] [22m        ^^^^^^^^^
[2m[WebServer] [22m    ).generations[0][0],
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 946, in generate_prompt
[2m[WebServer] [22m    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
[2m[WebServer] [22m           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 765, in generate
[2m[WebServer] [22m    self._generate_with_cache(
[2m[WebServer] [22m    ~~~~~~~~~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        m,
[2m[WebServer] [22m        ^^
[2m[WebServer] [22m    ...<2 lines>...
[2m[WebServer] [22m        **kwargs,
[2m[WebServer] [22m        ^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 1011, in _generate_with_cache
[2m[WebServer] [22m    result = self._generate(
[2m[WebServer] [22m        messages, stop=stop, run_manager=run_manager, **kwargs
[2m[WebServer] [22m    )
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py", line 991, in _generate
[2m[WebServer] [22m    response = self.client.create(**payload)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_utils/_utils.py", line 287, in wrapper
[2m[WebServer] [22m    return func(*args, **kwargs)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py", line 925, in create
[2m[WebServer] [22m    return self._post(
[2m[WebServer] [22m           ~~~~~~~~~~^
[2m[WebServer] [22m        "/chat/completions",
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<43 lines>...
[2m[WebServer] [22m        stream_cls=Stream[ChatCompletionChunk],
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_base_client.py", line 1239, in post
[2m[WebServer] [22m    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
[2m[WebServer] [22m                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_base_client.py", line 1034, in request
[2m[WebServer] [22m    raise self._make_status_error_from_response(err.response) from None
[2m[WebServer] [22mopenai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `gpt-mock` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
[2m[WebServer] [22mDuring task with name 'agent_executor' and id '6ff4f630-2b91-0afe-11f6-a9a249d7bb7d'

[1A[2K[2m[WebServer] [22mERROR - [AgentNode] Updated node_state to 'failed' in DB

[1A[2K[2m[WebServer] [22mERROR - [AgentNode] Re-raising exception to fail workflow execution

[1A[2K[2m[WebServer] [22mERROR - [LangGraphEngine] Execution failed – execution_id=1
[2m[WebServer] [22mTraceback (most recent call last):
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/services/langgraph_workflow_engine.py", line 146, in execute_workflow
[2m[WebServer] [22m    await self._execute_workflow_internal(workflow, execution, db)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/services/langgraph_workflow_engine.py", line 214, in _execute_workflow_internal
[2m[WebServer] [22m    async for chunk in graph.astream(initial_state, config):
[2m[WebServer] [22m    ...<36 lines>...
[2m[WebServer] [22m            logger.warning(f"[LangGraphEngine] Received empty chunk #{chunk_count}")
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2732, in astream
[2m[WebServer] [22m    async for _ in runner.atick(
[2m[WebServer] [22m    ...<7 lines>...
[2m[WebServer] [22m            yield o
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/services/langgraph_workflow_engine.py", line 729, in agent_node
[2m[WebServer] [22m    created_messages = await runner.run_thread(db, thread)
[2m[WebServer] [22m                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/managers/agent_runner.py", line 137, in run_thread
[2m[WebServer] [22m    updated_messages = await self._runnable.ainvoke(original_msgs, config)
[2m[WebServer] [22m                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2850, in ainvoke
[2m[WebServer] [22m    async for chunk in self.astream(
[2m[WebServer] [22m    ...<13 lines>...
[2m[WebServer] [22m            chunks.append(chunk)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2732, in astream
[2m[WebServer] [22m    async for _ in runner.atick(
[2m[WebServer] [22m    ...<7 lines>...
[2m[WebServer] [22m            yield o
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 256, in agent_executor
[2m[WebServer] [22m    return _agent_executor_sync(messages, previous=previous)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 248, in _agent_executor_sync
[2m[WebServer] [22m    return asyncio.run(_agent_executor_async(messages, previous=previous))
[2m[WebServer] [22m           ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/runners.py", line 194, in run
[2m[WebServer] [22m    return runner.run(main)
[2m[WebServer] [22m           ~~~~~~~~~~^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/runners.py", line 118, in run
[2m[WebServer] [22m    return self._loop.run_until_complete(task)
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/base_events.py", line 720, in run_until_complete
[2m[WebServer] [22m    return future.result()
[2m[WebServer] [22m           ~~~~~~~~~~~~~^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 208, in _agent_executor_async
[2m[WebServer] [22m    llm_response = await _call_model_async(current_messages)
[2m[WebServer] [22m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 134, in _call_model_async
[2m[WebServer] [22m    return await asyncio.to_thread(_call_model_sync, messages)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/threads.py", line 25, in to_thread
[2m[WebServer] [22m    return await loop.run_in_executor(None, func_call)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/thread.py", line 59, in run
[2m[WebServer] [22m    result = self.fn(*self.args, **self.kwargs)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 127, in _call_model_sync
[2m[WebServer] [22m    return llm_with_tools.invoke(messages)
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/runnables/base.py", line 5416, in invoke
[2m[WebServer] [22m    return self.bound.invoke(
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        input,
[2m[WebServer] [22m        ^^^^^^
[2m[WebServer] [22m        self._merge_configs(config),
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m        **{**self.kwargs, **kwargs},
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 369, in invoke
[2m[WebServer] [22m    self.generate_prompt(
[2m[WebServer] [22m    ~~~~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        [self._convert_input(input)],
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<6 lines>...
[2m[WebServer] [22m        **kwargs,
[2m[WebServer] [22m        ^^^^^^^^^
[2m[WebServer] [22m    ).generations[0][0],
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 946, in generate_prompt
[2m[WebServer] [22m    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
[2m[WebServer] [22m           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 765, in generate
[2m[WebServer] [22m    self._generate_with_cache(
[2m[WebServer] [22m    ~~~~~~~~~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        m,
[2m[WebServer] [22m        ^^
[2m[WebServer] [22m    ...<2 lines>...
[2m[WebServer] [22m        **kwargs,
[2m[WebServer] [22m        ^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 1011, in _generate_with_cache
[2m[WebServer] [22m    result = self._generate(
[2m[WebServer] [22m        messages, stop=stop, run_manager=run_manager, **kwargs
[2m[WebServer] [22m    )
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py", line 991, in _generate
[2m[WebServer] [22m    response = self.client.create(**payload)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_utils/_utils.py", line 287, in wrapper
[2m[WebServer] [22m    return func(*args, **kwargs)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py", line 925, in create
[2m[WebServer] [22m    return self._post(
[2m[WebServer] [22m           ~~~~~~~~~~^
[2m[WebServer] [22m        "/chat/completions",
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<43 lines>...
[2m[WebServer] [22m        stream_cls=Stream[ChatCompletionChunk],
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_base_client.py", line 1239, in post
[2m[WebServer] [22m    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
[2m[WebServer] [22m                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_base_client.py", line 1034, in request
[2m[WebServer] [22m    raise self._make_status_error_from_response(err.response) from None
[2m[WebServer] [22mopenai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `gpt-mock` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
[2m[WebServer] [22mDuring task with name 'agent_executor' and id '6ff4f630-2b91-0afe-11f6-a9a249d7bb7d'
[2m[WebServer] [22mDuring task with name 'agent-1' and id '6c09dcd7-6848-0e02-5fa7-6479bf954adc'

[1A[2K[2m[WebServer] [22mERROR - Unhandled exception: Error code: 404 - {'error': {'message': 'The model `gpt-mock` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
[2m[WebServer] [22mTraceback (most recent call last):
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/middleware/errors.py", line 165, in __call__
[2m[WebServer] [22m    await self.app(scope, receive, _send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/middleware/worker_db.py", line 101, in __call__
[2m[WebServer] [22m    await self.app(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/middleware/cors.py", line 85, in __call__
[2m[WebServer] [22m    await self.app(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/middleware/exceptions.py", line 62, in __call__
[2m[WebServer] [22m    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
[2m[WebServer] [22m    raise exc
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
[2m[WebServer] [22m    await app(scope, receive, sender)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/routing.py", line 714, in __call__
[2m[WebServer] [22m    await self.middleware_stack(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/routing.py", line 734, in app
[2m[WebServer] [22m    await route.handle(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/routing.py", line 288, in handle
[2m[WebServer] [22m    await self.app(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/routing.py", line 76, in app
[2m[WebServer] [22m    await wrap_app_handling_exceptions(app, request)(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
[2m[WebServer] [22m    raise exc
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
[2m[WebServer] [22m    await app(scope, receive, sender)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/routing.py", line 73, in app
[2m[WebServer] [22m    response = await f(request)
[2m[WebServer] [22m               ^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/fastapi/routing.py", line 301, in app
[2m[WebServer] [22m    raw_response = await run_endpoint_function(
[2m[WebServer] [22m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<3 lines>...
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/fastapi/routing.py", line 212, in run_endpoint_function
[2m[WebServer] [22m    return await dependant.call(**values)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/routers/workflow_executions.py", line 74, in start_workflow_execution
[2m[WebServer] [22m    execution_id = await langgraph_workflow_engine.execute_workflow(workflow_id)
[2m[WebServer] [22m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/services/langgraph_workflow_engine.py", line 146, in execute_workflow
[2m[WebServer] [22m    await self._execute_workflow_internal(workflow, execution, db)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/services/langgraph_workflow_engine.py", line 214, in _execute_workflow_internal
[2m[WebServer] [22m    async for chunk in graph.astream(initial_state, config):
[2m[WebServer] [22m    ...<36 lines>...
[2m[WebServer] [22m            logger.warning(f"[LangGraphEngine] Received empty chunk #{chunk_count}")
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2732, in astream
[2m[WebServer] [22m    async for _ in runner.atick(
[2m[WebServer] [22m    ...<7 lines>...
[2m[WebServer] [22m            yield o
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/services/langgraph_workflow_engine.py", line 729, in agent_node
[2m[WebServer] [22m    created_messages = await runner.run_thread(db, thread)
[2m[WebServer] [22m                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/managers/agent_runner.py", line 137, in run_thread
[2m[WebServer] [22m    updated_messages = await self._runnable.ainvoke(original_msgs, config)
[2m[WebServer] [22m                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2850, in ainvoke
[2m[WebServer] [22m    async for chunk in self.astream(
[2m[WebServer] [22m    ...<13 lines>...
[2m[WebServer] [22m            chunks.append(chunk)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2732, in astream
[2m[WebServer] [22m    async for _ in runner.atick(
[2m[WebServer] [22m    ...<7 lines>...
[2m[WebServer] [22m            yield o
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 256, in agent_executor
[2m[WebServer] [22m    return _agent_executor_sync(messages, previous=previous)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 248, in _agent_executor_sync
[2m[WebServer] [22m    return asyncio.run(_agent_executor_async(messages, previous=previous))
[2m[WebServer] [22m           ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/runners.py", line 194, in run
[2m[WebServer] [22m    return runner.run(main)
[2m[WebServer] [22m           ~~~~~~~~~~^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/runners.py", line 118, in run
[2m[WebServer] [22m    return self._loop.run_until_complete(task)
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/base_events.py", line 720, in run_until_complete
[2m[WebServer] [22m    return future.result()
[2m[WebServer] [22m           ~~~~~~~~~~~~~^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 208, in _agent_executor_async
[2m[WebServer] [22m    llm_response = await _call_model_async(current_messages)
[2m[WebServer] [22m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 134, in _call_model_async
[2m[WebServer] [22m    return await asyncio.to_thread(_call_model_sync, messages)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/threads.py", line 25, in to_thread
[2m[WebServer] [22m    return await loop.run_in_executor(None, func_call)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/thread.py", line 59, in run
[2m[WebServer] [22m    result = self.fn(*self.args, **self.kwargs)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 127, in _call_model_sync
[2m[WebServer] [22m    return llm_with_tools.invoke(messages)
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/runnables/base.py", line 5416, in invoke
[2m[WebServer] [22m    return self.bound.invoke(
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        input,
[2m[WebServer] [22m        ^^^^^^
[2m[WebServer] [22m        self._merge_configs(config),
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m        **{**self.kwargs, **kwargs},
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 369, in invoke
[2m[WebServer] [22m    self.generate_prompt(
[2m[WebServer] [22m    ~~~~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        [self._convert_input(input)],
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<6 lines>...
[2m[WebServer] [22m        **kwargs,
[2m[WebServer] [22m        ^^^^^^^^^
[2m[WebServer] [22m    ).generations[0][0],
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 946, in generate_prompt
[2m[WebServer] [22m    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
[2m[WebServer] [22m           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 765, 

[1A[2K[2m[WebServer] [22min generate
[2m[WebServer] [22m    self._generate_with_cache(
[2m[WebServer] [22m    ~~~~~~~~~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        m,
[2m[WebServer] [22m        ^^
[2m[WebServer] [22m    ...<2 lines>...
[2m[WebServer] [22m        **kwargs,
[2m[WebServer] [22m        ^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 1011, in _generate_with_cache
[2m[WebServer] [22m    result = self._generate(
[2m[WebServer] [22m        messages, stop=stop, run_manager=run_manager, **kwargs
[2m[WebServer] [22m    )
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py", line 991, in _generate
[2m[WebServer] [22m    response = self.client.create(**payload)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_utils/_utils.py", line 287, in wrapper
[2m[WebServer] [22m    return func(*args, **kwargs)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py", line 925, in create
[2m[WebServer] [22m    return self._post(
[2m[WebServer] [22m           ~~~~~~~~~~^
[2m[WebServer] [22m        "/chat/completions",
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<43 lines>...
[2m[WebServer] [22m        stream_cls=Stream[ChatCompletionChunk],
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_base_client.py", line 1239, in post
[2m[WebServer] [22m    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
[2m[WebServer] [22m                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_base_client.py", line 1034, in request
[2m[WebServer] [22m    raise self._make_status_error_from_response(err.response) from None
[2m[WebServer] [22mopenai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `gpt-mock` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
[2m[WebServer] [22mDuring task with name 'agent_executor' and id '6ff4f630-2b91-0afe-11f6-a9a249d7bb7d'
[2m[WebServer] [22mDuring task with name 'agent-1' and id '6c09dcd7-6848-0e02-5fa7-6479bf954adc'

[1A[2K❌ User 2 execution failed: [33m500[39m

[1A[2K[2m[WebServer] [22mERROR:    Exception in ASGI application
[2m[WebServer] [22mTraceback (most recent call last):
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/uvicorn/protocols/http/h11_impl.py", line 408, in run_asgi
[2m[WebServer] [22m    result = await app(  # type: ignore[func-returns-value]
[2m[WebServer] [22m             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m        self.scope, self.receive, self.send
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/uvicorn/middleware/proxy_headers.py", line 84, in __call__
[2m[WebServer] [22m    return await self.app(scope, receive, send)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/fastapi/applications.py", line 1054, in __call__
[2m[WebServer] [22m    await super().__call__(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/applications.py", line 112, in __call__
[2m[WebServer] [22m    await self.middleware_stack(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/middleware/errors.py", line 187, in __call__
[2m[WebServer] [22m    raise exc
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/middleware/errors.py", line 165, in __call__
[2m[WebServer] [22m    await self.app(scope, receive, _send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/middleware/worker_db.py", line 101, in __call__
[2m[WebServer] [22m    await self.app(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/middleware/cors.py", line 85, in __call__
[2m[WebServer] [22m    await self.app(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/middleware/exceptions.py", line 62, in __call__
[2m[WebServer] [22m    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
[2m[WebServer] [22m    raise exc
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
[2m[WebServer] [22m    await app(scope, receive, sender)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/routing.py", line 714, in __call__
[2m[WebServer] [22m    await self.middleware_stack(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/routing.py", line 734, in app
[2m[WebServer] [22m    await route.handle(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/routing.py", line 288, in handle
[2m[WebServer] [22m    await self.app(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/routing.py", line 76, in app
[2m[WebServer] [22m    await wrap_app_handling_exceptions(app, request)(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
[2m[WebServer] [22m    raise exc
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
[2m[WebServer] [22m    await app(scope, receive, sender)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/routing.py", line 73, in app
[2m[WebServer] [22m    response = await f(request)
[2m[WebServer] [22m               ^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/fastapi/routing.py", line 301, in app
[2m[WebServer] [22m    raw_response = await run_endpoint_function(
[2m[WebServer] [22m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<3 lines>...
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/fastapi/routing.py", line 212, in run_endpoint_function
[2m[WebServer] [22m    return await dependant.call(**values)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/routers/workflow_executions.py", line 74, in start_workflow_execution
[2m[WebServer] [22m    execution_id = await langgraph_workflow_engine.execute_workflow(workflow_id)
[2m[WebServer] [22m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/services/langgraph_workflow_engine.py", line 146, in execute_workflow
[2m[WebServer] [22m    await self._execute_workflow_internal(workflow, execution, db)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/services/langgraph_workflow_engine.py", line 214, in _execute_workflow_internal
[2m[WebServer] [22m    async for chunk in graph.astream(initial_state, config):
[2m[WebServer] [22m    ...<36 lines>...
[2m[WebServer] [22m            logger.warning(f"[LangGraphEngine] Received empty chunk #{chunk_count}")
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2732, in astream
[2m[WebServer] [22m    async for _ in runner.atick(
[2m[WebServer] [22m    ...<7 lines>...
[2m[WebServer] [22m            yield o
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/services/langgraph_workflow_engine.py", line 729, in agent_node
[2m[WebServer] [22m    created_messages = await runner.run_thread(db, thread)
[2m[WebServer] [22m                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/managers/agent_runner.py", line 137, in run_thread
[2m[WebServer] [22m    updated_messages = await self._runnable.ainvoke(original_msgs, config)
[2m[WebServer] [22m                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2850, in ainvoke
[2m[WebServer] [22m    async for chunk in self.astream(
[2m[WebServer] [22m    ...<13 lines>...
[2m[WebServer] [22m            chunks.append(chunk)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2732, in astream
[2m[WebServer] [22m    async for _ in runner.atick(
[2m[WebServer] [22m    ...<7 lines>...
[2m[WebServer] [22m            yield o
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 256, in agent_executor
[2m[WebServer] [22m    return _agent_executor_sync(messages, previous=previous)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 248, in _agent_executor_sync
[2m[WebServer] [22m    return asyncio.run(_agent_executor_async(messages, previous=previous))
[2m[WebServer] [22m           ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/runners.py", line 194, in run
[2m[WebServer] [22m    return runner.run(main)
[2m[WebServer] [22m           ~~~~~~~~~~^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/runners.py", line 118, in run
[2m[WebServer] [22m    return self._loop.run_until_complete(task)
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/base_events.py", line 720, in run_until_complete
[2m[WebServer] [22m    return future.result()
[2m[WebServer] [22m           ~~~~~~~~~~~~~^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 208, in _agent_executor_async
[2m[WebServer] [22m    llm_response = await _call_model_async(current_messages)
[2m[WebServer] [22m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 134, in _call_model_async
[2m[WebServer] [22m    return await asyncio.to_thread(_call_model_sync, messages)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/threads.py", line 25, in to_thread
[2m[WebServer] [22m    return await loop.run_in_executor(None, func_call)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/thread.py", line 59, in run
[2m[WebServer] [22m    result = self.fn(*self.args, **self.kwargs)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 127, in _call_model_sync
[2m[WebServer] [22m    return llm_with_tools.invoke(messages)
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/runnables/base.py", line 5416, in invoke
[2m[WebServer] [22m    return self.bound.invoke(
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        input,
[2m[WebServer] [22m        ^^^^^^
[2m[WebServer] [22m        self._merge_configs(config),
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^

[1A[2K[2m[WebServer] [22m^^^^^^^^^
[2m[WebServer] [22m        **{**self.kwargs, **kwargs},
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 369, in invoke
[2m[WebServer] [22m    self.generate_prompt(
[2m[WebServer] [22m    ~~~~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        [self._convert_input(input)],
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<6 lines>...
[2m[WebServer] [22m        **kwargs,
[2m[WebServer] [22m        ^^^^^^^^^
[2m[WebServer] [22m    ).generations[0][0],
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 946, in generate_prompt
[2m[WebServer] [22m    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
[2m[WebServer] [22m           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 765, in generate
[2m[WebServer] [22m    self._generate_with_cache(
[2m[WebServer] [22m    ~~~~~~~~~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        m,
[2m[WebServer] [22m        ^^
[2m[WebServer] [22m    ...<2 lines>...
[2m[WebServer] [22m        **kwargs,
[2m[WebServer] [22m        ^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 1011, in _generate_with_cache
[2m[WebServer] [22m    result = self._generate(
[2m[WebServer] [22m        messages, stop=stop, run_manager=run_manager, **kwargs
[2m[WebServer] [22m    )
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py", line 991, in _generate
[2m[WebServer] [22m    response = self.client.create(**payload)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_utils/_utils.py", line 287, in wrapper
[2m[WebServer] [22m    return func(*args, **kwargs)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py", line 925, in create
[2m[WebServer] [22m    return self._post(
[2m[WebServer] [22m           ~~~~~~~~~~^
[2m[WebServer] [22m        "/chat/completions",
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<43 lines>...
[2m[WebServer] [22m        stream_cls=Stream[ChatCompletionChunk],
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_base_client.py", line 1239, in post
[2m[WebServer] [22m    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
[2m[WebServer] [22m                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_base_client.py", line 1034, in request
[2m[WebServer] [22m    raise self._make_status_error_from_response(err.response) from None
[2m[WebServer] [22mopenai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `gpt-mock` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
[2m[WebServer] [22mDuring task with name 'agent_executor' and id '6ff4f630-2b91-0afe-11f6-a9a249d7bb7d'
[2m[WebServer] [22mDuring task with name 'agent-1' and id '6c09dcd7-6848-0e02-5fa7-6479bf954adc'

[1A[2K[2m[WebServer] [22mERROR - [AgentRunner] Exception during runnable.ainvoke: Error code: 404 - {'error': {'message': 'The model `gpt-mock` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
[2m[WebServer] [22mTraceback (most recent call last):
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/managers/agent_runner.py", line 137, in run_thread
[2m[WebServer] [22m    updated_messages = await self._runnable.ainvoke(original_msgs, config)
[2m[WebServer] [22m                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2850, in ainvoke
[2m[WebServer] [22m    async for chunk in self.astream(
[2m[WebServer] [22m    ...<13 lines>...
[2m[WebServer] [22m            chunks.append(chunk)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2732, in astream
[2m[WebServer] [22m    async for _ in runner.atick(
[2m[WebServer] [22m    ...<7 lines>...
[2m[WebServer] [22m            yield o
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 256, in agent_executor
[2m[WebServer] [22m    return _agent_executor_sync(messages, previous=previous)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 248, in _agent_executor_sync
[2m[WebServer] [22m    return asyncio.run(_agent_executor_async(messages, previous=previous))
[2m[WebServer] [22m           ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/runners.py", line 194, in run
[2m[WebServer] [22m    return runner.run(main)
[2m[WebServer] [22m           ~~~~~~~~~~^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/runners.py", line 118, in run
[2m[WebServer] [22m    return self._loop.run_until_complete(task)
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/base_events.py", line 720, in run_until_complete
[2m[WebServer] [22m    return future.result()
[2m[WebServer] [22m           ~~~~~~~~~~~~~^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 208, in _agent_executor_async
[2m[WebServer] [22m    llm_response = await _call_model_async(current_messages)
[2m[WebServer] [22m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 134, in _call_model_async
[2m[WebServer] [22m    return await asyncio.to_thread(_call_model_sync, messages)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/threads.py", line 25, in to_thread
[2m[WebServer] [22m    return await loop.run_in_executor(None, func_call)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/thread.py", line 59, in run
[2m[WebServer] [22m    result = self.fn(*self.args, **self.kwargs)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 127, in _call_model_sync
[2m[WebServer] [22m    return llm_with_tools.invoke(messages)
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/runnables/base.py", line 5416, in invoke
[2m[WebServer] [22m    return self.bound.invoke(
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        input,
[2m[WebServer] [22m        ^^^^^^
[2m[WebServer] [22m        self._merge_configs(config),
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m        **{**self.kwargs, **kwargs},
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 369, in invoke
[2m[WebServer] [22m    self.generate_prompt(
[2m[WebServer] [22m    ~~~~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        [self._convert_input(input)],
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<6 lines>...
[2m[WebServer] [22m        **kwargs,
[2m[WebServer] [22m        ^^^^^^^^^
[2m[WebServer] [22m    ).generations[0][0],
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 946, in generate_prompt
[2m[WebServer] [22m    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
[2m[WebServer] [22m           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 765, in generate
[2m[WebServer] [22m    self._generate_with_cache(
[2m[WebServer] [22m    ~~~~~~~~~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        m,
[2m[WebServer] [22m        ^^
[2m[WebServer] [22m    ...<2 lines>...
[2m[WebServer] [22m        **kwargs,
[2m[WebServer] [22m        ^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 1011, in _generate_with_cache
[2m[WebServer] [22m    result = self._generate(
[2m[WebServer] [22m        messages, stop=stop, run_manager=run_manager, **kwargs
[2m[WebServer] [22m    )
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py", line 991, in _generate
[2m[WebServer] [22m    response = self.client.create(**payload)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_utils/_utils.py", line 287, in wrapper
[2m[WebServer] [22m    return func(*args, **kwargs)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py", line 925, in create
[2m[WebServer] [22m    return self._post(
[2m[WebServer] [22m           ~~~~~~~~~~^
[2m[WebServer] [22m        "/chat/completions",
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<43 lines>...
[2m[WebServer] [22m        stream_cls=Stream[ChatCompletionChunk],
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_base_client.py", line 1239, in post
[2m[WebServer] [22m    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
[2m[WebServer] [22m                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_base_client.py", line 1034, in request
[2m[WebServer] [22m    raise self._make_status_error_from_response(err.response) from None
[2m[WebServer] [22mopenai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `gpt-mock` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
[2m[WebServer] [22mDuring task with name 'agent_executor' and id '69a614a1-b8c5-b4ee-63eb-55b49a22efa8'

[1A[2K[2m[WebServer] [22mERROR - [AgentNode] Exception in agent node agent-1 (agent_id=1): Error code: 404 - {'error': {'message': 'The model `gpt-mock` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
[2m[WebServer] [22mTraceback (most recent call last):
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/services/langgraph_workflow_engine.py", line 729, in agent_node
[2m[WebServer] [22m    created_messages = await runner.run_thread(db, thread)
[2m[WebServer] [22m                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/managers/agent_runner.py", line 137, in run_thread
[2m[WebServer] [22m    updated_messages = await self._runnable.ainvoke(original_msgs, config)
[2m[WebServer] [22m                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2850, in ainvoke
[2m[WebServer] [22m    async for chunk in self.astream(
[2m[WebServer] [22m    ...<13 lines>...
[2m[WebServer] [22m            chunks.append(chunk)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2732, in astream
[2m[WebServer] [22m    async for _ in runner.atick(
[2m[WebServer] [22m    ...<7 lines>...
[2m[WebServer] [22m            yield o
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 256, in agent_executor
[2m[WebServer] [22m    return _agent_executor_sync(messages, previous=previous)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 248, in _agent_executor_sync
[2m[WebServer] [22m    return asyncio.run(_agent_executor_async(messages, previous=previous))
[2m[WebServer] [22m           ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/runners.py", line 194, in run
[2m[WebServer] [22m    return runner.run(main)
[2m[WebServer] [22m           ~~~~~~~~~~^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/runners.py", line 118, in run
[2m[WebServer] [22m    return self._loop.run_until_complete(task)
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/base_events.py", line 720, in run_until_complete
[2m[WebServer] [22m    return future.result()
[2m[WebServer] [22m           ~~~~~~~~~~~~~^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 208, in _agent_executor_async
[2m[WebServer] [22m    llm_response = await _call_model_async(current_messages)
[2m[WebServer] [22m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 134, in _call_model_async
[2m[WebServer] [22m    return await asyncio.to_thread(_call_model_sync, messages)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/threads.py", line 25, in to_thread
[2m[WebServer] [22m    return await loop.run_in_executor(None, func_call)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/thread.py", line 59, in run
[2m[WebServer] [22m    result = self.fn(*self.args, **self.kwargs)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 127, in _call_model_sync
[2m[WebServer] [22m    return llm_with_tools.invoke(messages)
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/runnables/base.py", line 5416, in invoke
[2m[WebServer] [22m    return self.bound.invoke(
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        input,
[2m[WebServer] [22m        ^^^^^^
[2m[WebServer] [22m        self._merge_configs(config),
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m        **{**self.kwargs, **kwargs},
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 369, in invoke
[2m[WebServer] [22m    self.generate_prompt(
[2m[WebServer] [22m    ~~~~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        [self._convert_input(input)],
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<6 lines>...
[2m[WebServer] [22m        **kwargs,
[2m[WebServer] [22m        ^^^^^^^^^
[2m[WebServer] [22m    ).generations[0][0],
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 946, in generate_prompt
[2m[WebServer] [22m    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
[2m[WebServer] [22m           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 765, in generate
[2m[WebServer] [22m    self._generate_with_cache(
[2m[WebServer] [22m    ~~~~~~~~~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        m,
[2m[WebServer] [22m        ^^
[2m[WebServer] [22m    ...<2 lines>...
[2m[WebServer] [22m        **kwargs,
[2m[WebServer] [22m        ^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 1011, in _generate_with_cache
[2m[WebServer] [22m    result = self._generate(
[2m[WebServer] [22m        messages, stop=stop, run_manager=run_manager, **kwargs
[2m[WebServer] [22m    )
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py", line 991, in _generate
[2m[WebServer] [22m    response = self.client.create(**payload)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_utils/_utils.py", line 287, in wrapper
[2m[WebServer] [22m    return func(*args, **kwargs)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py", line 925, in create
[2m[WebServer] [22m    return self._post(
[2m[WebServer] [22m           ~~~~~~~~~~^
[2m[WebServer] [22m        "/chat/completions",
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<43 lines>...
[2m[WebServer] [22m        stream_cls=Stream[ChatCompletionChunk],
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_base_client.py", line 1239, in post
[2m[WebServer] [22m    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
[2m[WebServer] [22m                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_base_client.py", line 1034, in request
[2m[WebServer] [22m    raise self._make_status_error_from_response(err.response) from None
[2m[WebServer] [22mopenai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `gpt-mock` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
[2m[WebServer] [22mDuring task with name 'agent_executor' and id '69a614a1-b8c5-b4ee-63eb-55b49a22efa8'

[1A[2K[2m[WebServer] [22mERROR - [AgentNode] Updated node_state to 'failed' in DB

[1A[2K[2m[WebServer] [22mERROR - [AgentNode] Re-raising exception to fail workflow execution

[1A[2K[2m[WebServer] [22mERROR - [LangGraphEngine] Execution failed – execution_id=1
[2m[WebServer] [22mTraceback (most recent call last):
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/services/langgraph_workflow_engine.py", line 146, in execute_workflow
[2m[WebServer] [22m    await self._execute_workflow_internal(workflow, execution, db)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/services/langgraph_workflow_engine.py", line 214, in _execute_workflow_internal
[2m[WebServer] [22m    async for chunk in graph.astream(initial_state, config):
[2m[WebServer] [22m    ...<36 lines>...
[2m[WebServer] [22m            logger.warning(f"[LangGraphEngine] Received empty chunk #{chunk_count}")
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2732, in astream
[2m[WebServer] [22m    async for _ in runner.atick(
[2m[WebServer] [22m    ...<7 lines>...
[2m[WebServer] [22m            yield o
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/services/langgraph_workflow_engine.py", line 729, in agent_node
[2m[WebServer] [22m    created_messages = await runner.run_thread(db, thread)
[2m[WebServer] [22m                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/managers/agent_runner.py", line 137, in run_thread
[2m[WebServer] [22m    updated_messages = await self._runnable.ainvoke(original_msgs, config)
[2m[WebServer] [22m                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2850, in ainvoke
[2m[WebServer] [22m    async for chunk in self.astream(
[2m[WebServer] [22m    ...<13 lines>...
[2m[WebServer] [22m            chunks.append(chunk)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2732, in astream
[2m[WebServer] [22m    async for _ in runner.atick(
[2m[WebServer] [22m    ...<7 lines>...
[2m[WebServer] [22m            yield o
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 256, in agent_executor
[2m[WebServer] [22m    return _agent_executor_sync(messages, previous=previous)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 248, in _agent_executor_sync
[2m[WebServer] [22m    return asyncio.run(_agent_executor_async(messages, previous=previous))
[2m[WebServer] [22m           ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/runners.py", line 194, in run
[2m[WebServer] [22m    return runner.run(main)
[2m[WebServer] [22m           ~~~~~~~~~~^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/runners.py", line 118, in run
[2m[WebServer] [22m    return self._loop.run_until_complete(task)
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/base_events.py", line 720, in run_until_complete
[2m[WebServer] [22m    return future.result()
[2m[WebServer] [22m           ~~~~~~~~~~~~~^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 208, in _agent_executor_async
[2m[WebServer] [22m    llm_response = await _call_model_async(current_messages)
[2m[WebServer] [22m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 134, in _call_model_async
[2m[WebServer] [22m    return await asyncio.to_thread(_call_model_sync, messages)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/threads.py", line 25, in to_thread
[2m[WebServer] [22m    return await loop.run_in_executor(None, func_call)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/thread.py", line 59, in run
[2m[WebServer] [22m    result = self.fn(*self.args, **self.kwargs)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 127, in _call_model_sync
[2m[WebServer] [22m    return llm_with_tools.invoke(messages)
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/runnables/base.py", line 5416, in invoke
[2m[WebServer] [22m    return self.bound.invoke(
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        input,
[2m[WebServer] [22m        ^^^^^^
[2m[WebServer] [22m        self._merge_configs(config),
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m        **{**self.kwargs, **kwargs},
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 369, in invoke
[2m[WebServer] [22m    self.generate_prompt(
[2m[WebServer] [22m    ~~~~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        [self._convert_input(input)],
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<6 lines>...
[2m[WebServer] [22m        **kwargs,
[2m[WebServer] [22m        ^^^^^^^^^
[2m[WebServer] [22m    ).generations[0][0],
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 946, in generate_prompt
[2m[WebServer] [22m    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
[2m[WebServer] [22m           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 765, in generate
[2m[WebServer] [22m    self._generate_with_cache(
[2m[WebServer] [22m    ~~~~~~~~~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        m,
[2m[WebServer] [22m        ^^
[2m[WebServer] [22m    ...<2 lines>...
[2m[WebServer] [22m        **kwargs,
[2m[WebServer] [22m        ^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 1011, in _generate_with_cache
[2m[WebServer] [22m    result = self._generate(
[2m[WebServer] [22m        messages, stop=stop, run_manager=run_manager, **kwargs
[2m[WebServer] [22m    )
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py", line 991, in _generate
[2m[WebServer] [22m    response = self.client.create(**payload)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_utils/_utils.py", line 287, in wrapper
[2m[WebServer] [22m    return func(*args, **kwargs)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py", line 925, in create
[2m[WebServer] [22m    return self._post(
[2m[WebServer] [22m           ~~~~~~~~~~^
[2m[WebServer] [22m        "/chat/completions",
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<43 lines>...
[2m[WebServer] [22m        stream_cls=Stream[ChatCompletionChunk],
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_base_client.py", line 1239, in post
[2m[WebServer] [22m    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
[2m[WebServer] [22m                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_base_client.py", line 1034, in request
[2m[WebServer] [22m    raise self._make_status_error_from_response(err.response) from None
[2m[WebServer] [22mopenai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `gpt-mock` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
[2m[WebServer] [22mDuring task with name 'agent_executor' and id '69a614a1-b8c5-b4ee-63eb-55b49a22efa8'
[2m[WebServer] [22mDuring task with name 'agent-1' and id '2b5b6b3f-e04b-e1e9-e48e-36af28e847f9'

[1A[2K[2m[WebServer] [22mERROR - Unhandled exception: Error code: 404 - {'error': {'message': 'The model `gpt-mock` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
[2m[WebServer] [22mTraceback (most recent call last):
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/middleware/errors.py", line 165, in __call__
[2m[WebServer] [22m    await self.app(scope, receive, _send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/middleware/worker_db.py", line 101, in __call__
[2m[WebServer] [22m    await self.app(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/middleware/cors.py", line 85, in __call__
[2m[WebServer] [22m    await self.app(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/middleware/exceptions.py", line 62, in __call__
[2m[WebServer] [22m    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
[2m[WebServer] [22m    raise exc
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
[2m[WebServer] [22m    await app(scope, receive, sender)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/routing.py", line 714, in __call__
[2m[WebServer] [22m    await self.middleware_stack(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/routing.py", line 734, in app
[2m[WebServer] [22m    await route.handle(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/routing.py", line 288, in handle
[2m[WebServer] [22m    await self.app(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/routing.py", line 76, in app
[2m[WebServer] [22m    await wrap_app_handling_exceptions(app, request)(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
[2m[WebServer] [22m    raise exc
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
[2m[WebServer] [22m    await app(scope, receive, sender)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/routing.py", line 73, in app
[2m[WebServer] [22m    response = await f(request)
[2m[WebServer] [22m               ^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/fastapi/routing.py", line 301, in app
[2m[WebServer] [22m    raw_response = await run_endpoint_function(
[2m[WebServer] [22m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<3 lines>...
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/fastapi/routing.py", line 212, in run_endpoint_function
[2m[WebServer] [22m    return await dependant.call(**values)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/routers/workflow_executions.py", line 74, in start_workflow_execution
[2m[WebServer] [22m    execution_id = await langgraph_workflow_engine.execute_workflow(workflow_id)
[2m[WebServer] [22m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/services/langgraph_workflow_engine.py", line 146, in execute_workflow
[2m[WebServer] [22m    await self._execute_workflow_internal(workflow, execution, db)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/services/langgraph_workflow_engine.py", line 214, in _execute_workflow_internal
[2m[WebServer] [22m    async for chunk in graph.astream(initial_state, config):
[2m[WebServer] [22m    ...<36 lines>...
[2m[WebServer] [22m            logger.warning(f"[LangGraphEngine] Received empty chunk #{chunk_count}")
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2732, in astream
[2m[WebServer] [22m    async for _ in runner.atick(
[2m[WebServer] [22m    ...<7 lines>...
[2m[WebServer] [22m            yield o
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/services/langgraph_workflow_engine.py", line 729, in agent_node
[2m[WebServer] [22m    created_messages = await runner.run_thread(db, thread)
[2m[WebServer] [22m                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/managers/agent_runner.py", line 137, in run_thread
[2m[WebServer] [22m    updated_messages = await self._runnable.ainvoke(original_msgs, config)
[2m[WebServer] [22m                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2850, in ainvoke
[2m[WebServer] [22m    async for chunk in self.astream(
[2m[WebServer] [22m    ...<13 lines>...
[2m[WebServer] [22m            chunks.append(chunk)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2732, in astream
[2m[WebServer] [22m    async for _ in runner.atick(
[2m[WebServer] [22m    ...<7 lines>...
[2m[WebServer] [22m            yield o
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 256, in agent_executor
[2m[WebServer] [22m    return _agent_executor_sync(messages, previous=previous)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 248, in _agent_executor_sync
[2m[WebServer] [22m    return asyncio.run(_agent_executor_async(messages, previous=previous))
[2m[WebServer] [22m           ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/runners.py", line 194, in run
[2m[WebServer] [22m    return runner.run(main)
[2m[WebServer] [22m           ~~~~~~~~~~^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/runners.py", line 118, in run
[2m[WebServer] [22m    return self._loop.run_until_complete(task)
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/base_events.py", line 720, in run_until_complete
[2m[WebServer] [22m    return future.result()
[2m[WebServer] [22m           ~~~~~~~~~~~~~^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 208, in _agent_executor_async
[2m[WebServer] [22m    llm_response = await _call_model_async(current_messages)
[2m[WebServer] [22m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 134, in _call_model_async
[2m[WebServer] [22m    return await asyncio.to_thread(_call_model_sync, messages)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/threads.py", line 25, in to_thread
[2m[WebServer] [22m    return await loop.run_in_executor(None, func_call)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/thread.py", line 59, in run
[2m[WebServer] [22m    result = self.fn(*self.args, **self.kwargs)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 127, in _call_model_sync
[2m[WebServer] [22m    return llm_with_tools.invoke(messages)
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/runnables/base.py", line 5416, in invoke
[2m[WebServer] [22m    return self.bound.invoke(
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        input,
[2m[WebServer] [22m        ^^^^^^
[2m[WebServer] [22m        self._merge_configs(config),
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m        **{**self.kwargs, **kwargs},
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 369, in invoke
[2m[WebServer] [22m    self.generate_prompt(
[2m[WebServer] [22m    ~~~~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        [self._convert_input(input)],
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<6 lines>...
[2m[WebServer] [22m        **kwargs,
[2m[WebServer] [22m        ^^^^^^^^^
[2m[WebServer] [22m    ).generations[0][0],
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 946, in generate_prompt
[2m[WebServer] [22m    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
[2m[WebServer] [22m           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 765, 

[1A[2K[2m[WebServer] [22min generate
[2m[WebServer] [22m    self._generate_with_cache(
[2m[WebServer] [22m    ~~~~~~~~~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        m,
[2m[WebServer] [22m        ^^
[2m[WebServer] [22m    ...<2 lines>...
[2m[WebServer] [22m        **kwargs,
[2m[WebServer] [22m        ^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 1011, in _generate_with_cache
[2m[WebServer] [22m    result = self._generate(
[2m[WebServer] [22m        messages, stop=stop, run_manager=run_manager, **kwargs
[2m[WebServer] [22m    )
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py", line 991, in _generate
[2m[WebServer] [22m    response = self.client.create(**payload)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_utils/_utils.py", line 287, in wrapper
[2m[WebServer] [22m    return func(*args, **kwargs)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py", line 925, in create
[2m[WebServer] [22m    return self._post(
[2m[WebServer] [22m           ~~~~~~~~~~^
[2m[WebServer] [22m        "/chat/completions",
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<43 lines>...
[2m[WebServer] [22m        stream_cls=Stream[ChatCompletionChunk],
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_base_client.py", line 1239, in post
[2m[WebServer] [22m    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
[2m[WebServer] [22m                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_base_client.py", line 1034, in request
[2m[WebServer] [22m    raise self._make_status_error_from_response(err.response) from None
[2m[WebServer] [22mopenai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `gpt-mock` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
[2m[WebServer] [22mDuring task with name 'agent_executor' and id '69a614a1-b8c5-b4ee-63eb-55b49a22efa8'
[2m[WebServer] [22mDuring task with name 'agent-1' and id '2b5b6b3f-e04b-e1e9-e48e-36af28e847f9'

[1A[2K❌ User 1 execution failed: [33m500[39m

[1A[2K📊 Successful workflow executions: [33m0[39m / [33m3[39m

[1A[2K📊 Concurrent execution start time: [33m1113[39m ms

[1A[2K📊 Test 3: Monitoring concurrent executions...

[1A[2K[2m[WebServer] [22mERROR:    Exception in ASGI application
[2m[WebServer] [22mTraceback (most recent call last):
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/uvicorn/protocols/http/h11_impl.py", line 408, in run_asgi
[2m[WebServer] [22m    result = await app(  # type: ignore[func-returns-value]
[2m[WebServer] [22m             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m        self.scope, self.receive, self.send
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/uvicorn/middleware/proxy_headers.py", line 84, in __call__
[2m[WebServer] [22m    return await self.app(scope, receive, send)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/fastapi/applications.py", line 1054, in __call__
[2m[WebServer] [22m    await super().__call__(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/applications.py", line 112, in __call__
[2m[WebServer] [22m    await self.middleware_stack(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/middleware/errors.py", line 187, in __call__
[2m[WebServer] [22m    raise exc
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/middleware/errors.py", line 165, in __call__
[2m[WebServer] [22m    await self.app(scope, receive, _send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/middleware/worker_db.py", line 101, in __call__
[2m[WebServer] [22m    await self.app(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/middleware/cors.py", line 85, in __call__
[2m[WebServer] [22m    await self.app(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/middleware/exceptions.py", line 62, in __call__
[2m[WebServer] [22m    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
[2m[WebServer] [22m    raise exc
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
[2m[WebServer] [22m    await app(scope, receive, sender)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/routing.py", line 714, in __call__
[2m[WebServer] [22m    await self.middleware_stack(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/routing.py", line 734, in app
[2m[WebServer] [22m    await route.handle(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/routing.py", line 288, in handle
[2m[WebServer] [22m    await self.app(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/routing.py", line 76, in app
[2m[WebServer] [22m    await wrap_app_handling_exceptions(app, request)(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
[2m[WebServer] [22m    raise exc
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
[2m[WebServer] [22m    await app(scope, receive, sender)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/routing.py", line 73, in app
[2m[WebServer] [22m    response = await f(request)
[2m[WebServer] [22m               ^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/fastapi/routing.py", line 301, in app
[2m[WebServer] [22m    raw_response = await run_endpoint_function(
[2m[WebServer] [22m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<3 lines>...
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/fastapi/routing.py", line 212, in run_endpoint_function
[2m[WebServer] [22m    return await dependant.call(**values)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/routers/workflow_executions.py", line 74, in start_workflow_execution
[2m[WebServer] [22m    execution_id = await langgraph_workflow_engine.execute_workflow(workflow_id)
[2m[WebServer] [22m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/services/langgraph_workflow_engine.py", line 146, in execute_workflow
[2m[WebServer] [22m    await self._execute_workflow_internal(workflow, execution, db)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/services/langgraph_workflow_engine.py", line 214, in _execute_workflow_internal
[2m[WebServer] [22m    async for chunk in graph.astream(initial_state, config):
[2m[WebServer] [22m    ...<36 lines>...
[2m[WebServer] [22m            logger.warning(f"[LangGraphEngine] Received empty chunk #{chunk_count}")
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2732, in astream
[2m[WebServer] [22m    async for _ in runner.atick(
[2m[WebServer] [22m    ...<7 lines>...
[2m[WebServer] [22m            yield o
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/services/langgraph_workflow_engine.py", line 729, in agent_node
[2m[WebServer] [22m    created_messages = await runner.run_thread(db, thread)
[2m[WebServer] [22m                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/managers/agent_runner.py", line 137, in run_thread
[2m[WebServer] [22m    updated_messages = await self._runnable.ainvoke(original_msgs, config)
[2m[WebServer] [22m                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2850, in ainvoke
[2m[WebServer] [22m    async for chunk in self.astream(
[2m[WebServer] [22m    ...<13 lines>...
[2m[WebServer] [22m            chunks.append(chunk)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2732, in astream
[2m[WebServer] [22m    async for _ in runner.atick(
[2m[WebServer] [22m    ...<7 lines>...
[2m[WebServer] [22m            yield o
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 256, in agent_executor
[2m[WebServer] [22m    return _agent_executor_sync(messages, previous=previous)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 248, in _agent_executor_sync
[2m[WebServer] [22m    return asyncio.run(_agent_executor_async(messages, previous=previous))
[2m[WebServer] [22m           ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/runners.py", line 194, in run
[2m[WebServer] [22m    return runner.run(main)
[2m[WebServer] [22m           ~~~~~~~~~~^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/runners.py", line 118, in run
[2m[WebServer] [22m    return self._loop.run_until_complete(task)
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/base_events.py", line 720, in run_until_complete
[2m[WebServer] [22m    return future.result()
[2m[WebServer] [22m           ~~~~~~~~~~~~~^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 208, in _agent_executor_async
[2m[WebServer] [22m    llm_response = await _call_model_async(current_messages)
[2m[WebServer] [22m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 134, in _call_model_async
[2m[WebServer] [22m    return await asyncio.to_thread(_call_model_sync, messages)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/threads.py", line 25, in to_thread
[2m[WebServer] [22m    return await loop.run_in_executor(None, func_call)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/thread.py", line 59, in run
[2m[WebServer] [22m    result = self.fn(*self.args, **self.kwargs)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 127, in _call_model_sync
[2m[WebServer] [22m    return llm_with_tools.invoke(messages)
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/runnables/base.py", line 5416, in invoke
[2m[WebServer] [22m    return self.bound.invoke(
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        input,
[2m[WebServer] [22m        ^^^^^^
[2m[WebServer] [22m        self._merge_configs(config),
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^

[1A[2K[2m[WebServer] [22m^^^^^^^^^
[2m[WebServer] [22m        **{**self.kwargs, **kwargs},
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 369, in invoke
[2m[WebServer] [22m    self.generate_prompt(
[2m[WebServer] [22m    ~~~~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        [self._convert_input(input)],
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<6 lines>...
[2m[WebServer] [22m        **kwargs,
[2m[WebServer] [22m        ^^^^^^^^^
[2m[WebServer] [22m    ).generations[0][0],
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 946, in generate_prompt
[2m[WebServer] [22m    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
[2m[WebServer] [22m           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 765, in generate
[2m[WebServer] [22m    self._generate_with_cache(
[2m[WebServer] [22m    ~~~~~~~~~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        m,
[2m[WebServer] [22m        ^^
[2m[WebServer] [22m    ...<2 lines>...
[2m[WebServer] [22m        **kwargs,
[2m[WebServer] [22m        ^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 1011, in _generate_with_cache
[2m[WebServer] [22m    result = self._generate(
[2m[WebServer] [22m        messages, stop=stop, run_manager=run_manager, **kwargs
[2m[WebServer] [22m    )
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py", line 991, in _generate
[2m[WebServer] [22m    response = self.client.create(**payload)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_utils/_utils.py", line 287, in wrapper
[2m[WebServer] [22m    return func(*args, **kwargs)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py", line 925, in create
[2m[WebServer] [22m    return self._post(
[2m[WebServer] [22m           ~~~~~~~~~~^
[2m[WebServer] [22m        "/chat/completions",
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<43 lines>...
[2m[WebServer] [22m        stream_cls=Stream[ChatCompletionChunk],
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_base_client.py", line 1239, in post
[2m[WebServer] [22m    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
[2m[WebServer] [22m                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_base_client.py", line 1034, in request
[2m[WebServer] [22m    raise self._make_status_error_from_response(err.response) from None
[2m[WebServer] [22mopenai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `gpt-mock` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
[2m[WebServer] [22mDuring task with name 'agent_executor' and id '69a614a1-b8c5-b4ee-63eb-55b49a22efa8'
[2m[WebServer] [22mDuring task with name 'agent-1' and id '2b5b6b3f-e04b-e1e9-e48e-36af28e847f9'

[1A[2K✅ Concurrent workflow execution test completed

[1A[2K[21/36] tests/multi_user_concurrency.spec.ts:351:7 › Multi-User and Concurrency › WebSocket message broadcasting and isolation
[1A[2Ktests/multi_user_concurrency.spec.ts:351:7 › Multi-User and Concurrency › WebSocket message broadcasting and isolation
🚀 Starting WebSocket broadcasting test...

[1A[2K📊 Created 2 WebSocket monitoring sessions

[1A[2K📊 Test 1: Connecting users and monitoring initial messages...

[1A[2Ktests/error_handling_edge_cases.spec.ts:261:7 › Error Handling and Edge Cases › UI error state handling
📊 Invalid route page title: AI Agent Platform

[1A[2K📊 Error content present: [33mfalse[39m

[1A[2K📊 Test 3: JavaScript error monitoring

[1A[2Ktests/multi_user_concurrency.spec.ts:351:7 › Multi-User and Concurrency › WebSocket message broadcasting and isolation
📊 User 0 WebSocket connected: ws://localhost:8001/api/ws

[1A[2K📊 User 0 received: user_update

[1A[2K📊 User 1 WebSocket connected: ws://localhost:8001/api/ws

[1A[2K📊 User 1 received: user_update

[1A[2K📊 Test 2: Testing cross-session message broadcasting...

[1A[2K📊 Created agent in primary session: [33m1[39m

[1A[2Ktests/error_handling_edge_cases.spec.ts:261:7 › Error Handling and Edge Cases › UI error state handling
📊 JavaScript errors detected: [33m0[39m

[1A[2K✅ No JavaScript errors during navigation

[1A[2K✅ UI error state test completed

[1A[2K[22/36] tests/multi_user_concurrency.spec.ts:511:7 › Multi-User and Concurrency › Resource sharing and conflict resolution
[1A[2Ktests/multi_user_concurrency.spec.ts:511:7 › Multi-User and Concurrency › Resource sharing and conflict resolution
🚀 Starting resource sharing and conflict resolution test...

[1A[2K📊 Created 2 sessions for conflict testing

[1A[2K📊 Test 1: Testing concurrent modifications...

[1A[2K📊 User 1 created agent: [33m1[39m (340ms)

[1A[2K📊 User 0 created agent: [33m1[39m (360ms)

[1A[2K📊 Successful concurrent operations: [33m2[39m / [33m2[39m

[1A[2K📊 Response time range: [33m340[39m ms - [33m360[39m ms

[1A[2K📊 Average response time: [33m350[39m ms

[1A[2K✅ Concurrent operations have similar response times

[1A[2K📊 Test 2: Verifying database consistency...

[1A[2K📊 User 0 sees 1 agents

[1A[2K📊 User 1 sees 1 agents

[1A[2K📊 Test 3: Testing resource contention...

[1A[2K📊 User 0 created workflow referencing shared agent: [33m1[39m

[1A[2K📊 User 1 created workflow referencing shared agent: [33m1[39m

[1A[2K📊 Successful resource sharing operations: [33m2[39m / [33m2[39m

[1A[2K✅ Resource sharing handles concurrent access well

[1A[2K✅ Resource sharing and conflict resolution test completed

[1A[2K[23/36] tests/multi_user_concurrency.spec.ts:666:7 › Multi-User and Concurrency › Session management and cleanup
[1A[2Ktests/multi_user_concurrency.spec.ts:666:7 › Multi-User and Concurrency › Session management and cleanup
🚀 Starting session management test...

[1A[2K📊 Test 1: Testing session lifecycle...

[1A[2Ktests/multi_user_concurrency.spec.ts:351:7 › Multi-User and Concurrency › WebSocket message broadcasting and isolation
📊 User 0 received 1 agent-related messages

[1A[2K✅ User 0 received WebSocket notifications

[1A[2K📊 User 1 received 1 agent-related messages

[1A[2K✅ User 1 received WebSocket notifications

[1A[2K📊 Test 3: Testing session isolation in WebSocket messages...

[1A[2K📊 Primary session message types: []

[1A[2K📊 Secondary session message types: []

[1A[2K📊 Cross-session messages in secondary: [33m0[39m

[1A[2K✅ WebSocket messages properly isolated between sessions

[1A[2K📊 Test 4: Testing high-frequency message handling...

[1A[2K📊 Rapid operations completed: [33m5[39m / [33m5[39m

[1A[2K📊 Rapid operations time: [33m320[39m ms

[1A[2Ktests/multi_user_concurrency.spec.ts:666:7 › Multi-User and Concurrency › Session management and cleanup
📊 Created agent in session 1: [33m1[39m

[1A[2K📊 Closed session 1

[1A[2K📊 Test 2: Testing data persistence after session closure...

[1A[2K📊 Agent persisted after session closure: [33mtrue[39m

[1A[2K✅ Data persists correctly after session closure

[1A[2K📊 Test 3: Verifying session isolation...

[1A[2K📊 Created agent in session 2: [33m1[39m

[1A[2K📊 Session 2 sees session 1 data: [33mtrue[39m

[1A[2K📊 Session 2 sees own data: [33mtrue[39m

[1A[2K📊 Sessions share data (may be intended behavior)

[1A[2K📊 Test 4: Testing cleanup mechanisms...

[1A[2K📊 Created temporary agent: [33m1[39m

[1A[2K📊 Cleanup verification completed (manual inspection may be needed)

[1A[2K✅ Session management test completed

[1A[2K[24/36] tests/performance_load_testing.spec.ts:18:7 › Performance and Load Testing › UI responsiveness benchmarking
[1A[2Ktests/performance_load_testing.spec.ts:18:7 › Performance and Load Testing › UI responsiveness benchmarking
🚀 Starting UI responsiveness test...

[1A[2K📊 Worker ID: 0

[1A[2K📊 Test 1: Page load performance...

[1A[2Ktests/multi_user_concurrency.spec.ts:351:7 › Multi-User and Concurrency › WebSocket message broadcasting and isolation
📊 User 0 received 0 messages during rapid operations

[1A[2K📊 User 1 received 0 messages during rapid operations

[1A[2K✅ WebSocket broadcasting test completed

[1A[2K[25/36] tests/performance_load_testing.spec.ts:94:7 › Performance and Load Testing › API response time benchmarking
[1A[2Ktests/performance_load_testing.spec.ts:94:7 › Performance and Load Testing › API response time benchmarking
🚀 Starting API performance test...

[1A[2K📊 Test 1: Single API request performance...

[1A[2K📊 GET /api/agents response time: [33m4[39m ms

[1A[2K📊 GET /api/agents status: [33m200[39m

[1A[2K✅ GET /api/agents is very fast (< 200ms)

[1A[2K📊 GET /api/workflows response time: [33m3[39m ms

[1A[2K📊 GET /api/workflows status: [33m200[39m

[1A[2K✅ GET /api/workflows is very fast (< 200ms)

[1A[2K📊 GET /api/users/me response time: [33m2[39m ms

[1A[2K📊 GET /api/users/me status: [33m200[39m

[1A[2K✅ GET /api/users/me is very fast (< 200ms)

[1A[2K📊 Test 2: Batch API request performance...

[1A[2Ktests/performance_load_testing.spec.ts:18:7 › Performance and Load Testing › UI responsiveness benchmarking
📊 Page load time: [33m1116[39m ms

[1A[2K✅ Page loads within acceptable time (< 3s)

[1A[2K📊 Test 2: Navigation performance...

[1A[2Ktests/performance_load_testing.spec.ts:94:7 › Performance and Load Testing › API response time benchmarking
📊 Batch requests completed: [33m10[39m / [33m10[39m

[1A[2K📊 Batch total time: [33m326[39m ms

[1A[2K📊 Average per request: [33m33[39m ms

[1A[2K✅ Batch API performance is good

[1A[2K✅ API performance test completed

[1A[2K[26/36] tests/performance_load_testing.spec.ts:161:7 › Performance and Load Testing › Database performance with large datasets
[1A[2Ktests/performance_load_testing.spec.ts:161:7 › Performance and Load Testing › Database performance with large datasets
🚀 Starting database performance test...

[1A[2K📊 Test 1: Creating large dataset...

[1A[2Ktests/performance_load_testing.spec.ts:18:7 › Performance and Load Testing › UI responsiveness benchmarking
📊 Dashboard navigation time: [33m153[39m ms

[1A[2K✅ Dashboard navigation is responsive (< 500ms)

[1A[2K📊 Canvas navigation time: [33m193[39m ms

[1A[2K✅ Canvas navigation is responsive (< 500ms)

[1A[2K📊 Test 3: UI interaction responsiveness...

[1A[2K📊 Interactive elements found: [33m23[39m

[1A[2Ktests/performance_load_testing.spec.ts:161:7 › Performance and Load Testing › Database performance with large datasets
📊 Agents created successfully: [33m50[39m / [33m50[39m

[1A[2K📊 Creation time: [33m624[39m ms

[1A[2K📊 Average creation time: [33m12[39m ms per agent

[1A[2K✅ Large dataset creation successful

[1A[2K📊 Test 2: Query performance with large dataset...

[1A[2K📊 Total agents retrieved: [33m68[39m

[1A[2K📊 Query time: [33m7[39m ms

[1A[2K✅ Large dataset query performance is good (< 1s)

[1A[2K📊 Test 3: Testing pagination performance...

[1A[2K📊 Pagination query status: [33m200[39m

[1A[2K📊 Pagination query time: [33m4[39m ms

[1A[2K📊 Paginated results returned: [33m10[39m

[1A[2K✅ Pagination performance is excellent

[1A[2K✅ Database performance test completed

[1A[2K[27/36] tests/performance_load_testing.spec.ts:256:7 › Performance and Load Testing › Memory usage and resource monitoring
[1A[2Ktests/performance_load_testing.spec.ts:256:7 › Performance and Load Testing › Memory usage and resource monitoring
🚀 Starting memory usage test...

[1A[2K📊 Test 1: Establishing memory baseline...

[1A[2K📊 Initial memory usage: { used: [33m10000000[39m, total: [33m11900000[39m, limit: [33m3760000000[39m }

[1A[2K📊 Page timing: { domContentLoaded: [33m523[39m, fullyLoaded: [33m685[39m }

[1A[2K📊 Test 2: Memory usage during intensive operations...

[1A[2K📊 Memory usage after operations: { used: [33m10000000[39m, total: [33m11900000[39m }

[1A[2K📊 Memory increase: [33m0[39m %

[1A[2K✅ Memory usage increase is reasonable

[1A[2K📊 Test 3: Memory leak detection...

[1A[2Ktests/performance_load_testing.spec.ts:18:7 › Performance and Load Testing › UI responsiveness benchmarking
📊 Hover test skipped (element not interactive)

[1A[2K✅ UI responsiveness test completed

[1A[2K[28/36] tests/performance_load_testing.spec.ts:371:7 › Performance and Load Testing › Concurrent user simulation
[1A[2Ktests/performance_load_testing.spec.ts:371:7 › Performance and Load Testing › Concurrent user simulation
🚀 Starting concurrent user simulation...

[1A[2K📊 Test 1: Simulating 5 concurrent users...

[1A[2Ktests/performance_load_testing.spec.ts:256:7 › Performance and Load Testing › Memory usage and resource monitoring
📊 Memory usage after GC: { used: [33m10000000[39m, total: [33m11900000[39m }

[1A[2K📊 Memory freed by GC: [33m0[39m bytes

[1A[2K✅ Memory usage test completed

[1A[2K[29/36] tests/performance_load_testing.spec.ts:444:7 › Performance and Load Testing › Large workflow performance
[1A[2Ktests/performance_load_testing.spec.ts:444:7 › Performance and Load Testing › Large workflow performance
🚀 Starting large workflow performance test...

[1A[2K📊 Test 1: Creating agents for large workflow...

[1A[2K📊 Created agent 0: [33m79[39m

[1A[2K📊 Created agent 1: [33m80[39m

[1A[2K📊 Created agent 2: [33m81[39m

[1A[2K📊 Created agent 3: [33m82[39m

[1A[2K📊 Created agent 4: [33m83[39m

[1A[2K📊 Created agent 5: [33m84[39m

[1A[2K📊 Created agent 6: [33m85[39m

[1A[2K📊 Created agent 7: [33m86[39m

[1A[2K📊 Created agent 8: [33m87[39m

[1A[2K📊 Created agent 9: [33m88[39m

[1A[2K📊 Total agents for large workflow: [33m10[39m

[1A[2K📊 Test 2: Creating large workflow...

[1A[2K📊 Large workflow creation status: [33m200[39m

[1A[2K📊 Large workflow creation time: [33m308[39m ms

[1A[2K📊 Workflow nodes: [33m16[39m

[1A[2K📊 Workflow connections: [33m16[39m

[1A[2K📊 Large workflow created with ID: [33m3[39m

[1A[2K📊 Large workflow retrieval time: [33m1[39m ms

[1A[2K✅ Large workflow performance is acceptable

[1A[2K✅ Large workflow performance test completed

[1A[2K[30/36] tests/realtime_websocket_monitoring.spec.ts:15:7 › Real-time WebSocket Monitoring › WebSocket event monitoring and real-time updates
[1A[2Ktests/realtime_websocket_monitoring.spec.ts:15:7 › Real-time WebSocket Monitoring › WebSocket event monitoring and real-time updates
🚀 Starting WebSocket monitoring test...

[1A[2K📊 Worker ID: 0

[1A[2K📊 Step 1: Connecting to application...

[1A[2Ktests/performance_load_testing.spec.ts:371:7 › Performance and Load Testing › Concurrent user simulation
📊 User 4 agent creation: success

[1A[2K📊 User 2 agent creation: success

[1A[2K📊 User 0 agent creation: success

[1A[2K📊 User 1 agent creation: success

[1A[2K📊 User 3 agent creation: success

[1A[2K📊 Concurrent users completed successfully: [33m5[39m / [33m5[39m

[1A[2K📊 Total simulation time: [33m3100[39m ms

[1A[2K📊 Average time per user: [33m620[39m ms

[1A[2K✅ Concurrent user handling is robust

[1A[2K✅ Concurrent user simulation completed

[1A[2K[31/36] tests/tool_palette_node_connections.spec.ts:18:7 › Tool Palette and Node Connections › Tool palette discovery and cataloging
[1A[2Ktests/tool_palette_node_connections.spec.ts:18:7 › Tool Palette and Node Connections › Tool palette discovery and cataloging
🚀 Starting tool palette discovery test...

[1A[2K📊 Worker ID: 0

[1A[2Ktests/realtime_websocket_monitoring.spec.ts:15:7 › Real-time WebSocket Monitoring › WebSocket event monitoring and real-time updates
📊 Step 2: Monitoring WebSocket activity...

[1A[2K📊 Step 3: Creating agent to trigger updates...

[1A[2K✅ Agent created, waiting for WebSocket updates...

[1A[2K📊 Step 4: Navigating to trigger more WebSocket events...

[1A[2Ktests/tool_palette_node_connections.spec.ts:18:7 › Tool Palette and Node Connections › Tool palette discovery and cataloging
📊 Test 1: Locating tool palette...

[1A[2K📊 Tool palette visible: [33mfalse[39m

[1A[2K⚠️  Tool palette not visible - checking alternative locations...

[1A[2K📊 Alternative tool containers found: [33m0[39m

[1A[2K✅ Tool palette discovery completed

[1A[2K[32/36] tests/tool_palette_node_connections.spec.ts:84:7 › Tool Palette and Node Connections › Tool drag-and-drop from palette to canvas
[1A[2Ktests/tool_palette_node_connections.spec.ts:84:7 › Tool Palette and Node Connections › Tool drag-and-drop from palette to canvas
🚀 Starting tool drag-and-drop test...

[1A[2K📊 Created test agent: [33m90[39m

[1A[2Ktests/realtime_websocket_monitoring.spec.ts:15:7 › Real-time WebSocket Monitoring › WebSocket event monitoring and real-time updates
📊 Step 5: Analyzing WebSocket messages...

[1A[2K📊 Total WebSocket messages received: [33m0[39m

[1A[2K⚠️  No WebSocket messages received - may need connection investigation

[1A[2K📊 Step 6: Testing real-time UI updates...

[1A[2K📊 Agent visible in dashboard: [33mfalse[39m

[1A[2K📊 Step 7: Checking for real-time status indicators...

[1A[2K📊 Status indicators found: [33m0[39m

[1A[2K📊 Online indicators found: [33m0[39m

[1A[2K📊 Activity indicators found: [33m0[39m

[1A[2K✅ WebSocket monitoring test completed

[1A[2K📊 Summary: Real-time WebSocket communication validated

[1A[2K[33/36] tests/tool_palette_node_connections.spec.ts:180:7 › Tool Palette and Node Connections › Node connection handle detection and interaction
[1A[2Ktests/tool_palette_node_connections.spec.ts:180:7 › Tool Palette and Node Connections › Node connection handle detection and interaction
🚀 Starting node connection test...

[1A[2Ktests/tool_palette_node_connections.spec.ts:84:7 › Tool Palette and Node Connections › Tool drag-and-drop from palette to canvas
📊 Test 1: Identifying drag-and-drop targets...

[1A[2K📊 Canvas container visible: [33mfalse[39m

[1A[2K✅ Tool drag-and-drop test completed

[1A[2K[34/36] tests/tool_palette_node_connections.spec.ts:309:7 › Tool Palette and Node Connections › Complex workflow topology creation
[1A[2Ktests/tool_palette_node_connections.spec.ts:309:7 › Tool Palette and Node Connections › Complex workflow topology creation
🚀 Starting complex workflow topology test...

[1A[2K📊 Test 1: Creating multiple agents...

[1A[2K📊 Created agent 1: [33m92[39m

[1A[2K📊 Created agent 2: [33m93[39m

[1A[2K📊 Created agent 3: [33m94[39m

[1A[2K📊 Total agents created: [33m3[39m

[1A[2K📊 Test 2: Creating complex workflow topology...

[1A[2K📊 Complex workflow created: [33m4[39m

[1A[2K📊 Test 3: Verifying topology integrity...

[1A[2K✅ Complex workflow topology test completed

[1A[2K[35/36] tests/tool_palette_node_connections.spec.ts:458:7 › Tool Palette and Node Connections › Connection validation and constraint checking
[1A[2Ktests/tool_palette_node_connections.spec.ts:458:7 › Tool Palette and Node Connections › Connection validation and constraint checking
🚀 Starting connection validation test...

[1A[2K📊 Test 1: Testing valid connection topology...

[1A[2K📊 Valid workflow creation status: [33m200[39m

[1A[2K✅ Valid connection topology accepted

[1A[2K📊 Test 2: Testing invalid connection scenarios...

[1A[2K📊 Circular workflow creation status: [33m200[39m

[1A[2K📊 Circular references allowed (system permits cycles)

[1A[2K📊 Test 3: Testing non-existent node references...

[1A[2K📊 Invalid node workflow status: [33m200[39m

[1A[2K✅ Connection validation test completed

[1A[2K[36/36] tests/workflow_execution_http.spec.ts:15:7 › Workflow Execution with HTTP Tools › Execute workflow with HTTP tool and verify requests
[1A[2Ktests/workflow_execution_http.spec.ts:15:7 › Workflow Execution with HTTP Tools › Execute workflow with HTTP tool and verify requests
🚀 Starting workflow execution test...

[1A[2K📊 Worker ID: 2

[1A[2K📊 Step 1: Creating test agent...

[1A[2K✅ Test agent created with ID: [33m1[39m

[1A[2K📊 Step 2: Attempting workflow creation...

[1A[2K✅ Workflow created with ID: [33m2[39m

[1A[2K📊 Step 3: Executing workflow...

[1A[2K[2m[WebServer] [22mERROR - [AgentRunner] Exception during runnable.ainvoke: Error code: 404 - {'error': {'message': 'The model `gpt-mock` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
[2m[WebServer] [22mTraceback (most recent call last):
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/managers/agent_runner.py", line 137, in run_thread
[2m[WebServer] [22m    updated_messages = await self._runnable.ainvoke(original_msgs, config)
[2m[WebServer] [22m                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2850, in ainvoke
[2m[WebServer] [22m    async for chunk in self.astream(
[2m[WebServer] [22m    ...<13 lines>...
[2m[WebServer] [22m            chunks.append(chunk)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2732, in astream
[2m[WebServer] [22m    async for _ in runner.atick(
[2m[WebServer] [22m    ...<7 lines>...
[2m[WebServer] [22m            yield o
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 256, in agent_executor
[2m[WebServer] [22m    return _agent_executor_sync(messages, previous=previous)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 248, in _agent_executor_sync
[2m[WebServer] [22m    return asyncio.run(_agent_executor_async(messages, previous=previous))
[2m[WebServer] [22m           ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/runners.py", line 194, in run
[2m[WebServer] [22m    return runner.run(main)
[2m[WebServer] [22m           ~~~~~~~~~~^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/runners.py", line 118, in run
[2m[WebServer] [22m    return self._loop.run_until_complete(task)
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/base_events.py", line 720, in run_until_complete
[2m[WebServer] [22m    return future.result()
[2m[WebServer] [22m           ~~~~~~~~~~~~~^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 208, in _agent_executor_async
[2m[WebServer] [22m    llm_response = await _call_model_async(current_messages)
[2m[WebServer] [22m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 134, in _call_model_async
[2m[WebServer] [22m    return await asyncio.to_thread(_call_model_sync, messages)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/threads.py", line 25, in to_thread
[2m[WebServer] [22m    return await loop.run_in_executor(None, func_call)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/thread.py", line 59, in run
[2m[WebServer] [22m    result = self.fn(*self.args, **self.kwargs)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 127, in _call_model_sync
[2m[WebServer] [22m    return llm_with_tools.invoke(messages)
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/runnables/base.py", line 5416, in invoke
[2m[WebServer] [22m    return self.bound.invoke(
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        input,
[2m[WebServer] [22m        ^^^^^^
[2m[WebServer] [22m        self._merge_configs(config),
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m        **{**self.kwargs, **kwargs},
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 369, in invoke
[2m[WebServer] [22m    self.generate_prompt(
[2m[WebServer] [22m    ~~~~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        [self._convert_input(input)],
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<6 lines>...
[2m[WebServer] [22m        **kwargs,
[2m[WebServer] [22m        ^^^^^^^^^
[2m[WebServer] [22m    ).generations[0][0],
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 946, in generate_prompt
[2m[WebServer] [22m    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
[2m[WebServer] [22m           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 765, in generate
[2m[WebServer] [22m    self._generate_with_cache(
[2m[WebServer] [22m    ~~~~~~~~~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        m,
[2m[WebServer] [22m        ^^
[2m[WebServer] [22m    ...<2 lines>...
[2m[WebServer] [22m        **kwargs,
[2m[WebServer] [22m        ^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 1011, in _generate_with_cache
[2m[WebServer] [22m    result = self._generate(
[2m[WebServer] [22m        messages, stop=stop, run_manager=run_manager, **kwargs
[2m[WebServer] [22m    )
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py", line 991, in _generate
[2m[WebServer] [22m    response = self.client.create(**payload)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_utils/_utils.py", line 287, in wrapper
[2m[WebServer] [22m    return func(*args, **kwargs)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py", line 925, in create
[2m[WebServer] [22m    return self._post(
[2m[WebServer] [22m           ~~~~~~~~~~^
[2m[WebServer] [22m        "/chat/completions",
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<43 lines>...
[2m[WebServer] [22m        stream_cls=Stream[ChatCompletionChunk],
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_base_client.py", line 1239, in post
[2m[WebServer] [22m    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
[2m[WebServer] [22m                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_base_client.py", line 1034, in request
[2m[WebServer] [22m    raise self._make_status_error_from_response(err.response) from None
[2m[WebServer] [22mopenai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `gpt-mock` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
[2m[WebServer] [22mDuring task with name 'agent_executor' and id '40f0318f-84e6-156c-6968-498b27db9d91'

[1A[2K[2m[WebServer] [22mERROR - [AgentNode] Exception in agent node agent-1 (agent_id=1): Error code: 404 - {'error': {'message': 'The model `gpt-mock` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
[2m[WebServer] [22mTraceback (most recent call last):
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/services/langgraph_workflow_engine.py", line 729, in agent_node
[2m[WebServer] [22m    created_messages = await runner.run_thread(db, thread)
[2m[WebServer] [22m                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/managers/agent_runner.py", line 137, in run_thread
[2m[WebServer] [22m    updated_messages = await self._runnable.ainvoke(original_msgs, config)
[2m[WebServer] [22m                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2850, in ainvoke
[2m[WebServer] [22m    async for chunk in self.astream(
[2m[WebServer] [22m    ...<13 lines>...
[2m[WebServer] [22m            chunks.append(chunk)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2732, in astream
[2m[WebServer] [22m    async for _ in runner.atick(
[2m[WebServer] [22m    ...<7 lines>...
[2m[WebServer] [22m            yield o
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 256, in agent_executor
[2m[WebServer] [22m    return _agent_executor_sync(messages, previous=previous)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 248, in _agent_executor_sync
[2m[WebServer] [22m    return asyncio.run(_agent_executor_async(messages, previous=previous))
[2m[WebServer] [22m           ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/runners.py", line 194, in run
[2m[WebServer] [22m    return runner.run(main)
[2m[WebServer] [22m           ~~~~~~~~~~^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/runners.py", line 118, in run
[2m[WebServer] [22m    return self._loop.run_until_complete(task)
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/base_events.py", line 720, in run_until_complete
[2m[WebServer] [22m    return future.result()
[2m[WebServer] [22m           ~~~~~~~~~~~~~^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 208, in _agent_executor_async
[2m[WebServer] [22m    llm_response = await _call_model_async(current_messages)
[2m[WebServer] [22m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 134, in _call_model_async
[2m[WebServer] [22m    return await asyncio.to_thread(_call_model_sync, messages)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/threads.py", line 25, in to_thread
[2m[WebServer] [22m    return await loop.run_in_executor(None, func_call)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/thread.py", line 59, in run
[2m[WebServer] [22m    result = self.fn(*self.args, **self.kwargs)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 127, in _call_model_sync
[2m[WebServer] [22m    return llm_with_tools.invoke(messages)
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/runnables/base.py", line 5416, in invoke
[2m[WebServer] [22m    return self.bound.invoke(
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        input,
[2m[WebServer] [22m        ^^^^^^
[2m[WebServer] [22m        self._merge_configs(config),
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m        **{**self.kwargs, **kwargs},
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 369, in invoke
[2m[WebServer] [22m    self.generate_prompt(
[2m[WebServer] [22m    ~~~~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        [self._convert_input(input)],
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<6 lines>...
[2m[WebServer] [22m        **kwargs,
[2m[WebServer] [22m        ^^^^^^^^^
[2m[WebServer] [22m    ).generations[0][0],
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 946, in generate_prompt
[2m[WebServer] [22m    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
[2m[WebServer] [22m           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 765, in generate
[2m[WebServer] [22m    self._generate_with_cache(
[2m[WebServer] [22m    ~~~~~~~~~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        m,
[2m[WebServer] [22m        ^^
[2m[WebServer] [22m    ...<2 lines>...
[2m[WebServer] [22m        **kwargs,
[2m[WebServer] [22m        ^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 1011, in _generate_with_cache
[2m[WebServer] [22m    result = self._generate(
[2m[WebServer] [22m        messages, stop=stop, run_manager=run_manager, **kwargs
[2m[WebServer] [22m    )
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py", line 991, in _generate
[2m[WebServer] [22m    response = self.client.create(**payload)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_utils/_utils.py", line 287, in wrapper
[2m[WebServer] [22m    return func(*args, **kwargs)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py", line 925, in create
[2m[WebServer] [22m    return self._post(
[2m[WebServer] [22m           ~~~~~~~~~~^
[2m[WebServer] [22m        "/chat/completions",
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<43 lines>...
[2m[WebServer] [22m        stream_cls=Stream[ChatCompletionChunk],
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_base_client.py", line 1239, in post
[2m[WebServer] [22m    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
[2m[WebServer] [22m                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_base_client.py", line 1034, in request
[2m[WebServer] [22m    raise self._make_status_error_from_response(err.response) from None
[2m[WebServer] [22mopenai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `gpt-mock` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
[2m[WebServer] [22mDuring task with name 'agent_executor' and id '40f0318f-84e6-156c-6968-498b27db9d91'

[1A[2K[2m[WebServer] [22mERROR - [AgentNode] Updated node_state to 'failed' in DB

[1A[2K[2m[WebServer] [22mERROR - [AgentNode] Re-raising exception to fail workflow execution

[1A[2K[2m[WebServer] [22mERROR - [LangGraphEngine] Execution failed – execution_id=1
[2m[WebServer] [22mTraceback (most recent call last):
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/services/langgraph_workflow_engine.py", line 146, in execute_workflow
[2m[WebServer] [22m    await self._execute_workflow_internal(workflow, execution, db)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/services/langgraph_workflow_engine.py", line 214, in _execute_workflow_internal
[2m[WebServer] [22m    async for chunk in graph.astream(initial_state, config):
[2m[WebServer] [22m    ...<36 lines>...
[2m[WebServer] [22m            logger.warning(f"[LangGraphEngine] Received empty chunk #{chunk_count}")
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2732, in astream
[2m[WebServer] [22m    async for _ in runner.atick(
[2m[WebServer] [22m    ...<7 lines>...
[2m[WebServer] [22m            yield o
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/services/langgraph_workflow_engine.py", line 729, in agent_node
[2m[WebServer] [22m    created_messages = await runner.run_thread(db, thread)
[2m[WebServer] [22m                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/managers/agent_runner.py", line 137, in run_thread
[2m[WebServer] [22m    updated_messages = await self._runnable.ainvoke(original_msgs, config)
[2m[WebServer] [22m                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2850, in ainvoke
[2m[WebServer] [22m    async for chunk in self.astream(
[2m[WebServer] [22m    ...<13 lines>...
[2m[WebServer] [22m            chunks.append(chunk)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2732, in astream
[2m[WebServer] [22m    async for _ in runner.atick(
[2m[WebServer] [22m    ...<7 lines>...
[2m[WebServer] [22m            yield o
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 256, in agent_executor
[2m[WebServer] [22m    return _agent_executor_sync(messages, previous=previous)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 248, in _agent_executor_sync
[2m[WebServer] [22m    return asyncio.run(_agent_executor_async(messages, previous=previous))
[2m[WebServer] [22m           ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/runners.py", line 194, in run
[2m[WebServer] [22m    return runner.run(main)
[2m[WebServer] [22m           ~~~~~~~~~~^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/runners.py", line 118, in run
[2m[WebServer] [22m    return self._loop.run_until_complete(task)
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/base_events.py", line 720, in run_until_complete
[2m[WebServer] [22m    return future.result()
[2m[WebServer] [22m           ~~~~~~~~~~~~~^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 208, in _agent_executor_async
[2m[WebServer] [22m    llm_response = await _call_model_async(current_messages)
[2m[WebServer] [22m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 134, in _call_model_async
[2m[WebServer] [22m    return await asyncio.to_thread(_call_model_sync, messages)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/threads.py", line 25, in to_thread
[2m[WebServer] [22m    return await loop.run_in_executor(None, func_call)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/thread.py", line 59, in run
[2m[WebServer] [22m    result = self.fn(*self.args, **self.kwargs)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 127, in _call_model_sync
[2m[WebServer] [22m    return llm_with_tools.invoke(messages)
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/runnables/base.py", line 5416, in invoke
[2m[WebServer] [22m    return self.bound.invoke(
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        input,
[2m[WebServer] [22m        ^^^^^^
[2m[WebServer] [22m        self._merge_configs(config),
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m        **{**self.kwargs, **kwargs},
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 369, in invoke
[2m[WebServer] [22m    self.generate_prompt(
[2m[WebServer] [22m    ~~~~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        [self._convert_input(input)],
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<6 lines>...
[2m[WebServer] [22m        **kwargs,
[2m[WebServer] [22m        ^^^^^^^^^
[2m[WebServer] [22m    ).generations[0][0],
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 946, in generate_prompt
[2m[WebServer] [22m    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
[2m[WebServer] [22m           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 765, in generate
[2m[WebServer] [22m    self._generate_with_cache(
[2m[WebServer] [22m    ~~~~~~~~~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        m,
[2m[WebServer] [22m        ^^
[2m[WebServer] [22m    ...<2 lines>...
[2m[WebServer] [22m        **kwargs,
[2m[WebServer] [22m        ^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 1011, in _generate_with_cache
[2m[WebServer] [22m    result = self._generate(
[2m[WebServer] [22m        messages, stop=stop, run_manager=run_manager, **kwargs
[2m[WebServer] [22m    )
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py", line 991, in _generate
[2m[WebServer] [22m    response = self.client.create(**payload)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_utils/_utils.py", line 287, in wrapper
[2m[WebServer] [22m    return func(*args, **kwargs)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py", line 925, in create
[2m[WebServer] [22m    return self._post(
[2m[WebServer] [22m           ~~~~~~~~~~^
[2m[WebServer] [22m        "/chat/completions",
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<43 lines>...
[2m[WebServer] [22m        stream_cls=Stream[ChatCompletionChunk],
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_base_client.py", line 1239, in post
[2m[WebServer] [22m    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
[2m[WebServer] [22m                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_base_client.py", line 1034, in request
[2m[WebServer] [22m    raise self._make_status_error_from_response(err.response) from None
[2m[WebServer] [22mopenai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `gpt-mock` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
[2m[WebServer] [22mDuring task with name 'agent_executor' and id '40f0318f-84e6-156c-6968-498b27db9d91'
[2m[WebServer] [22mDuring task with name 'agent-1' and id '9bc59543-1ea7-06b5-7da1-dadb5a80beab'

[1A[2K[2m[WebServer] [22mERROR - Unhandled exception: Error code: 404 - {'error': {'message': 'The model `gpt-mock` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
[2m[WebServer] [22mTraceback (most recent call last):
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/middleware/errors.py", line 165, in __call__
[2m[WebServer] [22m    await self.app(scope, receive, _send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/middleware/worker_db.py", line 101, in __call__
[2m[WebServer] [22m    await self.app(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/middleware/cors.py", line 85, in __call__
[2m[WebServer] [22m    await self.app(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/middleware/exceptions.py", line 62, in __call__
[2m[WebServer] [22m    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
[2m[WebServer] [22m    raise exc
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
[2m[WebServer] [22m    await app(scope, receive, sender)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/routing.py", line 714, in __call__
[2m[WebServer] [22m    await self.middleware_stack(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/routing.py", line 734, in app
[2m[WebServer] [22m    await route.handle(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/routing.py", line 288, in handle
[2m[WebServer] [22m    await self.app(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/routing.py", line 76, in app
[2m[WebServer] [22m    await wrap_app_handling_exceptions(app, request)(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
[2m[WebServer] [22m    raise exc
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
[2m[WebServer] [22m    await app(scope, receive, sender)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/routing.py", line 73, in app
[2m[WebServer] [22m    response = await f(request)
[2m[WebServer] [22m               ^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/fastapi/routing.py", line 301, in app
[2m[WebServer] [22m    raw_response = await run_endpoint_function(
[2m[WebServer] [22m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<3 lines>...
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/fastapi/routing.py", line 212, in run_endpoint_function
[2m[WebServer] [22m    return await dependant.call(**values)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/routers/workflow_executions.py", line 74, in start_workflow_execution
[2m[WebServer] [22m    execution_id = await langgraph_workflow_engine.execute_workflow(workflow_id)
[2m[WebServer] [22m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/services/langgraph_workflow_engine.py", line 146, in execute_workflow
[2m[WebServer] [22m    await self._execute_workflow_internal(workflow, execution, db)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/services/langgraph_workflow_engine.py", line 214, in _execute_workflow_internal
[2m[WebServer] [22m    async for chunk in graph.astream(initial_state, config):
[2m[WebServer] [22m    ...<36 lines>...
[2m[WebServer] [22m            logger.warning(f"[LangGraphEngine] Received empty chunk #{chunk_count}")
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2732, in astream
[2m[WebServer] [22m    async for _ in runner.atick(
[2m[WebServer] [22m    ...<7 lines>...
[2m[WebServer] [22m            yield o
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/services/langgraph_workflow_engine.py", line 729, in agent_node
[2m[WebServer] [22m    created_messages = await runner.run_thread(db, thread)
[2m[WebServer] [22m                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/managers/agent_runner.py", line 137, in run_thread
[2m[WebServer] [22m    updated_messages = await self._runnable.ainvoke(original_msgs, config)
[2m[WebServer] [22m                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2850, in ainvoke
[2m[WebServer] [22m    async for chunk in self.astream(
[2m[WebServer] [22m    ...<13 lines>...
[2m[WebServer] [22m            chunks.append(chunk)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2732, in astream
[2m[WebServer] [22m    async for _ in runner.atick(
[2m[WebServer] [22m    ...<7 lines>...
[2m[WebServer] [22m            yield o
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 256, in agent_executor
[2m[WebServer] [22m    return _agent_executor_sync(messages, previous=previous)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 248, in _agent_executor_sync
[2m[WebServer] [22m    return asyncio.run(_agent_executor_async(messages, previous=previous))
[2m[WebServer] [22m           ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/runners.py", line 194, in run
[2m[WebServer] [22m    return runner.run(main)
[2m[WebServer] [22m           ~~~~~~~~~~^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/runners.py", line 118, in run
[2m[WebServer] [22m    return self._loop.run_until_complete(task)
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/base_events.py", line 720, in run_until_complete
[2m[WebServer] [22m    return future.result()
[2m[WebServer] [22m           ~~~~~~~~~~~~~^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 208, in _agent_executor_async
[2m[WebServer] [22m    llm_response = await _call_model_async(current_messages)
[2m[WebServer] [22m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 134, in _call_model_async
[2m[WebServer] [22m    return await asyncio.to_thread(_call_model_sync, messages)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/threads.py", line 25, in to_thread
[2m[WebServer] [22m    return await loop.run_in_executor(None, func_call)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/thread.py", line 59, in run
[2m[WebServer] [22m    result = self.fn(*self.args, **self.kwargs)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 127, in _call_model_sync
[2m[WebServer] [22m    return llm_with_tools.invoke(messages)
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/runnables/base.py", line 5416, in invoke
[2m[WebServer] [22m    return self.bound.invoke(
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        input,
[2m[WebServer] [22m        ^^^^^^
[2m[WebServer] [22m        self._merge_configs(config),
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m        **{**self.kwargs, **kwargs},
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 369, in invoke
[2m[WebServer] [22m    self.generate_prompt(
[2m[WebServer] [22m    ~~~~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        [self._convert_input(input)],
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<6 lines>...
[2m[WebServer] [22m        **kwargs,
[2m[WebServer] [22m        ^^^^^^^^^
[2m[WebServer] [22m    ).generations[0][0],
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 946, in generate_prompt
[2m[WebServer] [22m    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
[2m[WebServer] [22m           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 765, 

[1A[2K[2m[WebServer] [22min generate
[2m[WebServer] [22m    self._generate_with_cache(
[2m[WebServer] [22m    ~~~~~~~~~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        m,
[2m[WebServer] [22m        ^^
[2m[WebServer] [22m    ...<2 lines>...
[2m[WebServer] [22m        **kwargs,
[2m[WebServer] [22m        ^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 1011, in _generate_with_cache
[2m[WebServer] [22m    result = self._generate(
[2m[WebServer] [22m        messages, stop=stop, run_manager=run_manager, **kwargs
[2m[WebServer] [22m    )
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py", line 991, in _generate
[2m[WebServer] [22m    response = self.client.create(**payload)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_utils/_utils.py", line 287, in wrapper
[2m[WebServer] [22m    return func(*args, **kwargs)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py", line 925, in create
[2m[WebServer] [22m    return self._post(
[2m[WebServer] [22m           ~~~~~~~~~~^
[2m[WebServer] [22m        "/chat/completions",
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<43 lines>...
[2m[WebServer] [22m        stream_cls=Stream[ChatCompletionChunk],
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_base_client.py", line 1239, in post
[2m[WebServer] [22m    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
[2m[WebServer] [22m                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_base_client.py", line 1034, in request
[2m[WebServer] [22m    raise self._make_status_error_from_response(err.response) from None
[2m[WebServer] [22mopenai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `gpt-mock` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
[2m[WebServer] [22mDuring task with name 'agent_executor' and id '40f0318f-84e6-156c-6968-498b27db9d91'
[2m[WebServer] [22mDuring task with name 'agent-1' and id '9bc59543-1ea7-06b5-7da1-dadb5a80beab'

[1A[2K❌ Workflow execution failed: [33m500[39m

[1A[2K📊 Step 5: Testing direct HTTP tool usage...

[1A[2K[2m[WebServer] [22mERROR:    Exception in ASGI application
[2m[WebServer] [22mTraceback (most recent call last):
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/uvicorn/protocols/http/h11_impl.py", line 408, in run_asgi
[2m[WebServer] [22m    result = await app(  # type: ignore[func-returns-value]
[2m[WebServer] [22m             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m        self.scope, self.receive, self.send
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/uvicorn/middleware/proxy_headers.py", line 84, in __call__
[2m[WebServer] [22m    return await self.app(scope, receive, send)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/fastapi/applications.py", line 1054, in __call__
[2m[WebServer] [22m    await super().__call__(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/applications.py", line 112, in __call__
[2m[WebServer] [22m    await self.middleware_stack(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/middleware/errors.py", line 187, in __call__
[2m[WebServer] [22m    raise exc
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/middleware/errors.py", line 165, in __call__
[2m[WebServer] [22m    await self.app(scope, receive, _send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/middleware/worker_db.py", line 101, in __call__
[2m[WebServer] [22m    await self.app(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/middleware/cors.py", line 85, in __call__
[2m[WebServer] [22m    await self.app(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/middleware/exceptions.py", line 62, in __call__
[2m[WebServer] [22m    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
[2m[WebServer] [22m    raise exc
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
[2m[WebServer] [22m    await app(scope, receive, sender)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/routing.py", line 714, in __call__
[2m[WebServer] [22m    await self.middleware_stack(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/routing.py", line 734, in app
[2m[WebServer] [22m    await route.handle(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/routing.py", line 288, in handle
[2m[WebServer] [22m    await self.app(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/routing.py", line 76, in app
[2m[WebServer] [22m    await wrap_app_handling_exceptions(app, request)(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
[2m[WebServer] [22m    raise exc
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
[2m[WebServer] [22m    await app(scope, receive, sender)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/routing.py", line 73, in app
[2m[WebServer] [22m    response = await f(request)
[2m[WebServer] [22m               ^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/fastapi/routing.py", line 301, in app
[2m[WebServer] [22m    raw_response = await run_endpoint_function(
[2m[WebServer] [22m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<3 lines>...
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/fastapi/routing.py", line 212, in run_endpoint_function
[2m[WebServer] [22m    return await dependant.call(**values)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/routers/workflow_executions.py", line 74, in start_workflow_execution
[2m[WebServer] [22m    execution_id = await langgraph_workflow_engine.execute_workflow(workflow_id)
[2m[WebServer] [22m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/services/langgraph_workflow_engine.py", line 146, in execute_workflow
[2m[WebServer] [22m    await self._execute_workflow_internal(workflow, execution, db)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/services/langgraph_workflow_engine.py", line 214, in _execute_workflow_internal
[2m[WebServer] [22m    async for chunk in graph.astream(initial_state, config):
[2m[WebServer] [22m    ...<36 lines>...
[2m[WebServer] [22m            logger.warning(f"[LangGraphEngine] Received empty chunk #{chunk_count}")
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2732, in astream
[2m[WebServer] [22m    async for _ in runner.atick(
[2m[WebServer] [22m    ...<7 lines>...
[2m[WebServer] [22m            yield o
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/services/langgraph_workflow_engine.py", line 729, in agent_node
[2m[WebServer] [22m    created_messages = await runner.run_thread(db, thread)
[2m[WebServer] [22m                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/managers/agent_runner.py", line 137, in run_thread
[2m[WebServer] [22m    updated_messages = await self._runnable.ainvoke(original_msgs, config)
[2m[WebServer] [22m                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2850, in ainvoke
[2m[WebServer] [22m    async for chunk in self.astream(
[2m[WebServer] [22m    ...<13 lines>...
[2m[WebServer] [22m            chunks.append(chunk)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2732, in astream
[2m[WebServer] [22m    async for _ in runner.atick(
[2m[WebServer] [22m    ...<7 lines>...
[2m[WebServer] [22m            yield o
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 256, in agent_executor
[2m[WebServer] [22m    return _agent_executor_sync(messages, previous=previous)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 248, in _agent_executor_sync
[2m[WebServer] [22m    return asyncio.run(_agent_executor_async(messages, previous=previous))
[2m[WebServer] [22m           ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/runners.py", line 194, in run
[2m[WebServer] [22m    return runner.run(main)
[2m[WebServer] [22m           ~~~~~~~~~~^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/runners.py", line 118, in run
[2m[WebServer] [22m    return self._loop.run_until_complete(task)
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/base_events.py", line 720, in run_until_complete
[2m[WebServer] [22m    return future.result()
[2m[WebServer] [22m           ~~~~~~~~~~~~~^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 208, in _agent_executor_async
[2m[WebServer] [22m    llm_response = await _call_model_async(current_messages)
[2m[WebServer] [22m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 134, in _call_model_async
[2m[WebServer] [22m    return await asyncio.to_thread(_call_model_sync, messages)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/threads.py", line 25, in to_thread
[2m[WebServer] [22m    return await loop.run_in_executor(None, func_call)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/thread.py", line 59, in run
[2m[WebServer] [22m    result = self.fn(*self.args, **self.kwargs)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 127, in _call_model_sync
[2m[WebServer] [22m    return llm_with_tools.invoke(messages)
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/runnables/base.py", line 5416, in invoke
[2m[WebServer] [22m    return self.bound.invoke(
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        input,
[2m[WebServer] [22m        ^^^^^^
[2m[WebServer] [22m        self._merge_configs(config),
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^

[1A[2K[2m[WebServer] [22m^^^^^^^^^
[2m[WebServer] [22m        **{**self.kwargs, **kwargs},
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 369, in invoke
[2m[WebServer] [22m    self.generate_prompt(
[2m[WebServer] [22m    ~~~~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        [self._convert_input(input)],
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<6 lines>...
[2m[WebServer] [22m        **kwargs,
[2m[WebServer] [22m        ^^^^^^^^^
[2m[WebServer] [22m    ).generations[0][0],
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 946, in generate_prompt
[2m[WebServer] [22m    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
[2m[WebServer] [22m           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 765, in generate
[2m[WebServer] [22m    self._generate_with_cache(
[2m[WebServer] [22m    ~~~~~~~~~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        m,
[2m[WebServer] [22m        ^^
[2m[WebServer] [22m    ...<2 lines>...
[2m[WebServer] [22m        **kwargs,
[2m[WebServer] [22m        ^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 1011, in _generate_with_cache
[2m[WebServer] [22m    result = self._generate(
[2m[WebServer] [22m        messages, stop=stop, run_manager=run_manager, **kwargs
[2m[WebServer] [22m    )
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py", line 991, in _generate
[2m[WebServer] [22m    response = self.client.create(**payload)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_utils/_utils.py", line 287, in wrapper
[2m[WebServer] [22m    return func(*args, **kwargs)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py", line 925, in create
[2m[WebServer] [22m    return self._post(
[2m[WebServer] [22m           ~~~~~~~~~~^
[2m[WebServer] [22m        "/chat/completions",
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<43 lines>...
[2m[WebServer] [22m        stream_cls=Stream[ChatCompletionChunk],
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_base_client.py", line 1239, in post
[2m[WebServer] [22m    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
[2m[WebServer] [22m                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_base_client.py", line 1034, in request
[2m[WebServer] [22m    raise self._make_status_error_from_response(err.response) from None
[2m[WebServer] [22mopenai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `gpt-mock` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
[2m[WebServer] [22mDuring task with name 'agent_executor' and id '40f0318f-84e6-156c-6968-498b27db9d91'
[2m[WebServer] [22mDuring task with name 'agent-1' and id '9bc59543-1ea7-06b5-7da1-dadb5a80beab'

[1A[2K📊 Tools endpoint not available or error: apiRequestContext.get: read ECONNRESET
Call log:
[2m  - → GET http://localhost:8001/api/tools[22m
[2m    - user-agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/136.0.7103.25 Safari/537.36[22m
[2m    - accept: */*[22m
[2m    - accept-encoding: gzip,deflate,br[22m
[2m    - X-Test-Worker: 2[22m


[1A[2K📊 Step 6: Checking UI for workflow execution...

[1A[2Ktests/tool_palette_node_connections.spec.ts:180:7 › Tool Palette and Node Connections › Node connection handle detection and interaction
📊 Test 1: Detecting canvas nodes...

[1A[2K📊 Existing nodes on canvas: [33m0[39m

[1A[2K📊 No existing nodes - attempting to create nodes for connection test...

[1A[2K📊 Test 2: Detecting connection handles...

[1A[2K📊 Connection handles found: [33m0[39m

[1A[2K⚠️  No connection handles detected - may need UI implementation

[1A[2K✅ Node connection test completed

[1A[2Ktests/workflow_execution_http.spec.ts:15:7 › Workflow Execution with HTTP Tools › Execute workflow with HTTP tool and verify requests
📊 Execute buttons found: [33m0[39m

[1A[2K📊 Run buttons found: [33m0[39m

[1A[2K📊 Workflow elements found: [33m0[39m

[1A[2K✅ Workflow execution test completed

[1A[2K📊 Summary: Workflow execution infrastructure validated

[1A[2K  1 failed
    tests/data_persistence_recovery.spec.ts:19:7 › Data Persistence and Recovery › Data persistence across sessions 
  35 passed (1.0m)

[36m  Serving HTML report at http://localhost:9323. Press Ctrl+C to quit.[39m
