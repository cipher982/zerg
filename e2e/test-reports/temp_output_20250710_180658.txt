[1A[2K[2m[WebServer] [22m[build-only] ğŸ”§ building frontend (debug)â€¦

[1A[2K[2m[WebServer] [22m[build-only] ğŸ—  wasm-pack build â€¦

[1A[2K[2m[WebServer] [22m[INFO]: ğŸ¯  Checking for the Wasm target...

[1A[2K[2m[WebServer] [22m[INFO]: ğŸŒ€  Compiling to Wasm...

[1A[2K[2m[WebServer] [22mwarning: unused import: `ws_manager::init_chat_view_ws`
[2m[WebServer] [22m --> src/components/chat/mod.rs:2:9
[2m[WebServer] [22m  |
[2m[WebServer] [22m2 | pub use ws_manager::init_chat_view_ws;
[2m[WebServer] [22m  |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  

[1A[2K[2m[WebServer] [22m|
[2m[WebServer] [22m  = note: `#[warn(unused_imports)]` on by default
[2m[WebServer] [22m
[2m[WebServer] [22mwarning: unused import: `super::*`
[2m[WebServer] [22m  --> src/generated/tool_definitions.rs:83:9
[2m[WebServer] [22m   |
[2m[WebServer] [22m83 |     use super::*;
[2m[WebServer] [22m   |         ^^^^^^^^
[2m[WebServer] [22m

[1A[2K[2m[WebServer] [22mwarning: `agent-platform-frontend` (lib) generated 2 warnings (run `cargo fix --lib -p agent-platform-frontend` to apply 2 suggestions)
[2m[WebServer] [22m    Finished `dev` profile [unoptimized + debuginfo] target(s) in 0.03s

[1A[2K[2m[WebServer] [22m[INFO]: â¬‡ï¸  Installing wasm-bindgen...

[1A[2K[2m[WebServer] [22m[INFO]: Optional fields missing from Cargo.toml: 'description', 'repository', and 'license'. These are not necessary, but recommended

[1A[2K[2m[WebServer] [22m[INFO]: âœ¨   Done in 0.48s
[2m[WebServer] [22m[INFO]: ğŸ“¦   Your wasm pkg is ready to publish at /Users/davidrose/git/zerg/frontend/pkg.

[1A[2K[2m[WebServer] [22m[build-only] ğŸ“¦ copying WASM artifacts to www...

[1A[2K[2m[WebServer] [22m[build-only] âœï¸  writing bootstrap.js â€¦

[1A[2K[2m[WebServer] [22m[build-only] âœï¸  writing config.js â€¦

[1A[2K[2m[WebServer] [22m[build-only] âœ… build complete (output in frontend/www/)


Running 36 tests using 2 workers

[1A[2K[1/36] tests/accessibility_ui_ux.spec.ts:113:7 â€º Accessibility and UI/UX â€º Keyboard navigation functionality
[1A[2K[2/36] tests/accessibility_ui_ux.spec.ts:18:7 â€º Accessibility and UI/UX â€º WCAG compliance and semantic markup
[1A[2Ktests/accessibility_ui_ux.spec.ts:18:7 â€º Accessibility and UI/UX â€º WCAG compliance and semantic markup
ğŸš€ Starting WCAG compliance test...

[1A[2Ktests/accessibility_ui_ux.spec.ts:113:7 â€º Accessibility and UI/UX â€º Keyboard navigation functionality
ğŸš€ Starting keyboard navigation test...

[1A[2Ktests/accessibility_ui_ux.spec.ts:18:7 â€º Accessibility and UI/UX â€º WCAG compliance and semantic markup
ğŸ“Š Worker ID: 0

[1A[2Ktests/accessibility_ui_ux.spec.ts:113:7 â€º Accessibility and UI/UX â€º Keyboard navigation functionality
ğŸ“Š Test 1: Testing tab order...

[1A[2KğŸ“Š Tab 1: BUTTON [create-agent-btn]

[1A[2KğŸ“Š Tab 2: BUTTON [reset-db-btn]

[1A[2KğŸ“Š Tab 3: BUTTON

[1A[2KğŸ“Š Tab 4: BUTTON [global-dashboard-tab]

[1A[2KğŸ“Š Tab 5: BUTTON [global-canvas-tab]

[1A[2KğŸ“Š Tab 6: BODY

[1A[2KğŸ“Š Tab 7: BUTTON [create-agent-btn]

[1A[2Ktests/accessibility_ui_ux.spec.ts:18:7 â€º Accessibility and UI/UX â€º WCAG compliance and semantic markup
ğŸ“Š Test 1: Checking semantic structure...

[1A[2Ktests/accessibility_ui_ux.spec.ts:113:7 â€º Accessibility and UI/UX â€º Keyboard navigation functionality
ğŸ“Š Tab 8: BUTTON [reset-db-btn]

[1A[2Ktests/accessibility_ui_ux.spec.ts:18:7 â€º Accessibility and UI/UX â€º WCAG compliance and semantic markup
ğŸ“Š Semantic elements found: {
  header: [33m0[39m,
  nav: [33m0[39m,
  main: [33m0[39m,
  section: [33m0[39m,
  article: [33m0[39m,
  aside: [33m0[39m,
  footer: [33m0[39m
}

[1A[2Kâš ï¸  Consider adding semantic HTML elements

[1A[2KğŸ“Š Test 2: Checking heading hierarchy...

[1A[2KğŸ“Š Heading structure: { h1: [33m1[39m, h2: [33m1[39m, h3: [33m0[39m, h4: [33m0[39m, h5: [33m0[39m, h6: [33m0[39m }

[1A[2Kâœ… Page has primary heading (h1)

[1A[2KğŸ“Š Test 3: Checking ARIA attributes...

[1A[2KğŸ“Š ARIA attributes found: {
  [32m'aria-label'[39m: [33m1[39m,
  [32m'aria-labelledby'[39m: [33m0[39m,
  [32m'aria-describedby'[39m: [33m0[39m,
  [32m'aria-hidden'[39m: [33m1[39m,
  role: [33m1[39m,
  [32m'aria-expanded'[39m: [33m0[39m
}

[1A[2Kâœ… ARIA attributes are being used

[1A[2KğŸ“Š Test 4: Checking form accessibility...

[1A[2KğŸ“Š Form elements found: [33m11[39m

[1A[2KğŸ“Š Labeled form elements: [33m2[39m

[1A[2Kâœ… Form elements have labels

[1A[2Kâœ… WCAG compliance test completed

[1A[2K[3/36] tests/accessibility_ui_ux.spec.ts:196:7 â€º Accessibility and UI/UX â€º Screen reader compatibility
[1A[2Ktests/accessibility_ui_ux.spec.ts:196:7 â€º Accessibility and UI/UX â€º Screen reader compatibility
ğŸš€ Starting screen reader compatibility test...

[1A[2Ktests/accessibility_ui_ux.spec.ts:113:7 â€º Accessibility and UI/UX â€º Keyboard navigation functionality
ğŸ“Š Tab 9: BUTTON

[1A[2KğŸ“Š Tab 10: BUTTON [global-dashboard-tab]

[1A[2KğŸ“Š Unique focusable elements: [33m6[39m

[1A[2Kâœ… Multiple elements are keyboard accessible

[1A[2KğŸ“Š Test 2: Testing escape key functionality...

[1A[2Kâœ… Escape key press handled

[1A[2KğŸ“Š Test 3: Testing enter key activation...

[1A[2Kâœ… Enter key activation tested

[1A[2KğŸ“Š Test 4: Testing arrow key navigation...

[1A[2Kâœ… Keyboard navigation test completed

[1A[2K[4/36] tests/accessibility_ui_ux.spec.ts:274:7 â€º Accessibility and UI/UX â€º Color contrast and visual accessibility
[1A[2Ktests/accessibility_ui_ux.spec.ts:274:7 â€º Accessibility and UI/UX â€º Color contrast and visual accessibility
ğŸš€ Starting color contrast test...

[1A[2Ktests/accessibility_ui_ux.spec.ts:196:7 â€º Accessibility and UI/UX â€º Screen reader compatibility
ğŸ“Š Test 1: Checking page title and structure...

[1A[2KğŸ“Š Page title: AI Agent Platform

[1A[2Kâœ… Page has a descriptive title

[1A[2KğŸ“Š Test 2: Checking image alt text...

[1A[2KğŸ“Š Total images: [33m0[39m

[1A[2KğŸ“Š Images with alt text: [33m0[39m

[1A[2KğŸ“Š Decorative images (empty alt): [33m0[39m

[1A[2KğŸ“Š No images found on page

[1A[2KğŸ“Š Test 3: Checking link accessibility...

[1A[2KğŸ“Š Total links: [33m0[39m

[1A[2KğŸ“Š Test 4: Checking live regions...

[1A[2KğŸ“Š Live regions found: [33m0[39m

[1A[2KğŸ“Š Status/alert elements: [33m0[39m

[1A[2KğŸ“Š No live regions found (may not be needed)

[1A[2Kâœ… Screen reader compatibility test completed

[1A[2K[5/36] tests/accessibility_ui_ux.spec.ts:372:7 â€º Accessibility and UI/UX â€º Responsive design and mobile compatibility
[1A[2Ktests/accessibility_ui_ux.spec.ts:372:7 â€º Accessibility and UI/UX â€º Responsive design and mobile compatibility
ğŸš€ Starting responsive design test...

[1A[2KğŸ“Š Test 1: Testing mobile viewport...

[1A[2Ktests/accessibility_ui_ux.spec.ts:274:7 â€º Accessibility and UI/UX â€º Color contrast and visual accessibility
ğŸ“Š Test 1: Analyzing color usage...

[1A[2KğŸ“Š Color-based indicators: [33m1[39m

[1A[2KğŸ“Š Icon-based indicators: [33m0[39m

[1A[2Kâš ï¸  Consider adding icons or text to supplement color information

[1A[2KğŸ“Š Test 2: Checking focus indicators...

[1A[2KğŸ“Š Focus styles: {
  outline: [32m'rgb(0, 95, 204) auto 1px'[39m,
  outlineColor: [32m'rgb(0, 95, 204)'[39m,
  outlineWidth: [32m'1px'[39m,
  boxShadow: [32m'none'[39m,
  border: [32m'0px none rgb(10, 10, 15)'[39m
}

[1A[2Kâœ… Focus indicators are visible

[1A[2KğŸ“Š Test 3: Testing text scalability...

[1A[2KğŸ“Š Original text sizes: [
  { fontSize: [32m'14px'[39m, lineHeight: [32m'normal'[39m },
  { fontSize: [32m'14px'[39m, lineHeight: [32m'normal'[39m },
  { fontSize: [32m'14px'[39m, lineHeight: [32m'normal'[39m }
]

[1A[2KğŸ“Š Scaled text sizes: [
  { fontSize: [32m'19.2px'[39m, lineHeight: [32m'normal'[39m },
  { fontSize: [32m'19.2px'[39m, lineHeight: [32m'normal'[39m },
  { fontSize: [32m'19.2px'[39m, lineHeight: [32m'normal'[39m }
]

[1A[2Kâœ… Text scalability tested

[1A[2Kâœ… Color contrast test completed

[1A[2K[6/36] tests/accessibility_ui_ux.spec.ts:467:7 â€º Accessibility and UI/UX â€º User workflow usability testing
[1A[2Ktests/accessibility_ui_ux.spec.ts:467:7 â€º Accessibility and UI/UX â€º User workflow usability testing
ğŸš€ Starting user workflow usability test...

[1A[2KğŸ“Š Test 1: Testing agent creation workflow...

[1A[2Ktests/accessibility_ui_ux.spec.ts:372:7 â€º Accessibility and UI/UX â€º Responsive design and mobile compatibility
ğŸ“Š Mobile layout: {
  bodyWidth: [33m375[39m,
  hasHorizontalScroll: [33mtrue[39m,
  navigationVisible: [33mfalse[39m,
  mainContentVisible: [33mfalse[39m
}

[1A[2Kâš ï¸  Page has horizontal scroll on mobile

[1A[2KğŸ“Š Test 2: Testing tablet viewport...

[1A[2KğŸ“Š Tablet layout: { bodyWidth: [33m768[39m, hasHorizontalScroll: [33mfalse[39m }

[1A[2KğŸ“Š Test 3: Testing desktop viewport...

[1A[2KğŸ“Š Desktop layout: { bodyWidth: [33m1920[39m, hasHorizontalScroll: [33mfalse[39m }

[1A[2KğŸ“Š Test 4: Testing touch interactions...

[1A[2KğŸ“Š Touchable elements: [33m18[39m

[1A[2KğŸ“Š Touch target sizes: [
  { width: [33m114.46875[39m, height: [33m23[39m, area: [33m2632.78125[39m },
  { width: [33m109.75[39m, height: [33m30[39m, area: [33m3292.5[39m },
  { width: [33m27.734375[39m, height: [33m22[39m, area: [33m610.15625[39m },
  { width: [33m148.96875[39m, height: [33m43[39m, area: [33m6405.65625[39m },
  { width: [33m127.9375[39m, height: [33m43[39m, area: [33m5501.3125[39m }
]

[1A[2KğŸ“Š Adequate touch targets (44x44px+): [33m0[39m

[1A[2Kâœ… Responsive design test completed

[1A[2K[7/36] tests/agent_creation_full.spec.ts:15:7 â€º Agent Creation Full Workflow â€º Complete agent creation and isolation test
[1A[2Ktests/agent_creation_full.spec.ts:15:7 â€º Agent Creation Full Workflow â€º Complete agent creation and isolation test
ğŸ” Starting complete agent creation test...

[1A[2KğŸ“Š Worker ID: 0

[1A[2KğŸ“Š Step 0: Resetting database...

[1A[2K[2m[WebServer] [22mWARNING - Resetting database - dropping all tables

[1A[2Kâœ… Database reset successful

[1A[2KğŸ“Š Step 1: Verifying empty state...

[1A[2KğŸ“Š Initial agent count: [33m0[39m

[1A[2KğŸ“Š Step 2: Creating agent via API...

[1A[2KğŸ“Š Agent creation status: [33m201[39m

[1A[2KğŸ“Š Created agent ID: [33m1[39m

[1A[2KğŸ“Š Created agent name: Test Agent Worker 0

[1A[2KğŸ“Š Step 3: Verifying agent appears in list...

[1A[2KğŸ“Š Updated agent count: [33m1[39m

[1A[2Kâœ… Agent found in list with correct data

[1A[2KğŸ“Š Step 5: Testing UI integration...

[1A[2Ktests/accessibility_ui_ux.spec.ts:467:7 â€º Accessibility and UI/UX â€º User workflow usability testing
ğŸ“Š Create buttons found: [33m2[39m

[1A[2KğŸ“Š Test agent created: [33m2[39m

[1A[2KğŸ“Š Agent visible in dashboard: [33mfalse[39m

[1A[2KğŸ“Š Canvas workflow elements: { canvas: [33m0[39m, agentShelf: [33m0[39m, toolPalette: [33m0[39m }

[1A[2KğŸ“Š User workflow steps completed: [33m3[39m

[1A[2KğŸ“Š Total workflow time: [33m1616[39m ms

[1A[2KğŸ“Š Average step time: [33m539[39m ms

[1A[2Kâœ… User workflow is responsive

[1A[2KğŸ“Š Test 2: Testing error recovery...

[1A[2Ktests/agent_creation_full.spec.ts:15:7 â€º Agent Creation Full Workflow â€º Complete agent creation and isolation test
ğŸ“Š Agent visible in UI: [33mtrue[39m

[1A[2Kâœ… Agent successfully appears in UI

[1A[2KğŸ“Š Step 6: Creating second agent for isolation test...

[1A[2KğŸ“Š Second agent created with ID: [33m3[39m

[1A[2KğŸ“Š Step 7: Verifying agent isolation...

[1A[2KğŸ“Š Final agent count: [33m3[39m

[1A[2KğŸ“Š Worker-specific agent count: [33m2[39m

[1A[2Kâœ… Complete agent creation and isolation test passed!

[1A[2K[8/36] tests/canvas_complete_workflow.spec.ts:17:7 â€º Complete Canvas Workflow â€º End-to-end canvas workflow with agent and tool execution
[1A[2Ktests/canvas_complete_workflow.spec.ts:17:7 â€º Complete Canvas Workflow â€º End-to-end canvas workflow with agent and tool execution
ğŸš€ Starting complete canvas workflow test...

[1A[2KğŸ“Š Worker ID: 0

[1A[2KğŸ“Š Step 1: Creating test agent...

[1A[2Kâœ… Test agent created with ID: [33m4[39m

[1A[2KğŸ“Š Step 2: Navigating to application...

[1A[2Ktests/accessibility_ui_ux.spec.ts:467:7 â€º Accessibility and UI/UX â€º User workflow usability testing
ğŸ“Š Recovery elements found: [33m0[39m

[1A[2Kâœ… User workflow usability test completed

[1A[2K[9/36] tests/comprehensive_debug.spec.ts:15:7 â€º Comprehensive Debug â€º Complete system debug and diagnosis
[1A[2Ktests/comprehensive_debug.spec.ts:15:7 â€º Comprehensive Debug â€º Complete system debug and diagnosis
ğŸ” Starting comprehensive debug test...

[1A[2KğŸ“Š Worker ID: 1

[1A[2KğŸ“Š NODE_ENV: test

[1A[2KğŸ” Test 1: Basic connectivity

[1A[2KğŸ“Š Basic connectivity status: [33m200[39m

[1A[2Kâœ… Backend is accessible

[1A[2KğŸ” Test 2: Header transmission

[1A[2KğŸ“Š Header transmission status: [33m200[39m

[1A[2Kâœ… Headers can be sent

[1A[2KğŸ” Test 3: Agent GET endpoint

[1A[2KğŸ“Š Agent GET status: [33m200[39m

[1A[2KğŸ“Š Agent GET count: [33m1[39m

[1A[2Kâœ… Agent GET endpoint working

[1A[2KğŸ” Test 4: Testing different database operations

[1A[2KğŸ“Š Testing user endpoint...

[1A[2KğŸ“Š User endpoint status: [33m200[39m

[1A[2KğŸ“Š User data available: [33mtrue[39m

[1A[2KğŸ” Test 5: Workflow creation test

[1A[2KğŸ“Š Workflow creation status: [33m422[39m

[1A[2KâŒ Workflow creation failed: {"detail":[{"type":"missing","loc":["body","canvas_data"],"msg":"Field required","input":{"name":"Test Workflow 1","description":"Test workflow for debugging"}}]}

[1A[2KğŸ” Test 6: Minimal agent creation

[1A[2KğŸ“Š Minimal agent creation status: [33m201[39m

[1A[2KğŸ“Š Minimal agent created ID: [33m2[39m

[1A[2Kâœ… Agent creation working with mock model

[1A[2KğŸ” Test 7: Database introspection

[1A[2KğŸ“Š System health status: [33m404[39m

[1A[2Kâœ… Comprehensive debug test complete

[1A[2K[10/36] tests/data_persistence_recovery.spec.ts:19:7 â€º Data Persistence and Recovery â€º Data persistence across sessions
[1A[2Ktests/data_persistence_recovery.spec.ts:19:7 â€º Data Persistence and Recovery â€º Data persistence across sessions
ğŸš€ Starting data persistence test...

[1A[2KğŸ“Š Worker ID: 0

[1A[2KğŸ“Š Step 0: Resetting database...

[1A[2K[2m[WebServer] [22mWARNING - Resetting database - dropping all tables

[1A[2Kâœ… Database reset successful

[1A[2KğŸ“Š Test 1: Creating persistent data...

[1A[2KğŸ“Š Created agent ID: [33m5[39m

[1A[2Ktests/canvas_complete_workflow.spec.ts:17:7 â€º Complete Canvas Workflow â€º End-to-end canvas workflow with agent and tool execution
ğŸ“Š Step 3: Verifying agent in dashboard...

[1A[2KğŸ“Š Agent visible in dashboard: [33mtrue[39m

[1A[2KğŸ“Š Step 4: Navigating to canvas...

[1A[2KğŸ“Š Canvas visible: [33mfalse[39m

[1A[2Kâœ… Complete canvas workflow test finished

[1A[2KğŸ“Š Summary: Basic navigation and UI structure validated

[1A[2KğŸ“Š Next: UI implementation needed for full drag-and-drop workflow

[1A[2K[11/36] tests/data_persistence_recovery.spec.ts:127:7 â€º Data Persistence and Recovery â€º Auto-save and draft recovery
[1A[2Ktests/data_persistence_recovery.spec.ts:127:7 â€º Data Persistence and Recovery â€º Auto-save and draft recovery
ğŸš€ Starting auto-save test...

[1A[2KğŸ“Š Test 1: Looking for auto-save functionality...

[1A[2KğŸ“Š Form elements found: [33m8[39m

[1A[2KğŸ“Š Auto-save indicators: [33m0[39m

[1A[2KğŸ“Š Test 2: Testing data recovery after refresh...

[1A[2Ktests/data_persistence_recovery.spec.ts:19:7 â€º Data Persistence and Recovery â€º Data persistence across sessions
ğŸ“Š Agent row visible in UI: [33mfalse[39m

[1A[2KğŸ“Š Agent name visible in UI: [33mfalse[39m

[1A[2KğŸ“Š Agent in table by name: [33mfalse[39m

[1A[2KğŸ“Š Any agents visible in table: [33mtrue[39m

[1A[2KğŸ“Š Test 2: Simulating session restart...

[1A[2Ktests/data_persistence_recovery.spec.ts:127:7 â€º Data Persistence and Recovery â€º Auto-save and draft recovery
ğŸ“Š Draft recovery test error: locator.fill: Timeout 5000ms exceeded.
Call log:
[2m  - waiting for locator('input[type="text"], textarea').first()[22m
[2m    - locator resolved to <input type="text" id="agent-name" data-testid="agent-name-input" placeholder="Enter agent name..."/>[22m
[2m    - fill("Recovery test data 1752145640692")[22m
[2m  - attempting fill action[22m
[2m    2 Ã— waiting for element to be visible, enabled and editable[22m
[2m      - element is not visible[22m
[2m    - retrying fill action[22m
[2m    - waiting 20ms[22m
[2m    2 Ã— waiting for element to be visible, enabled and editable[22m
[2m      - element is not visible[22m
[2m    - retrying fill action[22m
[2m      - waiting 100ms[22m
[2m    10 Ã— waiting for element to be visible, enabled and editable[22m
[2m       - element is not visible[22m
[2m     - retrying fill action[22m
[2m       - waiting 500ms[22m


[1A[2Kâœ… Auto-save test completed

[1A[2K[12/36] tests/data_persistence_recovery.spec.ts:192:7 â€º Data Persistence and Recovery â€º Data consistency and integrity
[1A[2Ktests/data_persistence_recovery.spec.ts:192:7 â€º Data Persistence and Recovery â€º Data consistency and integrity
ğŸš€ Starting data consistency test...

[1A[2KğŸ“Š Test 1: Testing data relationships...

[1A[2Ktests/data_persistence_recovery.spec.ts:19:7 â€º Data Persistence and Recovery â€º Data persistence across sessions
ğŸ“Š Agent visible after restart: [33mfalse[39m

[1A[2K  1) tests/data_persistence_recovery.spec.ts:19:7 â€º Data Persistence and Recovery â€º Data persistence across sessions 

    Error: [2mexpect([22m[31mreceived[39m[2m).[22mtoBe[2m([22m[32mexpected[39m[2m) // Object.is equality[22m

    Expected: [32mtrue[39m
    Received: [31mfalse[39m

      108 |     const agentStillVisible = await newPage.locator(`text=${testAgentName}`).isVisible();
      109 |     console.log('ğŸ“Š Agent visible after restart:', agentStillVisible);
    > 110 |     expect(agentStillVisible).toBe(true);
          |                               ^
      111 |     
      112 |     // Verify via API as well
      113 |     const persistedResponse = await newPage.request.get('http://localhost:8001/api/agents', {
        at /Users/davidrose/git/zerg/e2e/tests/data_persistence_recovery.spec.ts:110:31

    Error Context: test-results/data_persistence_recovery--09f15-persistence-across-sessions/error-context.md


[1A[2Ktests/data_persistence_recovery.spec.ts:192:7 â€º Data Persistence and Recovery â€º Data consistency and integrity
ğŸ“Š Created agent for consistency test: [33m6[39m

[1A[2K[13/36] tests/data_persistence_recovery.spec.ts:313:7 â€º Data Persistence and Recovery â€º Data export and import integrity
[1A[2KğŸ“Š Created workflow with agent reference: [33m2[39m

[1A[2KğŸ“Š Test 2: Testing data integrity...

[1A[2KğŸ“Š Initial agent count: [33m6[39m

[1A[2KğŸ“Š After creation agent count: [33m7[39m

[1A[2Kâœ… Data integrity maintained during operations

[1A[2Kâœ… Data consistency test completed

[1A[2K[14/36] tests/data_persistence_recovery.spec.ts:403:7 â€º Data Persistence and Recovery â€º Recovery from data corruption scenarios
[1A[2Ktests/data_persistence_recovery.spec.ts:313:7 â€º Data Persistence and Recovery â€º Data export and import integrity
ğŸš€ Starting export/import test...

[1A[2KğŸ“Š Test 1: Looking for export functionality...

[1A[2Ktests/data_persistence_recovery.spec.ts:403:7 â€º Data Persistence and Recovery â€º Recovery from data corruption scenarios
ğŸš€ Starting data corruption recovery test...

[1A[2KğŸ“Š Test 1: Invalid data format recovery...

[1A[2KğŸ“Š Corrupt data response status: [33m422[39m

[1A[2Kâœ… Invalid data properly rejected

[1A[2KğŸ“Š Error details provided: [33mtrue[39m

[1A[2KğŸ“Š Test 2: System state recovery...

[1A[2KğŸ“Š Recovery creation status: [33m201[39m

[1A[2Kâœ… System recovered and accepts valid data after corruption attempt

[1A[2KğŸ“Š Test 3: UI state recovery...

[1A[2Ktests/data_persistence_recovery.spec.ts:313:7 â€º Data Persistence and Recovery â€º Data export and import integrity
ğŸ“Š Export buttons found: [33m0[39m

[1A[2KğŸ“Š Download buttons found: [33m0[39m

[1A[2KğŸ“Š Backup buttons found: [33m0[39m

[1A[2KğŸ“Š No export UI elements found (may be in different location)

[1A[2KğŸ“Š Test 2: Looking for import functionality...

[1A[2KğŸ“Š Import buttons found: [33m0[39m

[1A[2KğŸ“Š Upload buttons found: [33m0[39m

[1A[2KğŸ“Š File inputs found: [33m0[39m

[1A[2KğŸ“Š No import UI elements found (may be in different location)

[1A[2KğŸ“Š Test 3: API data integrity verification...

[1A[2Ktests/data_persistence_recovery.spec.ts:403:7 â€º Data Persistence and Recovery â€º Recovery from data corruption scenarios
ğŸ“Š UI loaded successfully: [33mtrue[39m

[1A[2KğŸ“Š UI error count: [33m0[39m

[1A[2Kâœ… UI recovered successfully

[1A[2Kâœ… Data corruption recovery test completed

[1A[2K[15/36] tests/error_handling_edge_cases.spec.ts:18:7 â€º Error Handling and Edge Cases â€º API error handling with invalid data
[1A[2Ktests/error_handling_edge_cases.spec.ts:18:7 â€º Error Handling and Edge Cases â€º API error handling with invalid data
ğŸš€ Starting API error handling test...

[1A[2KğŸ“Š Worker ID: 0

[1A[2KğŸ“Š Test 1: Invalid agent creation - missing fields

[1A[2KğŸ“Š Invalid agent creation status: [33m422[39m

[1A[2KğŸ“Š Validation error structure: [33mtrue[39m

[1A[2Kâœ… Validation errors properly returned

[1A[2KğŸ“Š Test 2: Invalid JSON payload

[1A[2KğŸ“Š Invalid JSON status: [33m422[39m

[1A[2Kâœ… Invalid JSON properly rejected

[1A[2KğŸ“Š Test 3: Large payload handling

[1A[2KğŸ“Š Large payload status: [33m201[39m

[1A[2Kâœ… Large payload accepted (system handles large data)

[1A[2KğŸ“Š Test 4: Invalid HTTP methods

[1A[2KğŸ“Š Invalid method status: [33m405[39m

[1A[2Kâœ… Invalid HTTP methods properly rejected

[1A[2KğŸ“Š Test 5: Non-existent resource access

[1A[2KğŸ“Š Non-existent resource status: [33m404[39m

[1A[2Kâœ… Non-existent resources return 404

[1A[2Kâœ… API error handling test completed

[1A[2K[16/36] tests/error_handling_edge_cases.spec.ts:126:7 â€º Error Handling and Edge Cases â€º Database constraint and data integrity
[1A[2Ktests/error_handling_edge_cases.spec.ts:126:7 â€º Error Handling and Edge Cases â€º Database constraint and data integrity
ğŸš€ Starting database constraint test...

[1A[2KğŸ“Š Test 1: Duplicate name handling

[1A[2KğŸ“Š First agent created: [33m10[39m

[1A[2KğŸ“Š Duplicate creation status: [33m201[39m

[1A[2Kâœ… Duplicate names allowed (system permits duplicates)

[1A[2KğŸ“Š Test 2: Field length validation

[1A[2KğŸ“Š Long field status: [33m201[39m

[1A[2Kâœ… Long fields accepted (no length limits)

[1A[2Kâœ… Database constraint test completed

[1A[2K[17/36] tests/error_handling_edge_cases.spec.ts:201:7 â€º Error Handling and Edge Cases â€º Concurrent operations and race conditions
[1A[2Ktests/error_handling_edge_cases.spec.ts:201:7 â€º Error Handling and Edge Cases â€º Concurrent operations and race conditions
ğŸš€ Starting concurrency test...

[1A[2KğŸ“Š Test 1: Concurrent agent creation

[1A[2Ktests/data_persistence_recovery.spec.ts:313:7 â€º Data Persistence and Recovery â€º Data export and import integrity
ğŸ“Š Created test agent for export: [33m14[39m

[1A[2KğŸ“Š Data integrity on retrieval: [33mtrue[39m

[1A[2Kâœ… Data maintains integrity during storage/retrieval

[1A[2Kâœ… Export/import test completed

[1A[2K[18/36] tests/error_handling_edge_cases.spec.ts:261:7 â€º Error Handling and Edge Cases â€º UI error state handling
[1A[2Ktests/error_handling_edge_cases.spec.ts:261:7 â€º Error Handling and Edge Cases â€º UI error state handling
ğŸš€ Starting UI error state test...

[1A[2Ktests/error_handling_edge_cases.spec.ts:201:7 â€º Error Handling and Edge Cases â€º Concurrent operations and race conditions
ğŸ“Š Concurrent creation success: [33m5[39m

[1A[2KğŸ“Š Concurrent creation errors: [33m0[39m

[1A[2Kâœ… Concurrent operations handled well

[1A[2KğŸ“Š Test 2: Rapid-fire GET requests

[1A[2KğŸ“Š Rapid requests success: [33m10[39m

[1A[2Kâœ… Rapid requests handled well

[1A[2Kâœ… Concurrency test completed

[1A[2K[19/36] tests/multi_user_concurrency.spec.ts:18:7 â€º Multi-User and Concurrency â€º Multiple user sessions with data isolation
[1A[2Ktests/multi_user_concurrency.spec.ts:18:7 â€º Multi-User and Concurrency â€º Multiple user sessions with data isolation
ğŸš€ Starting multi-user data isolation test...

[1A[2KğŸ“Š Created 3 user sessions

[1A[2KğŸ“Š Test 1: Creating isolated data per user...

[1A[2Ktests/error_handling_edge_cases.spec.ts:261:7 â€º Error Handling and Edge Cases â€º UI error state handling
ğŸ“Š Test 1: Network connectivity simulation

[1A[2Ktests/multi_user_concurrency.spec.ts:18:7 â€º Multi-User and Concurrency â€º Multiple user sessions with data isolation
ğŸ“Š User 2 created agent: [33m1[39m

[1A[2KğŸ“Š User 0 created agent: [33m1[39m

[1A[2Ktests/error_handling_edge_cases.spec.ts:261:7 â€º Error Handling and Edge Cases â€º UI error state handling
ğŸ“Š Error indicators found: [33m0[39m

[1A[2Ktests/multi_user_concurrency.spec.ts:18:7 â€º Multi-User and Concurrency â€º Multiple user sessions with data isolation
ğŸ“Š User 1 created agent: [33m1[39m

[1A[2KğŸ“Š Successful agent creations: [33m3[39m / [33m3[39m

[1A[2KğŸ“Š Test 2: Verifying data isolation...

[1A[2KğŸ“Š User 0 sees own agent: [33mtrue[39m

[1A[2KğŸ“Š User 0 sees other users' agents: [33mtrue[39m

[1A[2KğŸ“Š User 2 sees own agent: [33mtrue[39m

[1A[2KğŸ“Š User 2 sees other users' agents: [33mtrue[39m

[1A[2KğŸ“Š User 1 sees own agent: [33mtrue[39m

[1A[2KğŸ“Š User 1 sees other users' agents: [33mtrue[39m

[1A[2KğŸ“Š Users with proper data isolation: [33m0[39m / [33m3[39m

[1A[2Kâš ï¸  Data isolation may need improvement

[1A[2Kâœ… Multi-user data isolation test completed

[1A[2K[20/36] tests/multi_user_concurrency.spec.ts:137:7 â€º Multi-User and Concurrency â€º Concurrent workflow execution
[1A[2Ktests/multi_user_concurrency.spec.ts:137:7 â€º Multi-User and Concurrency â€º Concurrent workflow execution
ğŸš€ Starting concurrent workflow execution test...

[1A[2KğŸ“Š Created 3 workflow sessions

[1A[2KğŸ“Š Test 1: Creating workflows concurrently...

[1A[2KğŸ“Š User 2 created workflow: [33m1[39m

[1A[2KğŸ“Š User 1 created workflow: [33m1[39m

[1A[2KğŸ“Š User 0 created workflow: [33m1[39m

[1A[2KğŸ“Š Successful workflow creations: [33m3[39m / [33m3[39m

[1A[2KğŸ“Š Concurrent workflow creation time: [33m11[39m ms

[1A[2KğŸ“Š Test 2: Executing workflows concurrently...

[1A[2Ktests/error_handling_edge_cases.spec.ts:261:7 â€º Error Handling and Edge Cases â€º UI error state handling
âœ… Network connectivity simulation completed

[1A[2KğŸ“Š Test 2: Invalid navigation handling

[1A[2K[2m[WebServer] [22mERROR - [AgentRunner] Exception during runnable.ainvoke: Error code: 404 - {'error': {'message': 'The model `gpt-mock` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
[2m[WebServer] [22mTraceback (most recent call last):
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/managers/agent_runner.py", line 137, in run_thread
[2m[WebServer] [22m    updated_messages = await self._runnable.ainvoke(original_msgs, config)
[2m[WebServer] [22m                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2850, in ainvoke
[2m[WebServer] [22m    async for chunk in self.astream(
[2m[WebServer] [22m    ...<13 lines>...
[2m[WebServer] [22m            chunks.append(chunk)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2732, in astream
[2m[WebServer] [22m    async for _ in runner.atick(
[2m[WebServer] [22m    ...<7 lines>...
[2m[WebServer] [22m            yield o
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 256, in agent_executor
[2m[WebServer] [22m    return _agent_executor_sync(messages, previous=previous)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 248, in _agent_executor_sync
[2m[WebServer] [22m    return asyncio.run(_agent_executor_async(messages, previous=previous))
[2m[WebServer] [22m           ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/runners.py", line 194, in run
[2m[WebServer] [22m    return runner.run(main)
[2m[WebServer] [22m           ~~~~~~~~~~^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/runners.py", line 118, in run
[2m[WebServer] [22m    return self._loop.run_until_complete(task)
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/base_events.py", line 720, in run_until_complete
[2m[WebServer] [22m    return future.result()
[2m[WebServer] [22m           ~~~~~~~~~~~~~^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 208, in _agent_executor_async
[2m[WebServer] [22m    llm_response = await _call_model_async(current_messages)
[2m[WebServer] [22m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 134, in _call_model_async
[2m[WebServer] [22m    return await asyncio.to_thread(_call_model_sync, messages)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/threads.py", line 25, in to_thread
[2m[WebServer] [22m    return await loop.run_in_executor(None, func_call)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/thread.py", line 59, in run
[2m[WebServer] [22m    result = self.fn(*self.args, **self.kwargs)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 127, in _call_model_sync
[2m[WebServer] [22m    return llm_with_tools.invoke(messages)
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/runnables/base.py", line 5416, in invoke
[2m[WebServer] [22m    return self.bound.invoke(
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        input,
[2m[WebServer] [22m        ^^^^^^
[2m[WebServer] [22m        self._merge_configs(config),
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m        **{**self.kwargs, **kwargs},
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 369, in invoke
[2m[WebServer] [22m    self.generate_prompt(
[2m[WebServer] [22m    ~~~~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        [self._convert_input(input)],
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<6 lines>...
[2m[WebServer] [22m        **kwargs,
[2m[WebServer] [22m        ^^^^^^^^^
[2m[WebServer] [22m    ).generations[0][0],
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 946, in generate_prompt
[2m[WebServer] [22m    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
[2m[WebServer] [22m           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 765, in generate
[2m[WebServer] [22m    self._generate_with_cache(
[2m[WebServer] [22m    ~~~~~~~~~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        m,
[2m[WebServer] [22m        ^^
[2m[WebServer] [22m    ...<2 lines>...
[2m[WebServer] [22m        **kwargs,
[2m[WebServer] [22m        ^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 1011, in _generate_with_cache
[2m[WebServer] [22m    result = self._generate(
[2m[WebServer] [22m        messages, stop=stop, run_manager=run_manager, **kwargs
[2m[WebServer] [22m    )
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py", line 991, in _generate
[2m[WebServer] [22m    response = self.client.create(**payload)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_utils/_utils.py", line 287, in wrapper
[2m[WebServer] [22m    return func(*args, **kwargs)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py", line 925, in create
[2m[WebServer] [22m    return self._post(
[2m[WebServer] [22m           ~~~~~~~~~~^
[2m[WebServer] [22m        "/chat/completions",
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<43 lines>...
[2m[WebServer] [22m        stream_cls=Stream[ChatCompletionChunk],
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_base_client.py", line 1239, in post
[2m[WebServer] [22m    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
[2m[WebServer] [22m                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_base_client.py", line 1034, in request
[2m[WebServer] [22m    raise self._make_status_error_from_response(err.response) from None
[2m[WebServer] [22mopenai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `gpt-mock` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
[2m[WebServer] [22mDuring task with name 'agent_executor' and id '1ddafec4-5f06-a162-b73f-0a5794ef9643'

[1A[2K[2m[WebServer] [22mERROR - [AgentNode] Exception in agent node agent-1 (agent_id=1): Error code: 404 - {'error': {'message': 'The model `gpt-mock` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
[2m[WebServer] [22mTraceback (most recent call last):
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/services/langgraph_workflow_engine.py", line 729, in agent_node
[2m[WebServer] [22m    created_messages = await runner.run_thread(db, thread)
[2m[WebServer] [22m                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/managers/agent_runner.py", line 137, in run_thread
[2m[WebServer] [22m    updated_messages = await self._runnable.ainvoke(original_msgs, config)
[2m[WebServer] [22m                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2850, in ainvoke
[2m[WebServer] [22m    async for chunk in self.astream(
[2m[WebServer] [22m    ...<13 lines>...
[2m[WebServer] [22m            chunks.append(chunk)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2732, in astream
[2m[WebServer] [22m    async for _ in runner.atick(
[2m[WebServer] [22m    ...<7 lines>...
[2m[WebServer] [22m            yield o
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 256, in agent_executor
[2m[WebServer] [22m    return _agent_executor_sync(messages, previous=previous)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 248, in _agent_executor_sync
[2m[WebServer] [22m    return asyncio.run(_agent_executor_async(messages, previous=previous))
[2m[WebServer] [22m           ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/runners.py", line 194, in run
[2m[WebServer] [22m    return runner.run(main)
[2m[WebServer] [22m           ~~~~~~~~~~^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/runners.py", line 118, in run
[2m[WebServer] [22m    return self._loop.run_until_complete(task)
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/base_events.py", line 720, in run_until_complete
[2m[WebServer] [22m    return future.result()
[2m[WebServer] [22m           ~~~~~~~~~~~~~^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 208, in _agent_executor_async
[2m[WebServer] [22m    llm_response = await _call_model_async(current_messages)
[2m[WebServer] [22m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 134, in _call_model_async
[2m[WebServer] [22m    return await asyncio.to_thread(_call_model_sync, messages)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/threads.py", line 25, in to_thread
[2m[WebServer] [22m    return await loop.run_in_executor(None, func_call)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/thread.py", line 59, in run
[2m[WebServer] [22m    result = self.fn(*self.args, **self.kwargs)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 127, in _call_model_sync
[2m[WebServer] [22m    return llm_with_tools.invoke(messages)
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/runnables/base.py", line 5416, in invoke
[2m[WebServer] [22m    return self.bound.invoke(
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        input,
[2m[WebServer] [22m        ^^^^^^
[2m[WebServer] [22m        self._merge_configs(config),
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m        **{**self.kwargs, **kwargs},
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 369, in invoke
[2m[WebServer] [22m    self.generate_prompt(
[2m[WebServer] [22m    ~~~~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        [self._convert_input(input)],
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<6 lines>...
[2m[WebServer] [22m        **kwargs,
[2m[WebServer] [22m        ^^^^^^^^^
[2m[WebServer] [22m    ).generations[0][0],
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 946, in generate_prompt
[2m[WebServer] [22m    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
[2m[WebServer] [22m           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 765, in generate
[2m[WebServer] [22m    self._generate_with_cache(
[2m[WebServer] [22m    ~~~~~~~~~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        m,
[2m[WebServer] [22m        ^^
[2m[WebServer] [22m    ...<2 lines>...
[2m[WebServer] [22m        **kwargs,
[2m[WebServer] [22m        ^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 1011, in _generate_with_cache
[2m[WebServer] [22m    result = self._generate(
[2m[WebServer] [22m        messages, stop=stop, run_manager=run_manager, **kwargs
[2m[WebServer] [22m    )
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py", line 991, in _generate
[2m[WebServer] [22m    response = self.client.create(**payload)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_utils/_utils.py", line 287, in wrapper
[2m[WebServer] [22m    return func(*args, **kwargs)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py", line 925, in create
[2m[WebServer] [22m    return self._post(
[2m[WebServer] [22m           ~~~~~~~~~~^
[2m[WebServer] [22m        "/chat/completions",
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<43 lines>...
[2m[WebServer] [22m        stream_cls=Stream[ChatCompletionChunk],
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_base_client.py", line 1239, in post
[2m[WebServer] [22m    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
[2m[WebServer] [22m                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_base_client.py", line 1034, in request
[2m[WebServer] [22m    raise self._make_status_error_from_response(err.response) from None
[2m[WebServer] [22mopenai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `gpt-mock` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
[2m[WebServer] [22mDuring task with name 'agent_executor' and id '1ddafec4-5f06-a162-b73f-0a5794ef9643'

[1A[2K[2m[WebServer] [22mERROR - [AgentNode] Updated node_state to 'failed' in DB

[1A[2K[2m[WebServer] [22mERROR - [AgentNode] Re-raising exception to fail workflow execution

[1A[2K[2m[WebServer] [22mERROR - [LangGraphEngine] Execution failed â€“ execution_id=1
[2m[WebServer] [22mTraceback (most recent call last):
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/services/langgraph_workflow_engine.py", line 146, in execute_workflow
[2m[WebServer] [22m    await self._execute_workflow_internal(workflow, execution, db)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/services/langgraph_workflow_engine.py", line 214, in _execute_workflow_internal
[2m[WebServer] [22m    async for chunk in graph.astream(initial_state, config):
[2m[WebServer] [22m    ...<36 lines>...
[2m[WebServer] [22m            logger.warning(f"[LangGraphEngine] Received empty chunk #{chunk_count}")
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2732, in astream
[2m[WebServer] [22m    async for _ in runner.atick(
[2m[WebServer] [22m    ...<7 lines>...
[2m[WebServer] [22m            yield o
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/services/langgraph_workflow_engine.py", line 729, in agent_node
[2m[WebServer] [22m    created_messages = await runner.run_thread(db, thread)
[2m[WebServer] [22m                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/managers/agent_runner.py", line 137, in run_thread
[2m[WebServer] [22m    updated_messages = await self._runnable.ainvoke(original_msgs, config)
[2m[WebServer] [22m                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2850, in ainvoke
[2m[WebServer] [22m    async for chunk in self.astream(
[2m[WebServer] [22m    ...<13 lines>...
[2m[WebServer] [22m            chunks.append(chunk)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2732, in astream
[2m[WebServer] [22m    async for _ in runner.atick(
[2m[WebServer] [22m    ...<7 lines>...
[2m[WebServer] [22m            yield o
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 256, in agent_executor
[2m[WebServer] [22m    return _agent_executor_sync(messages, previous=previous)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 248, in _agent_executor_sync
[2m[WebServer] [22m    return asyncio.run(_agent_executor_async(messages, previous=previous))
[2m[WebServer] [22m           ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/runners.py", line 194, in run
[2m[WebServer] [22m    return runner.run(main)
[2m[WebServer] [22m           ~~~~~~~~~~^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/runners.py", line 118, in run
[2m[WebServer] [22m    return self._loop.run_until_complete(task)
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/base_events.py", line 720, in run_until_complete
[2m[WebServer] [22m    return future.result()
[2m[WebServer] [22m           ~~~~~~~~~~~~~^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 208, in _agent_executor_async
[2m[WebServer] [22m    llm_response = await _call_model_async(current_messages)
[2m[WebServer] [22m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 134, in _call_model_async
[2m[WebServer] [22m    return await asyncio.to_thread(_call_model_sync, messages)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/threads.py", line 25, in to_thread
[2m[WebServer] [22m    return await loop.run_in_executor(None, func_call)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/thread.py", line 59, in run
[2m[WebServer] [22m    result = self.fn(*self.args, **self.kwargs)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 127, in _call_model_sync
[2m[WebServer] [22m    return llm_with_tools.invoke(messages)
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/runnables/base.py", line 5416, in invoke
[2m[WebServer] [22m    return self.bound.invoke(
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        input,
[2m[WebServer] [22m        ^^^^^^
[2m[WebServer] [22m        self._merge_configs(config),
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m        **{**self.kwargs, **kwargs},
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 369, in invoke
[2m[WebServer] [22m    self.generate_prompt(
[2m[WebServer] [22m    ~~~~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        [self._convert_input(input)],
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<6 lines>...
[2m[WebServer] [22m        **kwargs,
[2m[WebServer] [22m        ^^^^^^^^^
[2m[WebServer] [22m    ).generations[0][0],
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 946, in generate_prompt
[2m[WebServer] [22m    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
[2m[WebServer] [22m           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 765, in generate
[2m[WebServer] [22m    self._generate_with_cache(
[2m[WebServer] [22m    ~~~~~~~~~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        m,
[2m[WebServer] [22m        ^^
[2m[WebServer] [22m    ...<2 lines>...
[2m[WebServer] [22m        **kwargs,
[2m[WebServer] [22m        ^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 1011, in _generate_with_cache
[2m[WebServer] [22m    result = self._generate(
[2m[WebServer] [22m        messages, stop=stop, run_manager=run_manager, **kwargs
[2m[WebServer] [22m    )
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py", line 991, in _generate
[2m[WebServer] [22m    response = self.client.create(**payload)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_utils/_utils.py", line 287, in wrapper
[2m[WebServer] [22m    return func(*args, **kwargs)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py", line 925, in create
[2m[WebServer] [22m    return self._post(
[2m[WebServer] [22m           ~~~~~~~~~~^
[2m[WebServer] [22m        "/chat/completions",
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<43 lines>...
[2m[WebServer] [22m        stream_cls=Stream[ChatCompletionChunk],
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_base_client.py", line 1239, in post
[2m[WebServer] [22m    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
[2m[WebServer] [22m                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_base_client.py", line 1034, in request
[2m[WebServer] [22m    raise self._make_status_error_from_response(err.response) from None
[2m[WebServer] [22mopenai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `gpt-mock` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
[2m[WebServer] [22mDuring task with name 'agent_executor' and id '1ddafec4-5f06-a162-b73f-0a5794ef9643'
[2m[WebServer] [22mDuring task with name 'agent-1' and id '87437cbe-c5b1-168e-5158-e1f052752888'

[1A[2K[2m[WebServer] [22mERROR - Unhandled exception: Error code: 404 - {'error': {'message': 'The model `gpt-mock` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
[2m[WebServer] [22mTraceback (most recent call last):
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/middleware/errors.py", line 165, in __call__
[2m[WebServer] [22m    await self.app(scope, receive, _send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/middleware/worker_db.py", line 101, in __call__
[2m[WebServer] [22m    await self.app(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/middleware/cors.py", line 85, in __call__
[2m[WebServer] [22m    await self.app(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/middleware/exceptions.py", line 62, in __call__
[2m[WebServer] [22m    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
[2m[WebServer] [22m    raise exc
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
[2m[WebServer] [22m    await app(scope, receive, sender)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/routing.py", line 714, in __call__
[2m[WebServer] [22m    await self.middleware_stack(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/routing.py", line 734, in app
[2m[WebServer] [22m    await route.handle(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/routing.py", line 288, in handle
[2m[WebServer] [22m    await self.app(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/routing.py", line 76, in app
[2m[WebServer] [22m    await wrap_app_handling_exceptions(app, request)(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
[2m[WebServer] [22m    raise exc
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
[2m[WebServer] [22m    await app(scope, receive, sender)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/routing.py", line 73, in app
[2m[WebServer] [22m    response = await f(request)
[2m[WebServer] [22m               ^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/fastapi/routing.py", line 301, in app
[2m[WebServer] [22m    raw_response = await run_endpoint_function(
[2m[WebServer] [22m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<3 lines>...
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/fastapi/routing.py", line 212, in run_endpoint_function
[2m[WebServer] [22m    return await dependant.call(**values)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/routers/workflow_executions.py", line 74, in start_workflow_execution
[2m[WebServer] [22m    execution_id = await langgraph_workflow_engine.execute_workflow(workflow_id)
[2m[WebServer] [22m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/services/langgraph_workflow_engine.py", line 146, in execute_workflow
[2m[WebServer] [22m    await self._execute_workflow_internal(workflow, execution, db)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/services/langgraph_workflow_engine.py", line 214, in _execute_workflow_internal
[2m[WebServer] [22m    async for chunk in graph.astream(initial_state, config):
[2m[WebServer] [22m    ...<36 lines>...
[2m[WebServer] [22m            logger.warning(f"[LangGraphEngine] Received empty chunk #{chunk_count}")
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2732, in astream
[2m[WebServer] [22m    async for _ in runner.atick(
[2m[WebServer] [22m    ...<7 lines>...
[2m[WebServer] [22m            yield o
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/services/langgraph_workflow_engine.py", line 729, in agent_node
[2m[WebServer] [22m    created_messages = await runner.run_thread(db, thread)
[2m[WebServer] [22m                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/managers/agent_runner.py", line 137, in run_thread
[2m[WebServer] [22m    updated_messages = await self._runnable.ainvoke(original_msgs, config)
[2m[WebServer] [22m                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2850, in ainvoke
[2m[WebServer] [22m    async for chunk in self.astream(
[2m[WebServer] [22m    ...<13 lines>...
[2m[WebServer] [22m            chunks.append(chunk)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2732, in astream
[2m[WebServer] [22m    async for _ in runner.atick(
[2m[WebServer] [22m    ...<7 lines>...
[2m[WebServer] [22m            yield o
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 256, in agent_executor
[2m[WebServer] [22m    return _agent_executor_sync(messages, previous=previous)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 248, in _agent_executor_sync
[2m[WebServer] [22m    return asyncio.run(_agent_executor_async(messages, previous=previous))
[2m[WebServer] [22m           ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/runners.py", line 194, in run
[2m[WebServer] [22m    return runner.run(main)
[2m[WebServer] [22m           ~~~~~~~~~~^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/runners.py", line 118, in run
[2m[WebServer] [22m    return self._loop.run_until_complete(task)
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/base_events.py", line 720, in run_until_complete
[2m[WebServer] [22m    return future.result()
[2m[WebServer] [22m           ~~~~~~~~~~~~~^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 208, in _agent_executor_async
[2m[WebServer] [22m    llm_response = await _call_model_async(current_messages)
[2m[WebServer] [22m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 134, in _call_model_async
[2m[WebServer] [22m    return await asyncio.to_thread(_call_model_sync, messages)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/threads.py", line 25, in to_thread
[2m[WebServer] [22m    return await loop.run_in_executor(None, func_call)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/thread.py", line 59, in run
[2m[WebServer] [22m    result = self.fn(*self.args, **self.kwargs)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 127, in _call_model_sync
[2m[WebServer] [22m    return llm_with_tools.invoke(messages)
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/runnables/base.py", line 5416, in invoke
[2m[WebServer] [22m    return self.bound.invoke(
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        input,
[2m[WebServer] [22m        ^^^^^^
[2m[WebServer] [22m        self._merge_configs(config),
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m        **{**self.kwargs, **kwargs},
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 369, in invoke
[2m[WebServer] [22m    self.generate_prompt(
[2m[WebServer] [22m    ~~~~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        [self._convert_input(input)],
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<6 lines>...
[2m[WebServer] [22m        **kwargs,
[2m[WebServer] [22m        ^^^^^^^^^
[2m[WebServer] [22m    ).generations[0][0],
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 946, in generate_prompt
[2m[WebServer] [22m    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
[2m[WebServer] [22m           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 765, 

[1A[2K[2m[WebServer] [22min generate
[2m[WebServer] [22m    self._generate_with_cache(
[2m[WebServer] [22m    ~~~~~~~~~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        m,
[2m[WebServer] [22m        ^^
[2m[WebServer] [22m    ...<2 lines>...
[2m[WebServer] [22m        **kwargs,
[2m[WebServer] [22m        ^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 1011, in _generate_with_cache
[2m[WebServer] [22m    result = self._generate(
[2m[WebServer] [22m        messages, stop=stop, run_manager=run_manager, **kwargs
[2m[WebServer] [22m    )
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py", line 991, in _generate
[2m[WebServer] [22m    response = self.client.create(**payload)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_utils/_utils.py", line 287, in wrapper
[2m[WebServer] [22m    return func(*args, **kwargs)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py", line 925, in create
[2m[WebServer] [22m    return self._post(
[2m[WebServer] [22m           ~~~~~~~~~~^
[2m[WebServer] [22m        "/chat/completions",
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<43 lines>...
[2m[WebServer] [22m        stream_cls=Stream[ChatCompletionChunk],
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_base_client.py", line 1239, in post
[2m[WebServer] [22m    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
[2m[WebServer] [22m                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_base_client.py", line 1034, in request
[2m[WebServer] [22m    raise self._make_status_error_from_response(err.response) from None
[2m[WebServer] [22mopenai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `gpt-mock` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
[2m[WebServer] [22mDuring task with name 'agent_executor' and id '1ddafec4-5f06-a162-b73f-0a5794ef9643'
[2m[WebServer] [22mDuring task with name 'agent-1' and id '87437cbe-c5b1-168e-5158-e1f052752888'

[1A[2Ktests/multi_user_concurrency.spec.ts:137:7 â€º Multi-User and Concurrency â€º Concurrent workflow execution
âŒ User 0 execution failed: [33m500[39m

[1A[2K[2m[WebServer] [22mERROR:    Exception in ASGI application
[2m[WebServer] [22mTraceback (most recent call last):
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/uvicorn/protocols/http/h11_impl.py", line 408, in run_asgi
[2m[WebServer] [22m    result = await app(  # type: ignore[func-returns-value]
[2m[WebServer] [22m             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m        self.scope, self.receive, self.send
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/uvicorn/middleware/proxy_headers.py", line 84, in __call__
[2m[WebServer] [22m    return await self.app(scope, receive, send)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/fastapi/applications.py", line 1054, in __call__
[2m[WebServer] [22m    await super().__call__(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/applications.py", line 112, in __call__
[2m[WebServer] [22m    await self.middleware_stack(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/middleware/errors.py", line 187, in __call__
[2m[WebServer] [22m    raise exc
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/middleware/errors.py", line 165, in __call__
[2m[WebServer] [22m    await self.app(scope, receive, _send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/middleware/worker_db.py", line 101, in __call__
[2m[WebServer] [22m    await self.app(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/middleware/cors.py", line 85, in __call__
[2m[WebServer] [22m    await self.app(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/middleware/exceptions.py", line 62, in __call__
[2m[WebServer] [22m    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
[2m[WebServer] [22m    raise exc
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
[2m[WebServer] [22m    await app(scope, receive, sender)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/routing.py", line 714, in __call__
[2m[WebServer] [22m    await self.middleware_stack(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/routing.py", line 734, in app
[2m[WebServer] [22m    await route.handle(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/routing.py", line 288, in handle
[2m[WebServer] [22m    await self.app(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/routing.py", line 76, in app
[2m[WebServer] [22m    await wrap_app_handling_exceptions(app, request)(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
[2m[WebServer] [22m    raise exc
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
[2m[WebServer] [22m    await app(scope, receive, sender)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/routing.py", line 73, in app
[2m[WebServer] [22m    response = await f(request)
[2m[WebServer] [22m               ^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/fastapi/routing.py", line 301, in app
[2m[WebServer] [22m    raw_response = await run_endpoint_function(
[2m[WebServer] [22m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<3 lines>...
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/fastapi/routing.py", line 212, in run_endpoint_function
[2m[WebServer] [22m    return await dependant.call(**values)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/routers/workflow_executions.py", line 74, in start_workflow_execution
[2m[WebServer] [22m    execution_id = await langgraph_workflow_engine.execute_workflow(workflow_id)
[2m[WebServer] [22m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/services/langgraph_workflow_engine.py", line 146, in execute_workflow
[2m[WebServer] [22m    await self._execute_workflow_internal(workflow, execution, db)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/services/langgraph_workflow_engine.py", line 214, in _execute_workflow_internal
[2m[WebServer] [22m    async for chunk in graph.astream(initial_state, config):
[2m[WebServer] [22m    ...<36 lines>...
[2m[WebServer] [22m            logger.warning(f"[LangGraphEngine] Received empty chunk #{chunk_count}")
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2732, in astream
[2m[WebServer] [22m    async for _ in runner.atick(
[2m[WebServer] [22m    ...<7 lines>...
[2m[WebServer] [22m            yield o
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/services/langgraph_workflow_engine.py", line 729, in agent_node
[2m[WebServer] [22m    created_messages = await runner.run_thread(db, thread)
[2m[WebServer] [22m                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/managers/agent_runner.py", line 137, in run_thread
[2m[WebServer] [22m    updated_messages = await self._runnable.ainvoke(original_msgs, config)
[2m[WebServer] [22m                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2850, in ainvoke
[2m[WebServer] [22m    async for chunk in self.astream(
[2m[WebServer] [22m    ...<13 lines>...
[2m[WebServer] [22m            chunks.append(chunk)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2732, in astream
[2m[WebServer] [22m    async for _ in runner.atick(
[2m[WebServer] [22m    ...<7 lines>...
[2m[WebServer] [22m            yield o
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 256, in agent_executor
[2m[WebServer] [22m    return _agent_executor_sync(messages, previous=previous)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 248, in _agent_executor_sync
[2m[WebServer] [22m    return asyncio.run(_agent_executor_async(messages, previous=previous))
[2m[WebServer] [22m           ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/runners.py", line 194, in run
[2m[WebServer] [22m    return runner.run(main)
[2m[WebServer] [22m           ~~~~~~~~~~^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/runners.py", line 118, in run
[2m[WebServer] [22m    return self._loop.run_until_complete(task)
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/base_events.py", line 720, in run_until_complete
[2m[WebServer] [22m    return future.result()
[2m[WebServer] [22m           ~~~~~~~~~~~~~^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 208, in _agent_executor_async
[2m[WebServer] [22m    llm_response = await _call_model_async(current_messages)
[2m[WebServer] [22m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 134, in _call_model_async
[2m[WebServer] [22m    return await asyncio.to_thread(_call_model_sync, messages)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/threads.py", line 25, in to_thread
[2m[WebServer] [22m    return await loop.run_in_executor(None, func_call)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/thread.py", line 59, in run
[2m[WebServer] [22m    result = self.fn(*self.args, **self.kwargs)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 127, in _call_model_sync
[2m[WebServer] [22m    return llm_with_tools.invoke(messages)
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/runnables/base.py", line 5416, in invoke
[2m[WebServer] [22m    return self.bound.invoke(
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        input,
[2m[WebServer] [22m        ^^^^^^
[2m[WebServer] [22m        self._merge_configs(config),
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^

[1A[2K[2m[WebServer] [22m^^^^^^^^^
[2m[WebServer] [22m        **{**self.kwargs, **kwargs},
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 369, in invoke
[2m[WebServer] [22m    self.generate_prompt(
[2m[WebServer] [22m    ~~~~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        [self._convert_input(input)],
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<6 lines>...
[2m[WebServer] [22m        **kwargs,
[2m[WebServer] [22m        ^^^^^^^^^
[2m[WebServer] [22m    ).generations[0][0],
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 946, in generate_prompt
[2m[WebServer] [22m    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
[2m[WebServer] [22m           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 765, in generate
[2m[WebServer] [22m    self._generate_with_cache(
[2m[WebServer] [22m    ~~~~~~~~~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        m,
[2m[WebServer] [22m        ^^
[2m[WebServer] [22m    ...<2 lines>...
[2m[WebServer] [22m        **kwargs,
[2m[WebServer] [22m        ^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 1011, in _generate_with_cache
[2m[WebServer] [22m    result = self._generate(
[2m[WebServer] [22m        messages, stop=stop, run_manager=run_manager, **kwargs
[2m[WebServer] [22m    )
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py", line 991, in _generate
[2m[WebServer] [22m    response = self.client.create(**payload)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_utils/_utils.py", line 287, in wrapper
[2m[WebServer] [22m    return func(*args, **kwargs)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py", line 925, in create
[2m[WebServer] [22m    return self._post(
[2m[WebServer] [22m           ~~~~~~~~~~^
[2m[WebServer] [22m        "/chat/completions",
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<43 lines>...
[2m[WebServer] [22m        stream_cls=Stream[ChatCompletionChunk],
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_base_client.py", line 1239, in post
[2m[WebServer] [22m    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
[2m[WebServer] [22m                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_base_client.py", line 1034, in request
[2m[WebServer] [22m    raise self._make_status_error_from_response(err.response) from None
[2m[WebServer] [22mopenai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `gpt-mock` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
[2m[WebServer] [22mDuring task with name 'agent_executor' and id '1ddafec4-5f06-a162-b73f-0a5794ef9643'
[2m[WebServer] [22mDuring task with name 'agent-1' and id '87437cbe-c5b1-168e-5158-e1f052752888'

[1A[2K[2m[WebServer] [22mERROR - [AgentRunner] Exception during runnable.ainvoke: Error code: 404 - {'error': {'message': 'The model `gpt-mock` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
[2m[WebServer] [22mTraceback (most recent call last):
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/managers/agent_runner.py", line 137, in run_thread
[2m[WebServer] [22m    updated_messages = await self._runnable.ainvoke(original_msgs, config)
[2m[WebServer] [22m                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2850, in ainvoke
[2m[WebServer] [22m    async for chunk in self.astream(
[2m[WebServer] [22m    ...<13 lines>...
[2m[WebServer] [22m            chunks.append(chunk)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2732, in astream
[2m[WebServer] [22m    async for _ in runner.atick(
[2m[WebServer] [22m    ...<7 lines>...
[2m[WebServer] [22m            yield o
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 256, in agent_executor
[2m[WebServer] [22m    return _agent_executor_sync(messages, previous=previous)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 248, in _agent_executor_sync
[2m[WebServer] [22m    return asyncio.run(_agent_executor_async(messages, previous=previous))
[2m[WebServer] [22m           ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/runners.py", line 194, in run
[2m[WebServer] [22m    return runner.run(main)
[2m[WebServer] [22m           ~~~~~~~~~~^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/runners.py", line 118, in run
[2m[WebServer] [22m    return self._loop.run_until_complete(task)
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/base_events.py", line 720, in run_until_complete
[2m[WebServer] [22m    return future.result()
[2m[WebServer] [22m           ~~~~~~~~~~~~~^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 208, in _agent_executor_async
[2m[WebServer] [22m    llm_response = await _call_model_async(current_messages)
[2m[WebServer] [22m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 134, in _call_model_async
[2m[WebServer] [22m    return await asyncio.to_thread(_call_model_sync, messages)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/threads.py", line 25, in to_thread
[2m[WebServer] [22m    return await loop.run_in_executor(None, func_call)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/thread.py", line 59, in run
[2m[WebServer] [22m    result = self.fn(*self.args, **self.kwargs)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 127, in _call_model_sync
[2m[WebServer] [22m    return llm_with_tools.invoke(messages)
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/runnables/base.py", line 5416, in invoke
[2m[WebServer] [22m    return self.bound.invoke(
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        input,
[2m[WebServer] [22m        ^^^^^^
[2m[WebServer] [22m        self._merge_configs(config),
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m        **{**self.kwargs, **kwargs},
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 369, in invoke
[2m[WebServer] [22m    self.generate_prompt(
[2m[WebServer] [22m    ~~~~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        [self._convert_input(input)],
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<6 lines>...
[2m[WebServer] [22m        **kwargs,
[2m[WebServer] [22m        ^^^^^^^^^
[2m[WebServer] [22m    ).generations[0][0],
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 946, in generate_prompt
[2m[WebServer] [22m    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
[2m[WebServer] [22m           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 765, in generate
[2m[WebServer] [22m    self._generate_with_cache(
[2m[WebServer] [22m    ~~~~~~~~~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        m,
[2m[WebServer] [22m        ^^
[2m[WebServer] [22m    ...<2 lines>...
[2m[WebServer] [22m        **kwargs,
[2m[WebServer] [22m        ^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 1011, in _generate_with_cache
[2m[WebServer] [22m    result = self._generate(
[2m[WebServer] [22m        messages, stop=stop, run_manager=run_manager, **kwargs
[2m[WebServer] [22m    )
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py", line 991, in _generate
[2m[WebServer] [22m    response = self.client.create(**payload)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_utils/_utils.py", line 287, in wrapper
[2m[WebServer] [22m    return func(*args, **kwargs)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py", line 925, in create
[2m[WebServer] [22m    return self._post(
[2m[WebServer] [22m           ~~~~~~~~~~^
[2m[WebServer] [22m        "/chat/completions",
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<43 lines>...
[2m[WebServer] [22m        stream_cls=Stream[ChatCompletionChunk],
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_base_client.py", line 1239, in post
[2m[WebServer] [22m    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
[2m[WebServer] [22m                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_base_client.py", line 1034, in request
[2m[WebServer] [22m    raise self._make_status_error_from_response(err.response) from None
[2m[WebServer] [22mopenai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `gpt-mock` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
[2m[WebServer] [22mDuring task with name 'agent_executor' and id '6ff4f630-2b91-0afe-11f6-a9a249d7bb7d'

[1A[2K[2m[WebServer] [22mERROR - [AgentNode] Exception in agent node agent-1 (agent_id=1): Error code: 404 - {'error': {'message': 'The model `gpt-mock` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
[2m[WebServer] [22mTraceback (most recent call last):
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/services/langgraph_workflow_engine.py", line 729, in agent_node
[2m[WebServer] [22m    created_messages = await runner.run_thread(db, thread)
[2m[WebServer] [22m                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/managers/agent_runner.py", line 137, in run_thread
[2m[WebServer] [22m    updated_messages = await self._runnable.ainvoke(original_msgs, config)
[2m[WebServer] [22m                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2850, in ainvoke
[2m[WebServer] [22m    async for chunk in self.astream(
[2m[WebServer] [22m    ...<13 lines>...
[2m[WebServer] [22m            chunks.append(chunk)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2732, in astream
[2m[WebServer] [22m    async for _ in runner.atick(
[2m[WebServer] [22m    ...<7 lines>...
[2m[WebServer] [22m            yield o
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 256, in agent_executor
[2m[WebServer] [22m    return _agent_executor_sync(messages, previous=previous)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 248, in _agent_executor_sync
[2m[WebServer] [22m    return asyncio.run(_agent_executor_async(messages, previous=previous))
[2m[WebServer] [22m           ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/runners.py", line 194, in run
[2m[WebServer] [22m    return runner.run(main)
[2m[WebServer] [22m           ~~~~~~~~~~^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/runners.py", line 118, in run
[2m[WebServer] [22m    return self._loop.run_until_complete(task)
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/base_events.py", line 720, in run_until_complete
[2m[WebServer] [22m    return future.result()
[2m[WebServer] [22m           ~~~~~~~~~~~~~^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 208, in _agent_executor_async
[2m[WebServer] [22m    llm_response = await _call_model_async(current_messages)
[2m[WebServer] [22m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 134, in _call_model_async
[2m[WebServer] [22m    return await asyncio.to_thread(_call_model_sync, messages)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/threads.py", line 25, in to_thread
[2m[WebServer] [22m    return await loop.run_in_executor(None, func_call)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/thread.py", line 59, in run
[2m[WebServer] [22m    result = self.fn(*self.args, **self.kwargs)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 127, in _call_model_sync
[2m[WebServer] [22m    return llm_with_tools.invoke(messages)
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/runnables/base.py", line 5416, in invoke
[2m[WebServer] [22m    return self.bound.invoke(
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        input,
[2m[WebServer] [22m        ^^^^^^
[2m[WebServer] [22m        self._merge_configs(config),
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m        **{**self.kwargs, **kwargs},
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 369, in invoke
[2m[WebServer] [22m    self.generate_prompt(
[2m[WebServer] [22m    ~~~~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        [self._convert_input(input)],
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<6 lines>...
[2m[WebServer] [22m        **kwargs,
[2m[WebServer] [22m        ^^^^^^^^^
[2m[WebServer] [22m    ).generations[0][0],
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 946, in generate_prompt
[2m[WebServer] [22m    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
[2m[WebServer] [22m           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 765, in generate
[2m[WebServer] [22m    self._generate_with_cache(
[2m[WebServer] [22m    ~~~~~~~~~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        m,
[2m[WebServer] [22m        ^^
[2m[WebServer] [22m    ...<2 lines>...
[2m[WebServer] [22m        **kwargs,
[2m[WebServer] [22m        ^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 1011, in _generate_with_cache
[2m[WebServer] [22m    result = self._generate(
[2m[WebServer] [22m        messages, stop=stop, run_manager=run_manager, **kwargs
[2m[WebServer] [22m    )
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py", line 991, in _generate
[2m[WebServer] [22m    response = self.client.create(**payload)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_utils/_utils.py", line 287, in wrapper
[2m[WebServer] [22m    return func(*args, **kwargs)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py", line 925, in create
[2m[WebServer] [22m    return self._post(
[2m[WebServer] [22m           ~~~~~~~~~~^
[2m[WebServer] [22m        "/chat/completions",
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<43 lines>...
[2m[WebServer] [22m        stream_cls=Stream[ChatCompletionChunk],
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_base_client.py", line 1239, in post
[2m[WebServer] [22m    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
[2m[WebServer] [22m                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_base_client.py", line 1034, in request
[2m[WebServer] [22m    raise self._make_status_error_from_response(err.response) from None
[2m[WebServer] [22mopenai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `gpt-mock` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
[2m[WebServer] [22mDuring task with name 'agent_executor' and id '6ff4f630-2b91-0afe-11f6-a9a249d7bb7d'

[1A[2K[2m[WebServer] [22mERROR - [AgentNode] Updated node_state to 'failed' in DB

[1A[2K[2m[WebServer] [22mERROR - [AgentNode] Re-raising exception to fail workflow execution

[1A[2K[2m[WebServer] [22mERROR - [LangGraphEngine] Execution failed â€“ execution_id=1
[2m[WebServer] [22mTraceback (most recent call last):
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/services/langgraph_workflow_engine.py", line 146, in execute_workflow
[2m[WebServer] [22m    await self._execute_workflow_internal(workflow, execution, db)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/services/langgraph_workflow_engine.py", line 214, in _execute_workflow_internal
[2m[WebServer] [22m    async for chunk in graph.astream(initial_state, config):
[2m[WebServer] [22m    ...<36 lines>...
[2m[WebServer] [22m            logger.warning(f"[LangGraphEngine] Received empty chunk #{chunk_count}")
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2732, in astream
[2m[WebServer] [22m    async for _ in runner.atick(
[2m[WebServer] [22m    ...<7 lines>...
[2m[WebServer] [22m            yield o
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/services/langgraph_workflow_engine.py", line 729, in agent_node
[2m[WebServer] [22m    created_messages = await runner.run_thread(db, thread)
[2m[WebServer] [22m                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/managers/agent_runner.py", line 137, in run_thread
[2m[WebServer] [22m    updated_messages = await self._runnable.ainvoke(original_msgs, config)
[2m[WebServer] [22m                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2850, in ainvoke
[2m[WebServer] [22m    async for chunk in self.astream(
[2m[WebServer] [22m    ...<13 lines>...
[2m[WebServer] [22m            chunks.append(chunk)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2732, in astream
[2m[WebServer] [22m    async for _ in runner.atick(
[2m[WebServer] [22m    ...<7 lines>...
[2m[WebServer] [22m            yield o
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 256, in agent_executor
[2m[WebServer] [22m    return _agent_executor_sync(messages, previous=previous)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 248, in _agent_executor_sync
[2m[WebServer] [22m    return asyncio.run(_agent_executor_async(messages, previous=previous))
[2m[WebServer] [22m           ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/runners.py", line 194, in run
[2m[WebServer] [22m    return runner.run(main)
[2m[WebServer] [22m           ~~~~~~~~~~^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/runners.py", line 118, in run
[2m[WebServer] [22m    return self._loop.run_until_complete(task)
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/base_events.py", line 720, in run_until_complete
[2m[WebServer] [22m    return future.result()
[2m[WebServer] [22m           ~~~~~~~~~~~~~^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 208, in _agent_executor_async
[2m[WebServer] [22m    llm_response = await _call_model_async(current_messages)
[2m[WebServer] [22m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 134, in _call_model_async
[2m[WebServer] [22m    return await asyncio.to_thread(_call_model_sync, messages)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/threads.py", line 25, in to_thread
[2m[WebServer] [22m    return await loop.run_in_executor(None, func_call)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/thread.py", line 59, in run
[2m[WebServer] [22m    result = self.fn(*self.args, **self.kwargs)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 127, in _call_model_sync
[2m[WebServer] [22m    return llm_with_tools.invoke(messages)
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/runnables/base.py", line 5416, in invoke
[2m[WebServer] [22m    return self.bound.invoke(
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        input,
[2m[WebServer] [22m        ^^^^^^
[2m[WebServer] [22m        self._merge_configs(config),
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m        **{**self.kwargs, **kwargs},
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 369, in invoke
[2m[WebServer] [22m    self.generate_prompt(
[2m[WebServer] [22m    ~~~~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        [self._convert_input(input)],
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<6 lines>...
[2m[WebServer] [22m        **kwargs,
[2m[WebServer] [22m        ^^^^^^^^^
[2m[WebServer] [22m    ).generations[0][0],
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 946, in generate_prompt
[2m[WebServer] [22m    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
[2m[WebServer] [22m           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 765, in generate
[2m[WebServer] [22m    self._generate_with_cache(
[2m[WebServer] [22m    ~~~~~~~~~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        m,
[2m[WebServer] [22m        ^^
[2m[WebServer] [22m    ...<2 lines>...
[2m[WebServer] [22m        **kwargs,
[2m[WebServer] [22m        ^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 1011, in _generate_with_cache
[2m[WebServer] [22m    result = self._generate(
[2m[WebServer] [22m        messages, stop=stop, run_manager=run_manager, **kwargs
[2m[WebServer] [22m    )
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py", line 991, in _generate
[2m[WebServer] [22m    response = self.client.create(**payload)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_utils/_utils.py", line 287, in wrapper
[2m[WebServer] [22m    return func(*args, **kwargs)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py", line 925, in create
[2m[WebServer] [22m    return self._post(
[2m[WebServer] [22m           ~~~~~~~~~~^
[2m[WebServer] [22m        "/chat/completions",
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<43 lines>...
[2m[WebServer] [22m        stream_cls=Stream[ChatCompletionChunk],
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_base_client.py", line 1239, in post
[2m[WebServer] [22m    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
[2m[WebServer] [22m                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_base_client.py", line 1034, in request
[2m[WebServer] [22m    raise self._make_status_error_from_response(err.response) from None
[2m[WebServer] [22mopenai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `gpt-mock` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
[2m[WebServer] [22mDuring task with name 'agent_executor' and id '6ff4f630-2b91-0afe-11f6-a9a249d7bb7d'
[2m[WebServer] [22mDuring task with name 'agent-1' and id '6c09dcd7-6848-0e02-5fa7-6479bf954adc'

[1A[2K[2m[WebServer] [22mERROR - Unhandled exception: Error code: 404 - {'error': {'message': 'The model `gpt-mock` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
[2m[WebServer] [22mTraceback (most recent call last):
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/middleware/errors.py", line 165, in __call__
[2m[WebServer] [22m    await self.app(scope, receive, _send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/middleware/worker_db.py", line 101, in __call__
[2m[WebServer] [22m    await self.app(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/middleware/cors.py", line 85, in __call__
[2m[WebServer] [22m    await self.app(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/middleware/exceptions.py", line 62, in __call__
[2m[WebServer] [22m    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
[2m[WebServer] [22m    raise exc
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
[2m[WebServer] [22m    await app(scope, receive, sender)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/routing.py", line 714, in __call__
[2m[WebServer] [22m    await self.middleware_stack(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/routing.py", line 734, in app
[2m[WebServer] [22m    await route.handle(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/routing.py", line 288, in handle
[2m[WebServer] [22m    await self.app(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/routing.py", line 76, in app
[2m[WebServer] [22m    await wrap_app_handling_exceptions(app, request)(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
[2m[WebServer] [22m    raise exc
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
[2m[WebServer] [22m    await app(scope, receive, sender)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/routing.py", line 73, in app
[2m[WebServer] [22m    response = await f(request)
[2m[WebServer] [22m               ^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/fastapi/routing.py", line 301, in app
[2m[WebServer] [22m    raw_response = await run_endpoint_function(
[2m[WebServer] [22m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<3 lines>...
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/fastapi/routing.py", line 212, in run_endpoint_function
[2m[WebServer] [22m    return await dependant.call(**values)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/routers/workflow_executions.py", line 74, in start_workflow_execution
[2m[WebServer] [22m    execution_id = await langgraph_workflow_engine.execute_workflow(workflow_id)
[2m[WebServer] [22m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/services/langgraph_workflow_engine.py", line 146, in execute_workflow
[2m[WebServer] [22m    await self._execute_workflow_internal(workflow, execution, db)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/services/langgraph_workflow_engine.py", line 214, in _execute_workflow_internal
[2m[WebServer] [22m    async for chunk in graph.astream(initial_state, config):
[2m[WebServer] [22m    ...<36 lines>...
[2m[WebServer] [22m            logger.warning(f"[LangGraphEngine] Received empty chunk #{chunk_count}")
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2732, in astream
[2m[WebServer] [22m    async for _ in runner.atick(
[2m[WebServer] [22m    ...<7 lines>...
[2m[WebServer] [22m            yield o
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/services/langgraph_workflow_engine.py", line 729, in agent_node
[2m[WebServer] [22m    created_messages = await runner.run_thread(db, thread)
[2m[WebServer] [22m                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/managers/agent_runner.py", line 137, in run_thread
[2m[WebServer] [22m    updated_messages = await self._runnable.ainvoke(original_msgs, config)
[2m[WebServer] [22m                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2850, in ainvoke
[2m[WebServer] [22m    async for chunk in self.astream(
[2m[WebServer] [22m    ...<13 lines>...
[2m[WebServer] [22m            chunks.append(chunk)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2732, in astream
[2m[WebServer] [22m    async for _ in runner.atick(
[2m[WebServer] [22m    ...<7 lines>...
[2m[WebServer] [22m            yield o
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 256, in agent_executor
[2m[WebServer] [22m    return _agent_executor_sync(messages, previous=previous)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 248, in _agent_executor_sync
[2m[WebServer] [22m    return asyncio.run(_agent_executor_async(messages, previous=previous))
[2m[WebServer] [22m           ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/runners.py", line 194, in run
[2m[WebServer] [22m    return runner.run(main)
[2m[WebServer] [22m           ~~~~~~~~~~^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/runners.py", line 118, in run
[2m[WebServer] [22m    return self._loop.run_until_complete(task)
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/base_events.py", line 720, in run_until_complete
[2m[WebServer] [22m    return future.result()
[2m[WebServer] [22m           ~~~~~~~~~~~~~^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 208, in _agent_executor_async
[2m[WebServer] [22m    llm_response = await _call_model_async(current_messages)
[2m[WebServer] [22m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 134, in _call_model_async
[2m[WebServer] [22m    return await asyncio.to_thread(_call_model_sync, messages)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/threads.py", line 25, in to_thread
[2m[WebServer] [22m    return await loop.run_in_executor(None, func_call)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/thread.py", line 59, in run
[2m[WebServer] [22m    result = self.fn(*self.args, **self.kwargs)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 127, in _call_model_sync
[2m[WebServer] [22m    return llm_with_tools.invoke(messages)
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/runnables/base.py", line 5416, in invoke
[2m[WebServer] [22m    return self.bound.invoke(
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        input,
[2m[WebServer] [22m        ^^^^^^
[2m[WebServer] [22m        self._merge_configs(config),
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m        **{**self.kwargs, **kwargs},
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 369, in invoke
[2m[WebServer] [22m    self.generate_prompt(
[2m[WebServer] [22m    ~~~~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        [self._convert_input(input)],
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<6 lines>...
[2m[WebServer] [22m        **kwargs,
[2m[WebServer] [22m        ^^^^^^^^^
[2m[WebServer] [22m    ).generations[0][0],
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 946, in generate_prompt
[2m[WebServer] [22m    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
[2m[WebServer] [22m           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 765, 

[1A[2K[2m[WebServer] [22min generate
[2m[WebServer] [22m    self._generate_with_cache(
[2m[WebServer] [22m    ~~~~~~~~~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        m,
[2m[WebServer] [22m        ^^
[2m[WebServer] [22m    ...<2 lines>...
[2m[WebServer] [22m        **kwargs,
[2m[WebServer] [22m        ^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 1011, in _generate_with_cache
[2m[WebServer] [22m    result = self._generate(
[2m[WebServer] [22m        messages, stop=stop, run_manager=run_manager, **kwargs
[2m[WebServer] [22m    )
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py", line 991, in _generate
[2m[WebServer] [22m    response = self.client.create(**payload)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_utils/_utils.py", line 287, in wrapper
[2m[WebServer] [22m    return func(*args, **kwargs)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py", line 925, in create
[2m[WebServer] [22m    return self._post(
[2m[WebServer] [22m           ~~~~~~~~~~^
[2m[WebServer] [22m        "/chat/completions",
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<43 lines>...
[2m[WebServer] [22m        stream_cls=Stream[ChatCompletionChunk],
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_base_client.py", line 1239, in post
[2m[WebServer] [22m    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
[2m[WebServer] [22m                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_base_client.py", line 1034, in request
[2m[WebServer] [22m    raise self._make_status_error_from_response(err.response) from None
[2m[WebServer] [22mopenai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `gpt-mock` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
[2m[WebServer] [22mDuring task with name 'agent_executor' and id '6ff4f630-2b91-0afe-11f6-a9a249d7bb7d'
[2m[WebServer] [22mDuring task with name 'agent-1' and id '6c09dcd7-6848-0e02-5fa7-6479bf954adc'

[1A[2KâŒ User 2 execution failed: [33m500[39m

[1A[2K[2m[WebServer] [22mERROR:    Exception in ASGI application
[2m[WebServer] [22mTraceback (most recent call last):
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/uvicorn/protocols/http/h11_impl.py", line 408, in run_asgi
[2m[WebServer] [22m    result = await app(  # type: ignore[func-returns-value]
[2m[WebServer] [22m             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m        self.scope, self.receive, self.send
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/uvicorn/middleware/proxy_headers.py", line 84, in __call__
[2m[WebServer] [22m    return await self.app(scope, receive, send)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/fastapi/applications.py", line 1054, in __call__
[2m[WebServer] [22m    await super().__call__(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/applications.py", line 112, in __call__
[2m[WebServer] [22m    await self.middleware_stack(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/middleware/errors.py", line 187, in __call__
[2m[WebServer] [22m    raise exc
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/middleware/errors.py", line 165, in __call__
[2m[WebServer] [22m    await self.app(scope, receive, _send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/middleware/worker_db.py", line 101, in __call__
[2m[WebServer] [22m    await self.app(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/middleware/cors.py", line 85, in __call__
[2m[WebServer] [22m    await self.app(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/middleware/exceptions.py", line 62, in __call__
[2m[WebServer] [22m    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
[2m[WebServer] [22m    raise exc
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
[2m[WebServer] [22m    await app(scope, receive, sender)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/routing.py", line 714, in __call__
[2m[WebServer] [22m    await self.middleware_stack(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/routing.py", line 734, in app
[2m[WebServer] [22m    await route.handle(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/routing.py", line 288, in handle
[2m[WebServer] [22m    await self.app(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/routing.py", line 76, in app
[2m[WebServer] [22m    await wrap_app_handling_exceptions(app, request)(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
[2m[WebServer] [22m    raise exc
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
[2m[WebServer] [22m    await app(scope, receive, sender)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/routing.py", line 73, in app
[2m[WebServer] [22m    response = await f(request)
[2m[WebServer] [22m               ^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/fastapi/routing.py", line 301, in app
[2m[WebServer] [22m    raw_response = await run_endpoint_function(
[2m[WebServer] [22m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<3 lines>...
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/fastapi/routing.py", line 212, in run_endpoint_function
[2m[WebServer] [22m    return await dependant.call(**values)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/routers/workflow_executions.py", line 74, in start_workflow_execution
[2m[WebServer] [22m    execution_id = await langgraph_workflow_engine.execute_workflow(workflow_id)
[2m[WebServer] [22m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/services/langgraph_workflow_engine.py", line 146, in execute_workflow
[2m[WebServer] [22m    await self._execute_workflow_internal(workflow, execution, db)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/services/langgraph_workflow_engine.py", line 214, in _execute_workflow_internal
[2m[WebServer] [22m    async for chunk in graph.astream(initial_state, config):
[2m[WebServer] [22m    ...<36 lines>...
[2m[WebServer] [22m            logger.warning(f"[LangGraphEngine] Received empty chunk #{chunk_count}")
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2732, in astream
[2m[WebServer] [22m    async for _ in runner.atick(
[2m[WebServer] [22m    ...<7 lines>...
[2m[WebServer] [22m            yield o
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/services/langgraph_workflow_engine.py", line 729, in agent_node
[2m[WebServer] [22m    created_messages = await runner.run_thread(db, thread)
[2m[WebServer] [22m                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/managers/agent_runner.py", line 137, in run_thread
[2m[WebServer] [22m    updated_messages = await self._runnable.ainvoke(original_msgs, config)
[2m[WebServer] [22m                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2850, in ainvoke
[2m[WebServer] [22m    async for chunk in self.astream(
[2m[WebServer] [22m    ...<13 lines>...
[2m[WebServer] [22m            chunks.append(chunk)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2732, in astream
[2m[WebServer] [22m    async for _ in runner.atick(
[2m[WebServer] [22m    ...<7 lines>...
[2m[WebServer] [22m            yield o
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 256, in agent_executor
[2m[WebServer] [22m    return _agent_executor_sync(messages, previous=previous)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 248, in _agent_executor_sync
[2m[WebServer] [22m    return asyncio.run(_agent_executor_async(messages, previous=previous))
[2m[WebServer] [22m           ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/runners.py", line 194, in run
[2m[WebServer] [22m    return runner.run(main)
[2m[WebServer] [22m           ~~~~~~~~~~^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/runners.py", line 118, in run
[2m[WebServer] [22m    return self._loop.run_until_complete(task)
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/base_events.py", line 720, in run_until_complete
[2m[WebServer] [22m    return future.result()
[2m[WebServer] [22m           ~~~~~~~~~~~~~^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 208, in _agent_executor_async
[2m[WebServer] [22m    llm_response = await _call_model_async(current_messages)
[2m[WebServer] [22m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 134, in _call_model_async
[2m[WebServer] [22m    return await asyncio.to_thread(_call_model_sync, messages)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/threads.py", line 25, in to_thread
[2m[WebServer] [22m    return await loop.run_in_executor(None, func_call)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/thread.py", line 59, in run
[2m[WebServer] [22m    result = self.fn(*self.args, **self.kwargs)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 127, in _call_model_sync
[2m[WebServer] [22m    return llm_with_tools.invoke(messages)
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/runnables/base.py", line 5416, in invoke
[2m[WebServer] [22m    return self.bound.invoke(
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        input,
[2m[WebServer] [22m        ^^^^^^
[2m[WebServer] [22m        self._merge_configs(config),
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^

[1A[2K[2m[WebServer] [22m^^^^^^^^^
[2m[WebServer] [22m        **{**self.kwargs, **kwargs},
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 369, in invoke
[2m[WebServer] [22m    self.generate_prompt(
[2m[WebServer] [22m    ~~~~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        [self._convert_input(input)],
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<6 lines>...
[2m[WebServer] [22m        **kwargs,
[2m[WebServer] [22m        ^^^^^^^^^
[2m[WebServer] [22m    ).generations[0][0],
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 946, in generate_prompt
[2m[WebServer] [22m    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
[2m[WebServer] [22m           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 765, in generate
[2m[WebServer] [22m    self._generate_with_cache(
[2m[WebServer] [22m    ~~~~~~~~~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        m,
[2m[WebServer] [22m        ^^
[2m[WebServer] [22m    ...<2 lines>...
[2m[WebServer] [22m        **kwargs,
[2m[WebServer] [22m        ^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 1011, in _generate_with_cache
[2m[WebServer] [22m    result = self._generate(
[2m[WebServer] [22m        messages, stop=stop, run_manager=run_manager, **kwargs
[2m[WebServer] [22m    )
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py", line 991, in _generate
[2m[WebServer] [22m    response = self.client.create(**payload)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_utils/_utils.py", line 287, in wrapper
[2m[WebServer] [22m    return func(*args, **kwargs)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py", line 925, in create
[2m[WebServer] [22m    return self._post(
[2m[WebServer] [22m           ~~~~~~~~~~^
[2m[WebServer] [22m        "/chat/completions",
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<43 lines>...
[2m[WebServer] [22m        stream_cls=Stream[ChatCompletionChunk],
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_base_client.py", line 1239, in post
[2m[WebServer] [22m    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
[2m[WebServer] [22m                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_base_client.py", line 1034, in request
[2m[WebServer] [22m    raise self._make_status_error_from_response(err.response) from None
[2m[WebServer] [22mopenai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `gpt-mock` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
[2m[WebServer] [22mDuring task with name 'agent_executor' and id '6ff4f630-2b91-0afe-11f6-a9a249d7bb7d'
[2m[WebServer] [22mDuring task with name 'agent-1' and id '6c09dcd7-6848-0e02-5fa7-6479bf954adc'

[1A[2K[2m[WebServer] [22mERROR - [AgentRunner] Exception during runnable.ainvoke: Error code: 404 - {'error': {'message': 'The model `gpt-mock` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
[2m[WebServer] [22mTraceback (most recent call last):
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/managers/agent_runner.py", line 137, in run_thread
[2m[WebServer] [22m    updated_messages = await self._runnable.ainvoke(original_msgs, config)
[2m[WebServer] [22m                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2850, in ainvoke
[2m[WebServer] [22m    async for chunk in self.astream(
[2m[WebServer] [22m    ...<13 lines>...
[2m[WebServer] [22m            chunks.append(chunk)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2732, in astream
[2m[WebServer] [22m    async for _ in runner.atick(
[2m[WebServer] [22m    ...<7 lines>...
[2m[WebServer] [22m            yield o
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 256, in agent_executor
[2m[WebServer] [22m    return _agent_executor_sync(messages, previous=previous)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 248, in _agent_executor_sync
[2m[WebServer] [22m    return asyncio.run(_agent_executor_async(messages, previous=previous))
[2m[WebServer] [22m           ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/runners.py", line 194, in run
[2m[WebServer] [22m    return runner.run(main)
[2m[WebServer] [22m           ~~~~~~~~~~^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/runners.py", line 118, in run
[2m[WebServer] [22m    return self._loop.run_until_complete(task)
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/base_events.py", line 720, in run_until_complete
[2m[WebServer] [22m    return future.result()
[2m[WebServer] [22m           ~~~~~~~~~~~~~^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 208, in _agent_executor_async
[2m[WebServer] [22m    llm_response = await _call_model_async(current_messages)
[2m[WebServer] [22m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 134, in _call_model_async
[2m[WebServer] [22m    return await asyncio.to_thread(_call_model_sync, messages)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/threads.py", line 25, in to_thread
[2m[WebServer] [22m    return await loop.run_in_executor(None, func_call)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/thread.py", line 59, in run
[2m[WebServer] [22m    result = self.fn(*self.args, **self.kwargs)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 127, in _call_model_sync
[2m[WebServer] [22m    return llm_with_tools.invoke(messages)
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/runnables/base.py", line 5416, in invoke
[2m[WebServer] [22m    return self.bound.invoke(
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        input,
[2m[WebServer] [22m        ^^^^^^
[2m[WebServer] [22m        self._merge_configs(config),
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m        **{**self.kwargs, **kwargs},
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 369, in invoke
[2m[WebServer] [22m    self.generate_prompt(
[2m[WebServer] [22m    ~~~~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        [self._convert_input(input)],
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<6 lines>...
[2m[WebServer] [22m        **kwargs,
[2m[WebServer] [22m        ^^^^^^^^^
[2m[WebServer] [22m    ).generations[0][0],
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 946, in generate_prompt
[2m[WebServer] [22m    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
[2m[WebServer] [22m           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 765, in generate
[2m[WebServer] [22m    self._generate_with_cache(
[2m[WebServer] [22m    ~~~~~~~~~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        m,
[2m[WebServer] [22m        ^^
[2m[WebServer] [22m    ...<2 lines>...
[2m[WebServer] [22m        **kwargs,
[2m[WebServer] [22m        ^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 1011, in _generate_with_cache
[2m[WebServer] [22m    result = self._generate(
[2m[WebServer] [22m        messages, stop=stop, run_manager=run_manager, **kwargs
[2m[WebServer] [22m    )
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py", line 991, in _generate
[2m[WebServer] [22m    response = self.client.create(**payload)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_utils/_utils.py", line 287, in wrapper
[2m[WebServer] [22m    return func(*args, **kwargs)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py", line 925, in create
[2m[WebServer] [22m    return self._post(
[2m[WebServer] [22m           ~~~~~~~~~~^
[2m[WebServer] [22m        "/chat/completions",
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<43 lines>...
[2m[WebServer] [22m        stream_cls=Stream[ChatCompletionChunk],
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_base_client.py", line 1239, in post
[2m[WebServer] [22m    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
[2m[WebServer] [22m                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_base_client.py", line 1034, in request
[2m[WebServer] [22m    raise self._make_status_error_from_response(err.response) from None
[2m[WebServer] [22mopenai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `gpt-mock` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
[2m[WebServer] [22mDuring task with name 'agent_executor' and id '69a614a1-b8c5-b4ee-63eb-55b49a22efa8'

[1A[2K[2m[WebServer] [22mERROR - [AgentNode] Exception in agent node agent-1 (agent_id=1): Error code: 404 - {'error': {'message': 'The model `gpt-mock` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
[2m[WebServer] [22mTraceback (most recent call last):
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/services/langgraph_workflow_engine.py", line 729, in agent_node
[2m[WebServer] [22m    created_messages = await runner.run_thread(db, thread)
[2m[WebServer] [22m                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/managers/agent_runner.py", line 137, in run_thread
[2m[WebServer] [22m    updated_messages = await self._runnable.ainvoke(original_msgs, config)
[2m[WebServer] [22m                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2850, in ainvoke
[2m[WebServer] [22m    async for chunk in self.astream(
[2m[WebServer] [22m    ...<13 lines>...
[2m[WebServer] [22m            chunks.append(chunk)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2732, in astream
[2m[WebServer] [22m    async for _ in runner.atick(
[2m[WebServer] [22m    ...<7 lines>...
[2m[WebServer] [22m            yield o
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 256, in agent_executor
[2m[WebServer] [22m    return _agent_executor_sync(messages, previous=previous)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 248, in _agent_executor_sync
[2m[WebServer] [22m    return asyncio.run(_agent_executor_async(messages, previous=previous))
[2m[WebServer] [22m           ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/runners.py", line 194, in run
[2m[WebServer] [22m    return runner.run(main)
[2m[WebServer] [22m           ~~~~~~~~~~^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/runners.py", line 118, in run
[2m[WebServer] [22m    return self._loop.run_until_complete(task)
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/base_events.py", line 720, in run_until_complete
[2m[WebServer] [22m    return future.result()
[2m[WebServer] [22m           ~~~~~~~~~~~~~^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 208, in _agent_executor_async
[2m[WebServer] [22m    llm_response = await _call_model_async(current_messages)
[2m[WebServer] [22m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 134, in _call_model_async
[2m[WebServer] [22m    return await asyncio.to_thread(_call_model_sync, messages)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/threads.py", line 25, in to_thread
[2m[WebServer] [22m    return await loop.run_in_executor(None, func_call)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/thread.py", line 59, in run
[2m[WebServer] [22m    result = self.fn(*self.args, **self.kwargs)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 127, in _call_model_sync
[2m[WebServer] [22m    return llm_with_tools.invoke(messages)
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/runnables/base.py", line 5416, in invoke
[2m[WebServer] [22m    return self.bound.invoke(
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        input,
[2m[WebServer] [22m        ^^^^^^
[2m[WebServer] [22m        self._merge_configs(config),
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m        **{**self.kwargs, **kwargs},
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 369, in invoke
[2m[WebServer] [22m    self.generate_prompt(
[2m[WebServer] [22m    ~~~~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        [self._convert_input(input)],
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<6 lines>...
[2m[WebServer] [22m        **kwargs,
[2m[WebServer] [22m        ^^^^^^^^^
[2m[WebServer] [22m    ).generations[0][0],
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 946, in generate_prompt
[2m[WebServer] [22m    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
[2m[WebServer] [22m           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 765, in generate
[2m[WebServer] [22m    self._generate_with_cache(
[2m[WebServer] [22m    ~~~~~~~~~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        m,
[2m[WebServer] [22m        ^^
[2m[WebServer] [22m    ...<2 lines>...
[2m[WebServer] [22m        **kwargs,
[2m[WebServer] [22m        ^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 1011, in _generate_with_cache
[2m[WebServer] [22m    result = self._generate(
[2m[WebServer] [22m        messages, stop=stop, run_manager=run_manager, **kwargs
[2m[WebServer] [22m    )
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py", line 991, in _generate
[2m[WebServer] [22m    response = self.client.create(**payload)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_utils/_utils.py", line 287, in wrapper
[2m[WebServer] [22m    return func(*args, **kwargs)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py", line 925, in create
[2m[WebServer] [22m    return self._post(
[2m[WebServer] [22m           ~~~~~~~~~~^
[2m[WebServer] [22m        "/chat/completions",
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<43 lines>...
[2m[WebServer] [22m        stream_cls=Stream[ChatCompletionChunk],
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_base_client.py", line 1239, in post
[2m[WebServer] [22m    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
[2m[WebServer] [22m                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_base_client.py", line 1034, in request
[2m[WebServer] [22m    raise self._make_status_error_from_response(err.response) from None
[2m[WebServer] [22mopenai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `gpt-mock` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
[2m[WebServer] [22mDuring task with name 'agent_executor' and id '69a614a1-b8c5-b4ee-63eb-55b49a22efa8'

[1A[2K[2m[WebServer] [22mERROR - [AgentNode] Updated node_state to 'failed' in DB

[1A[2K[2m[WebServer] [22mERROR - [AgentNode] Re-raising exception to fail workflow execution

[1A[2K[2m[WebServer] [22mERROR - [LangGraphEngine] Execution failed â€“ execution_id=1
[2m[WebServer] [22mTraceback (most recent call last):
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/services/langgraph_workflow_engine.py", line 146, in execute_workflow
[2m[WebServer] [22m    await self._execute_workflow_internal(workflow, execution, db)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/services/langgraph_workflow_engine.py", line 214, in _execute_workflow_internal
[2m[WebServer] [22m    async for chunk in graph.astream(initial_state, config):
[2m[WebServer] [22m    ...<36 lines>...
[2m[WebServer] [22m            logger.warning(f"[LangGraphEngine] Received empty chunk #{chunk_count}")
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2732, in astream
[2m[WebServer] [22m    async for _ in runner.atick(
[2m[WebServer] [22m    ...<7 lines>...
[2m[WebServer] [22m            yield o
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/services/langgraph_workflow_engine.py", line 729, in agent_node
[2m[WebServer] [22m    created_messages = await runner.run_thread(db, thread)
[2m[WebServer] [22m                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/managers/agent_runner.py", line 137, in run_thread
[2m[WebServer] [22m    updated_messages = await self._runnable.ainvoke(original_msgs, config)
[2m[WebServer] [22m                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2850, in ainvoke
[2m[WebServer] [22m    async for chunk in self.astream(
[2m[WebServer] [22m    ...<13 lines>...
[2m[WebServer] [22m            chunks.append(chunk)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2732, in astream
[2m[WebServer] [22m    async for _ in runner.atick(
[2m[WebServer] [22m    ...<7 lines>...
[2m[WebServer] [22m            yield o
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 256, in agent_executor
[2m[WebServer] [22m    return _agent_executor_sync(messages, previous=previous)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 248, in _agent_executor_sync
[2m[WebServer] [22m    return asyncio.run(_agent_executor_async(messages, previous=previous))
[2m[WebServer] [22m           ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/runners.py", line 194, in run
[2m[WebServer] [22m    return runner.run(main)
[2m[WebServer] [22m           ~~~~~~~~~~^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/runners.py", line 118, in run
[2m[WebServer] [22m    return self._loop.run_until_complete(task)
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/base_events.py", line 720, in run_until_complete
[2m[WebServer] [22m    return future.result()
[2m[WebServer] [22m           ~~~~~~~~~~~~~^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 208, in _agent_executor_async
[2m[WebServer] [22m    llm_response = await _call_model_async(current_messages)
[2m[WebServer] [22m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 134, in _call_model_async
[2m[WebServer] [22m    return await asyncio.to_thread(_call_model_sync, messages)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/threads.py", line 25, in to_thread
[2m[WebServer] [22m    return await loop.run_in_executor(None, func_call)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/thread.py", line 59, in run
[2m[WebServer] [22m    result = self.fn(*self.args, **self.kwargs)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 127, in _call_model_sync
[2m[WebServer] [22m    return llm_with_tools.invoke(messages)
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/runnables/base.py", line 5416, in invoke
[2m[WebServer] [22m    return self.bound.invoke(
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        input,
[2m[WebServer] [22m        ^^^^^^
[2m[WebServer] [22m        self._merge_configs(config),
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m        **{**self.kwargs, **kwargs},
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 369, in invoke
[2m[WebServer] [22m    self.generate_prompt(
[2m[WebServer] [22m    ~~~~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        [self._convert_input(input)],
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<6 lines>...
[2m[WebServer] [22m        **kwargs,
[2m[WebServer] [22m        ^^^^^^^^^
[2m[WebServer] [22m    ).generations[0][0],
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 946, in generate_prompt
[2m[WebServer] [22m    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
[2m[WebServer] [22m           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 765, in generate
[2m[WebServer] [22m    self._generate_with_cache(
[2m[WebServer] [22m    ~~~~~~~~~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        m,
[2m[WebServer] [22m        ^^
[2m[WebServer] [22m    ...<2 lines>...
[2m[WebServer] [22m        **kwargs,
[2m[WebServer] [22m        ^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 1011, in _generate_with_cache
[2m[WebServer] [22m    result = self._generate(
[2m[WebServer] [22m        messages, stop=stop, run_manager=run_manager, **kwargs
[2m[WebServer] [22m    )
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py", line 991, in _generate
[2m[WebServer] [22m    response = self.client.create(**payload)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_utils/_utils.py", line 287, in wrapper
[2m[WebServer] [22m    return func(*args, **kwargs)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py", line 925, in create
[2m[WebServer] [22m    return self._post(
[2m[WebServer] [22m           ~~~~~~~~~~^
[2m[WebServer] [22m        "/chat/completions",
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<43 lines>...
[2m[WebServer] [22m        stream_cls=Stream[ChatCompletionChunk],
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_base_client.py", line 1239, in post
[2m[WebServer] [22m    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
[2m[WebServer] [22m                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_base_client.py", line 1034, in request
[2m[WebServer] [22m    raise self._make_status_error_from_response(err.response) from None
[2m[WebServer] [22mopenai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `gpt-mock` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
[2m[WebServer] [22mDuring task with name 'agent_executor' and id '69a614a1-b8c5-b4ee-63eb-55b49a22efa8'
[2m[WebServer] [22mDuring task with name 'agent-1' and id '2b5b6b3f-e04b-e1e9-e48e-36af28e847f9'

[1A[2K[2m[WebServer] [22mERROR - Unhandled exception: Error code: 404 - {'error': {'message': 'The model `gpt-mock` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
[2m[WebServer] [22mTraceback (most recent call last):
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/middleware/errors.py", line 165, in __call__
[2m[WebServer] [22m    await self.app(scope, receive, _send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/middleware/worker_db.py", line 101, in __call__
[2m[WebServer] [22m    await self.app(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/middleware/cors.py", line 85, in __call__
[2m[WebServer] [22m    await self.app(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/middleware/exceptions.py", line 62, in __call__
[2m[WebServer] [22m    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
[2m[WebServer] [22m    raise exc
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
[2m[WebServer] [22m    await app(scope, receive, sender)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/routing.py", line 714, in __call__
[2m[WebServer] [22m    await self.middleware_stack(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/routing.py", line 734, in app
[2m[WebServer] [22m    await route.handle(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/routing.py", line 288, in handle
[2m[WebServer] [22m    await self.app(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/routing.py", line 76, in app
[2m[WebServer] [22m    await wrap_app_handling_exceptions(app, request)(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
[2m[WebServer] [22m    raise exc
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
[2m[WebServer] [22m    await app(scope, receive, sender)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/routing.py", line 73, in app
[2m[WebServer] [22m    response = await f(request)
[2m[WebServer] [22m               ^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/fastapi/routing.py", line 301, in app
[2m[WebServer] [22m    raw_response = await run_endpoint_function(
[2m[WebServer] [22m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<3 lines>...
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/fastapi/routing.py", line 212, in run_endpoint_function
[2m[WebServer] [22m    return await dependant.call(**values)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/routers/workflow_executions.py", line 74, in start_workflow_execution
[2m[WebServer] [22m    execution_id = await langgraph_workflow_engine.execute_workflow(workflow_id)
[2m[WebServer] [22m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/services/langgraph_workflow_engine.py", line 146, in execute_workflow
[2m[WebServer] [22m    await self._execute_workflow_internal(workflow, execution, db)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/services/langgraph_workflow_engine.py", line 214, in _execute_workflow_internal
[2m[WebServer] [22m    async for chunk in graph.astream(initial_state, config):
[2m[WebServer] [22m    ...<36 lines>...
[2m[WebServer] [22m            logger.warning(f"[LangGraphEngine] Received empty chunk #{chunk_count}")
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2732, in astream
[2m[WebServer] [22m    async for _ in runner.atick(
[2m[WebServer] [22m    ...<7 lines>...
[2m[WebServer] [22m            yield o
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/services/langgraph_workflow_engine.py", line 729, in agent_node
[2m[WebServer] [22m    created_messages = await runner.run_thread(db, thread)
[2m[WebServer] [22m                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/managers/agent_runner.py", line 137, in run_thread
[2m[WebServer] [22m    updated_messages = await self._runnable.ainvoke(original_msgs, config)
[2m[WebServer] [22m                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2850, in ainvoke
[2m[WebServer] [22m    async for chunk in self.astream(
[2m[WebServer] [22m    ...<13 lines>...
[2m[WebServer] [22m            chunks.append(chunk)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2732, in astream
[2m[WebServer] [22m    async for _ in runner.atick(
[2m[WebServer] [22m    ...<7 lines>...
[2m[WebServer] [22m            yield o
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 256, in agent_executor
[2m[WebServer] [22m    return _agent_executor_sync(messages, previous=previous)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 248, in _agent_executor_sync
[2m[WebServer] [22m    return asyncio.run(_agent_executor_async(messages, previous=previous))
[2m[WebServer] [22m           ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/runners.py", line 194, in run
[2m[WebServer] [22m    return runner.run(main)
[2m[WebServer] [22m           ~~~~~~~~~~^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/runners.py", line 118, in run
[2m[WebServer] [22m    return self._loop.run_until_complete(task)
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/base_events.py", line 720, in run_until_complete
[2m[WebServer] [22m    return future.result()
[2m[WebServer] [22m           ~~~~~~~~~~~~~^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 208, in _agent_executor_async
[2m[WebServer] [22m    llm_response = await _call_model_async(current_messages)
[2m[WebServer] [22m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 134, in _call_model_async
[2m[WebServer] [22m    return await asyncio.to_thread(_call_model_sync, messages)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/threads.py", line 25, in to_thread
[2m[WebServer] [22m    return await loop.run_in_executor(None, func_call)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/thread.py", line 59, in run
[2m[WebServer] [22m    result = self.fn(*self.args, **self.kwargs)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 127, in _call_model_sync
[2m[WebServer] [22m    return llm_with_tools.invoke(messages)
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/runnables/base.py", line 5416, in invoke
[2m[WebServer] [22m    return self.bound.invoke(
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        input,
[2m[WebServer] [22m        ^^^^^^
[2m[WebServer] [22m        self._merge_configs(config),
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m        **{**self.kwargs, **kwargs},
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 369, in invoke
[2m[WebServer] [22m    self.generate_prompt(
[2m[WebServer] [22m    ~~~~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        [self._convert_input(input)],
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<6 lines>...
[2m[WebServer] [22m        **kwargs,
[2m[WebServer] [22m        ^^^^^^^^^
[2m[WebServer] [22m    ).generations[0][0],
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 946, in generate_prompt
[2m[WebServer] [22m    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
[2m[WebServer] [22m           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 765, 

[1A[2K[2m[WebServer] [22min generate
[2m[WebServer] [22m    self._generate_with_cache(
[2m[WebServer] [22m    ~~~~~~~~~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        m,
[2m[WebServer] [22m        ^^
[2m[WebServer] [22m    ...<2 lines>...
[2m[WebServer] [22m        **kwargs,
[2m[WebServer] [22m        ^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 1011, in _generate_with_cache
[2m[WebServer] [22m    result = self._generate(
[2m[WebServer] [22m        messages, stop=stop, run_manager=run_manager, **kwargs
[2m[WebServer] [22m    )
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py", line 991, in _generate
[2m[WebServer] [22m    response = self.client.create(**payload)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_utils/_utils.py", line 287, in wrapper
[2m[WebServer] [22m    return func(*args, **kwargs)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py", line 925, in create
[2m[WebServer] [22m    return self._post(
[2m[WebServer] [22m           ~~~~~~~~~~^
[2m[WebServer] [22m        "/chat/completions",
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<43 lines>...
[2m[WebServer] [22m        stream_cls=Stream[ChatCompletionChunk],
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_base_client.py", line 1239, in post
[2m[WebServer] [22m    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
[2m[WebServer] [22m                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_base_client.py", line 1034, in request
[2m[WebServer] [22m    raise self._make_status_error_from_response(err.response) from None
[2m[WebServer] [22mopenai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `gpt-mock` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
[2m[WebServer] [22mDuring task with name 'agent_executor' and id '69a614a1-b8c5-b4ee-63eb-55b49a22efa8'
[2m[WebServer] [22mDuring task with name 'agent-1' and id '2b5b6b3f-e04b-e1e9-e48e-36af28e847f9'

[1A[2KâŒ User 1 execution failed: [33m500[39m

[1A[2KğŸ“Š Successful workflow executions: [33m0[39m / [33m3[39m

[1A[2KğŸ“Š Concurrent execution start time: [33m1113[39m ms

[1A[2KğŸ“Š Test 3: Monitoring concurrent executions...

[1A[2K[2m[WebServer] [22mERROR:    Exception in ASGI application
[2m[WebServer] [22mTraceback (most recent call last):
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/uvicorn/protocols/http/h11_impl.py", line 408, in run_asgi
[2m[WebServer] [22m    result = await app(  # type: ignore[func-returns-value]
[2m[WebServer] [22m             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m        self.scope, self.receive, self.send
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/uvicorn/middleware/proxy_headers.py", line 84, in __call__
[2m[WebServer] [22m    return await self.app(scope, receive, send)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/fastapi/applications.py", line 1054, in __call__
[2m[WebServer] [22m    await super().__call__(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/applications.py", line 112, in __call__
[2m[WebServer] [22m    await self.middleware_stack(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/middleware/errors.py", line 187, in __call__
[2m[WebServer] [22m    raise exc
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/middleware/errors.py", line 165, in __call__
[2m[WebServer] [22m    await self.app(scope, receive, _send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/middleware/worker_db.py", line 101, in __call__
[2m[WebServer] [22m    await self.app(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/middleware/cors.py", line 85, in __call__
[2m[WebServer] [22m    await self.app(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/middleware/exceptions.py", line 62, in __call__
[2m[WebServer] [22m    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
[2m[WebServer] [22m    raise exc
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
[2m[WebServer] [22m    await app(scope, receive, sender)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/routing.py", line 714, in __call__
[2m[WebServer] [22m    await self.middleware_stack(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/routing.py", line 734, in app
[2m[WebServer] [22m    await route.handle(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/routing.py", line 288, in handle
[2m[WebServer] [22m    await self.app(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/routing.py", line 76, in app
[2m[WebServer] [22m    await wrap_app_handling_exceptions(app, request)(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
[2m[WebServer] [22m    raise exc
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
[2m[WebServer] [22m    await app(scope, receive, sender)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/routing.py", line 73, in app
[2m[WebServer] [22m    response = await f(request)
[2m[WebServer] [22m               ^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/fastapi/routing.py", line 301, in app
[2m[WebServer] [22m    raw_response = await run_endpoint_function(
[2m[WebServer] [22m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<3 lines>...
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/fastapi/routing.py", line 212, in run_endpoint_function
[2m[WebServer] [22m    return await dependant.call(**values)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/routers/workflow_executions.py", line 74, in start_workflow_execution
[2m[WebServer] [22m    execution_id = await langgraph_workflow_engine.execute_workflow(workflow_id)
[2m[WebServer] [22m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/services/langgraph_workflow_engine.py", line 146, in execute_workflow
[2m[WebServer] [22m    await self._execute_workflow_internal(workflow, execution, db)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/services/langgraph_workflow_engine.py", line 214, in _execute_workflow_internal
[2m[WebServer] [22m    async for chunk in graph.astream(initial_state, config):
[2m[WebServer] [22m    ...<36 lines>...
[2m[WebServer] [22m            logger.warning(f"[LangGraphEngine] Received empty chunk #{chunk_count}")
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2732, in astream
[2m[WebServer] [22m    async for _ in runner.atick(
[2m[WebServer] [22m    ...<7 lines>...
[2m[WebServer] [22m            yield o
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/services/langgraph_workflow_engine.py", line 729, in agent_node
[2m[WebServer] [22m    created_messages = await runner.run_thread(db, thread)
[2m[WebServer] [22m                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/managers/agent_runner.py", line 137, in run_thread
[2m[WebServer] [22m    updated_messages = await self._runnable.ainvoke(original_msgs, config)
[2m[WebServer] [22m                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2850, in ainvoke
[2m[WebServer] [22m    async for chunk in self.astream(
[2m[WebServer] [22m    ...<13 lines>...
[2m[WebServer] [22m            chunks.append(chunk)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2732, in astream
[2m[WebServer] [22m    async for _ in runner.atick(
[2m[WebServer] [22m    ...<7 lines>...
[2m[WebServer] [22m            yield o
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 256, in agent_executor
[2m[WebServer] [22m    return _agent_executor_sync(messages, previous=previous)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 248, in _agent_executor_sync
[2m[WebServer] [22m    return asyncio.run(_agent_executor_async(messages, previous=previous))
[2m[WebServer] [22m           ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/runners.py", line 194, in run
[2m[WebServer] [22m    return runner.run(main)
[2m[WebServer] [22m           ~~~~~~~~~~^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/runners.py", line 118, in run
[2m[WebServer] [22m    return self._loop.run_until_complete(task)
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/base_events.py", line 720, in run_until_complete
[2m[WebServer] [22m    return future.result()
[2m[WebServer] [22m           ~~~~~~~~~~~~~^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 208, in _agent_executor_async
[2m[WebServer] [22m    llm_response = await _call_model_async(current_messages)
[2m[WebServer] [22m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 134, in _call_model_async
[2m[WebServer] [22m    return await asyncio.to_thread(_call_model_sync, messages)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/threads.py", line 25, in to_thread
[2m[WebServer] [22m    return await loop.run_in_executor(None, func_call)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/thread.py", line 59, in run
[2m[WebServer] [22m    result = self.fn(*self.args, **self.kwargs)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 127, in _call_model_sync
[2m[WebServer] [22m    return llm_with_tools.invoke(messages)
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/runnables/base.py", line 5416, in invoke
[2m[WebServer] [22m    return self.bound.invoke(
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        input,
[2m[WebServer] [22m        ^^^^^^
[2m[WebServer] [22m        self._merge_configs(config),
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^

[1A[2K[2m[WebServer] [22m^^^^^^^^^
[2m[WebServer] [22m        **{**self.kwargs, **kwargs},
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 369, in invoke
[2m[WebServer] [22m    self.generate_prompt(
[2m[WebServer] [22m    ~~~~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        [self._convert_input(input)],
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<6 lines>...
[2m[WebServer] [22m        **kwargs,
[2m[WebServer] [22m        ^^^^^^^^^
[2m[WebServer] [22m    ).generations[0][0],
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 946, in generate_prompt
[2m[WebServer] [22m    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
[2m[WebServer] [22m           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 765, in generate
[2m[WebServer] [22m    self._generate_with_cache(
[2m[WebServer] [22m    ~~~~~~~~~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        m,
[2m[WebServer] [22m        ^^
[2m[WebServer] [22m    ...<2 lines>...
[2m[WebServer] [22m        **kwargs,
[2m[WebServer] [22m        ^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 1011, in _generate_with_cache
[2m[WebServer] [22m    result = self._generate(
[2m[WebServer] [22m        messages, stop=stop, run_manager=run_manager, **kwargs
[2m[WebServer] [22m    )
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py", line 991, in _generate
[2m[WebServer] [22m    response = self.client.create(**payload)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_utils/_utils.py", line 287, in wrapper
[2m[WebServer] [22m    return func(*args, **kwargs)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py", line 925, in create
[2m[WebServer] [22m    return self._post(
[2m[WebServer] [22m           ~~~~~~~~~~^
[2m[WebServer] [22m        "/chat/completions",
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<43 lines>...
[2m[WebServer] [22m        stream_cls=Stream[ChatCompletionChunk],
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_base_client.py", line 1239, in post
[2m[WebServer] [22m    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
[2m[WebServer] [22m                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_base_client.py", line 1034, in request
[2m[WebServer] [22m    raise self._make_status_error_from_response(err.response) from None
[2m[WebServer] [22mopenai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `gpt-mock` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
[2m[WebServer] [22mDuring task with name 'agent_executor' and id '69a614a1-b8c5-b4ee-63eb-55b49a22efa8'
[2m[WebServer] [22mDuring task with name 'agent-1' and id '2b5b6b3f-e04b-e1e9-e48e-36af28e847f9'

[1A[2Kâœ… Concurrent workflow execution test completed

[1A[2K[21/36] tests/multi_user_concurrency.spec.ts:351:7 â€º Multi-User and Concurrency â€º WebSocket message broadcasting and isolation
[1A[2Ktests/multi_user_concurrency.spec.ts:351:7 â€º Multi-User and Concurrency â€º WebSocket message broadcasting and isolation
ğŸš€ Starting WebSocket broadcasting test...

[1A[2KğŸ“Š Created 2 WebSocket monitoring sessions

[1A[2KğŸ“Š Test 1: Connecting users and monitoring initial messages...

[1A[2Ktests/error_handling_edge_cases.spec.ts:261:7 â€º Error Handling and Edge Cases â€º UI error state handling
ğŸ“Š Invalid route page title: AI Agent Platform

[1A[2KğŸ“Š Error content present: [33mfalse[39m

[1A[2KğŸ“Š Test 3: JavaScript error monitoring

[1A[2Ktests/multi_user_concurrency.spec.ts:351:7 â€º Multi-User and Concurrency â€º WebSocket message broadcasting and isolation
ğŸ“Š User 0 WebSocket connected: ws://localhost:8001/api/ws

[1A[2KğŸ“Š User 0 received: user_update

[1A[2KğŸ“Š User 1 WebSocket connected: ws://localhost:8001/api/ws

[1A[2KğŸ“Š User 1 received: user_update

[1A[2KğŸ“Š Test 2: Testing cross-session message broadcasting...

[1A[2KğŸ“Š Created agent in primary session: [33m1[39m

[1A[2Ktests/error_handling_edge_cases.spec.ts:261:7 â€º Error Handling and Edge Cases â€º UI error state handling
ğŸ“Š JavaScript errors detected: [33m0[39m

[1A[2Kâœ… No JavaScript errors during navigation

[1A[2Kâœ… UI error state test completed

[1A[2K[22/36] tests/multi_user_concurrency.spec.ts:511:7 â€º Multi-User and Concurrency â€º Resource sharing and conflict resolution
[1A[2Ktests/multi_user_concurrency.spec.ts:511:7 â€º Multi-User and Concurrency â€º Resource sharing and conflict resolution
ğŸš€ Starting resource sharing and conflict resolution test...

[1A[2KğŸ“Š Created 2 sessions for conflict testing

[1A[2KğŸ“Š Test 1: Testing concurrent modifications...

[1A[2KğŸ“Š User 1 created agent: [33m1[39m (340ms)

[1A[2KğŸ“Š User 0 created agent: [33m1[39m (360ms)

[1A[2KğŸ“Š Successful concurrent operations: [33m2[39m / [33m2[39m

[1A[2KğŸ“Š Response time range: [33m340[39m ms - [33m360[39m ms

[1A[2KğŸ“Š Average response time: [33m350[39m ms

[1A[2Kâœ… Concurrent operations have similar response times

[1A[2KğŸ“Š Test 2: Verifying database consistency...

[1A[2KğŸ“Š User 0 sees 1 agents

[1A[2KğŸ“Š User 1 sees 1 agents

[1A[2KğŸ“Š Test 3: Testing resource contention...

[1A[2KğŸ“Š User 0 created workflow referencing shared agent: [33m1[39m

[1A[2KğŸ“Š User 1 created workflow referencing shared agent: [33m1[39m

[1A[2KğŸ“Š Successful resource sharing operations: [33m2[39m / [33m2[39m

[1A[2Kâœ… Resource sharing handles concurrent access well

[1A[2Kâœ… Resource sharing and conflict resolution test completed

[1A[2K[23/36] tests/multi_user_concurrency.spec.ts:666:7 â€º Multi-User and Concurrency â€º Session management and cleanup
[1A[2Ktests/multi_user_concurrency.spec.ts:666:7 â€º Multi-User and Concurrency â€º Session management and cleanup
ğŸš€ Starting session management test...

[1A[2KğŸ“Š Test 1: Testing session lifecycle...

[1A[2Ktests/multi_user_concurrency.spec.ts:351:7 â€º Multi-User and Concurrency â€º WebSocket message broadcasting and isolation
ğŸ“Š User 0 received 1 agent-related messages

[1A[2Kâœ… User 0 received WebSocket notifications

[1A[2KğŸ“Š User 1 received 1 agent-related messages

[1A[2Kâœ… User 1 received WebSocket notifications

[1A[2KğŸ“Š Test 3: Testing session isolation in WebSocket messages...

[1A[2KğŸ“Š Primary session message types: []

[1A[2KğŸ“Š Secondary session message types: []

[1A[2KğŸ“Š Cross-session messages in secondary: [33m0[39m

[1A[2Kâœ… WebSocket messages properly isolated between sessions

[1A[2KğŸ“Š Test 4: Testing high-frequency message handling...

[1A[2KğŸ“Š Rapid operations completed: [33m5[39m / [33m5[39m

[1A[2KğŸ“Š Rapid operations time: [33m320[39m ms

[1A[2Ktests/multi_user_concurrency.spec.ts:666:7 â€º Multi-User and Concurrency â€º Session management and cleanup
ğŸ“Š Created agent in session 1: [33m1[39m

[1A[2KğŸ“Š Closed session 1

[1A[2KğŸ“Š Test 2: Testing data persistence after session closure...

[1A[2KğŸ“Š Agent persisted after session closure: [33mtrue[39m

[1A[2Kâœ… Data persists correctly after session closure

[1A[2KğŸ“Š Test 3: Verifying session isolation...

[1A[2KğŸ“Š Created agent in session 2: [33m1[39m

[1A[2KğŸ“Š Session 2 sees session 1 data: [33mtrue[39m

[1A[2KğŸ“Š Session 2 sees own data: [33mtrue[39m

[1A[2KğŸ“Š Sessions share data (may be intended behavior)

[1A[2KğŸ“Š Test 4: Testing cleanup mechanisms...

[1A[2KğŸ“Š Created temporary agent: [33m1[39m

[1A[2KğŸ“Š Cleanup verification completed (manual inspection may be needed)

[1A[2Kâœ… Session management test completed

[1A[2K[24/36] tests/performance_load_testing.spec.ts:18:7 â€º Performance and Load Testing â€º UI responsiveness benchmarking
[1A[2Ktests/performance_load_testing.spec.ts:18:7 â€º Performance and Load Testing â€º UI responsiveness benchmarking
ğŸš€ Starting UI responsiveness test...

[1A[2KğŸ“Š Worker ID: 0

[1A[2KğŸ“Š Test 1: Page load performance...

[1A[2Ktests/multi_user_concurrency.spec.ts:351:7 â€º Multi-User and Concurrency â€º WebSocket message broadcasting and isolation
ğŸ“Š User 0 received 0 messages during rapid operations

[1A[2KğŸ“Š User 1 received 0 messages during rapid operations

[1A[2Kâœ… WebSocket broadcasting test completed

[1A[2K[25/36] tests/performance_load_testing.spec.ts:94:7 â€º Performance and Load Testing â€º API response time benchmarking
[1A[2Ktests/performance_load_testing.spec.ts:94:7 â€º Performance and Load Testing â€º API response time benchmarking
ğŸš€ Starting API performance test...

[1A[2KğŸ“Š Test 1: Single API request performance...

[1A[2KğŸ“Š GET /api/agents response time: [33m4[39m ms

[1A[2KğŸ“Š GET /api/agents status: [33m200[39m

[1A[2Kâœ… GET /api/agents is very fast (< 200ms)

[1A[2KğŸ“Š GET /api/workflows response time: [33m3[39m ms

[1A[2KğŸ“Š GET /api/workflows status: [33m200[39m

[1A[2Kâœ… GET /api/workflows is very fast (< 200ms)

[1A[2KğŸ“Š GET /api/users/me response time: [33m2[39m ms

[1A[2KğŸ“Š GET /api/users/me status: [33m200[39m

[1A[2Kâœ… GET /api/users/me is very fast (< 200ms)

[1A[2KğŸ“Š Test 2: Batch API request performance...

[1A[2Ktests/performance_load_testing.spec.ts:18:7 â€º Performance and Load Testing â€º UI responsiveness benchmarking
ğŸ“Š Page load time: [33m1116[39m ms

[1A[2Kâœ… Page loads within acceptable time (< 3s)

[1A[2KğŸ“Š Test 2: Navigation performance...

[1A[2Ktests/performance_load_testing.spec.ts:94:7 â€º Performance and Load Testing â€º API response time benchmarking
ğŸ“Š Batch requests completed: [33m10[39m / [33m10[39m

[1A[2KğŸ“Š Batch total time: [33m326[39m ms

[1A[2KğŸ“Š Average per request: [33m33[39m ms

[1A[2Kâœ… Batch API performance is good

[1A[2Kâœ… API performance test completed

[1A[2K[26/36] tests/performance_load_testing.spec.ts:161:7 â€º Performance and Load Testing â€º Database performance with large datasets
[1A[2Ktests/performance_load_testing.spec.ts:161:7 â€º Performance and Load Testing â€º Database performance with large datasets
ğŸš€ Starting database performance test...

[1A[2KğŸ“Š Test 1: Creating large dataset...

[1A[2Ktests/performance_load_testing.spec.ts:18:7 â€º Performance and Load Testing â€º UI responsiveness benchmarking
ğŸ“Š Dashboard navigation time: [33m153[39m ms

[1A[2Kâœ… Dashboard navigation is responsive (< 500ms)

[1A[2KğŸ“Š Canvas navigation time: [33m193[39m ms

[1A[2Kâœ… Canvas navigation is responsive (< 500ms)

[1A[2KğŸ“Š Test 3: UI interaction responsiveness...

[1A[2KğŸ“Š Interactive elements found: [33m23[39m

[1A[2Ktests/performance_load_testing.spec.ts:161:7 â€º Performance and Load Testing â€º Database performance with large datasets
ğŸ“Š Agents created successfully: [33m50[39m / [33m50[39m

[1A[2KğŸ“Š Creation time: [33m624[39m ms

[1A[2KğŸ“Š Average creation time: [33m12[39m ms per agent

[1A[2Kâœ… Large dataset creation successful

[1A[2KğŸ“Š Test 2: Query performance with large dataset...

[1A[2KğŸ“Š Total agents retrieved: [33m68[39m

[1A[2KğŸ“Š Query time: [33m7[39m ms

[1A[2Kâœ… Large dataset query performance is good (< 1s)

[1A[2KğŸ“Š Test 3: Testing pagination performance...

[1A[2KğŸ“Š Pagination query status: [33m200[39m

[1A[2KğŸ“Š Pagination query time: [33m4[39m ms

[1A[2KğŸ“Š Paginated results returned: [33m10[39m

[1A[2Kâœ… Pagination performance is excellent

[1A[2Kâœ… Database performance test completed

[1A[2K[27/36] tests/performance_load_testing.spec.ts:256:7 â€º Performance and Load Testing â€º Memory usage and resource monitoring
[1A[2Ktests/performance_load_testing.spec.ts:256:7 â€º Performance and Load Testing â€º Memory usage and resource monitoring
ğŸš€ Starting memory usage test...

[1A[2KğŸ“Š Test 1: Establishing memory baseline...

[1A[2KğŸ“Š Initial memory usage: { used: [33m10000000[39m, total: [33m11900000[39m, limit: [33m3760000000[39m }

[1A[2KğŸ“Š Page timing: { domContentLoaded: [33m523[39m, fullyLoaded: [33m685[39m }

[1A[2KğŸ“Š Test 2: Memory usage during intensive operations...

[1A[2KğŸ“Š Memory usage after operations: { used: [33m10000000[39m, total: [33m11900000[39m }

[1A[2KğŸ“Š Memory increase: [33m0[39m %

[1A[2Kâœ… Memory usage increase is reasonable

[1A[2KğŸ“Š Test 3: Memory leak detection...

[1A[2Ktests/performance_load_testing.spec.ts:18:7 â€º Performance and Load Testing â€º UI responsiveness benchmarking
ğŸ“Š Hover test skipped (element not interactive)

[1A[2Kâœ… UI responsiveness test completed

[1A[2K[28/36] tests/performance_load_testing.spec.ts:371:7 â€º Performance and Load Testing â€º Concurrent user simulation
[1A[2Ktests/performance_load_testing.spec.ts:371:7 â€º Performance and Load Testing â€º Concurrent user simulation
ğŸš€ Starting concurrent user simulation...

[1A[2KğŸ“Š Test 1: Simulating 5 concurrent users...

[1A[2Ktests/performance_load_testing.spec.ts:256:7 â€º Performance and Load Testing â€º Memory usage and resource monitoring
ğŸ“Š Memory usage after GC: { used: [33m10000000[39m, total: [33m11900000[39m }

[1A[2KğŸ“Š Memory freed by GC: [33m0[39m bytes

[1A[2Kâœ… Memory usage test completed

[1A[2K[29/36] tests/performance_load_testing.spec.ts:444:7 â€º Performance and Load Testing â€º Large workflow performance
[1A[2Ktests/performance_load_testing.spec.ts:444:7 â€º Performance and Load Testing â€º Large workflow performance
ğŸš€ Starting large workflow performance test...

[1A[2KğŸ“Š Test 1: Creating agents for large workflow...

[1A[2KğŸ“Š Created agent 0: [33m79[39m

[1A[2KğŸ“Š Created agent 1: [33m80[39m

[1A[2KğŸ“Š Created agent 2: [33m81[39m

[1A[2KğŸ“Š Created agent 3: [33m82[39m

[1A[2KğŸ“Š Created agent 4: [33m83[39m

[1A[2KğŸ“Š Created agent 5: [33m84[39m

[1A[2KğŸ“Š Created agent 6: [33m85[39m

[1A[2KğŸ“Š Created agent 7: [33m86[39m

[1A[2KğŸ“Š Created agent 8: [33m87[39m

[1A[2KğŸ“Š Created agent 9: [33m88[39m

[1A[2KğŸ“Š Total agents for large workflow: [33m10[39m

[1A[2KğŸ“Š Test 2: Creating large workflow...

[1A[2KğŸ“Š Large workflow creation status: [33m200[39m

[1A[2KğŸ“Š Large workflow creation time: [33m308[39m ms

[1A[2KğŸ“Š Workflow nodes: [33m16[39m

[1A[2KğŸ“Š Workflow connections: [33m16[39m

[1A[2KğŸ“Š Large workflow created with ID: [33m3[39m

[1A[2KğŸ“Š Large workflow retrieval time: [33m1[39m ms

[1A[2Kâœ… Large workflow performance is acceptable

[1A[2Kâœ… Large workflow performance test completed

[1A[2K[30/36] tests/realtime_websocket_monitoring.spec.ts:15:7 â€º Real-time WebSocket Monitoring â€º WebSocket event monitoring and real-time updates
[1A[2Ktests/realtime_websocket_monitoring.spec.ts:15:7 â€º Real-time WebSocket Monitoring â€º WebSocket event monitoring and real-time updates
ğŸš€ Starting WebSocket monitoring test...

[1A[2KğŸ“Š Worker ID: 0

[1A[2KğŸ“Š Step 1: Connecting to application...

[1A[2Ktests/performance_load_testing.spec.ts:371:7 â€º Performance and Load Testing â€º Concurrent user simulation
ğŸ“Š User 4 agent creation: success

[1A[2KğŸ“Š User 2 agent creation: success

[1A[2KğŸ“Š User 0 agent creation: success

[1A[2KğŸ“Š User 1 agent creation: success

[1A[2KğŸ“Š User 3 agent creation: success

[1A[2KğŸ“Š Concurrent users completed successfully: [33m5[39m / [33m5[39m

[1A[2KğŸ“Š Total simulation time: [33m3100[39m ms

[1A[2KğŸ“Š Average time per user: [33m620[39m ms

[1A[2Kâœ… Concurrent user handling is robust

[1A[2Kâœ… Concurrent user simulation completed

[1A[2K[31/36] tests/tool_palette_node_connections.spec.ts:18:7 â€º Tool Palette and Node Connections â€º Tool palette discovery and cataloging
[1A[2Ktests/tool_palette_node_connections.spec.ts:18:7 â€º Tool Palette and Node Connections â€º Tool palette discovery and cataloging
ğŸš€ Starting tool palette discovery test...

[1A[2KğŸ“Š Worker ID: 0

[1A[2Ktests/realtime_websocket_monitoring.spec.ts:15:7 â€º Real-time WebSocket Monitoring â€º WebSocket event monitoring and real-time updates
ğŸ“Š Step 2: Monitoring WebSocket activity...

[1A[2KğŸ“Š Step 3: Creating agent to trigger updates...

[1A[2Kâœ… Agent created, waiting for WebSocket updates...

[1A[2KğŸ“Š Step 4: Navigating to trigger more WebSocket events...

[1A[2Ktests/tool_palette_node_connections.spec.ts:18:7 â€º Tool Palette and Node Connections â€º Tool palette discovery and cataloging
ğŸ“Š Test 1: Locating tool palette...

[1A[2KğŸ“Š Tool palette visible: [33mfalse[39m

[1A[2Kâš ï¸  Tool palette not visible - checking alternative locations...

[1A[2KğŸ“Š Alternative tool containers found: [33m0[39m

[1A[2Kâœ… Tool palette discovery completed

[1A[2K[32/36] tests/tool_palette_node_connections.spec.ts:84:7 â€º Tool Palette and Node Connections â€º Tool drag-and-drop from palette to canvas
[1A[2Ktests/tool_palette_node_connections.spec.ts:84:7 â€º Tool Palette and Node Connections â€º Tool drag-and-drop from palette to canvas
ğŸš€ Starting tool drag-and-drop test...

[1A[2KğŸ“Š Created test agent: [33m90[39m

[1A[2Ktests/realtime_websocket_monitoring.spec.ts:15:7 â€º Real-time WebSocket Monitoring â€º WebSocket event monitoring and real-time updates
ğŸ“Š Step 5: Analyzing WebSocket messages...

[1A[2KğŸ“Š Total WebSocket messages received: [33m0[39m

[1A[2Kâš ï¸  No WebSocket messages received - may need connection investigation

[1A[2KğŸ“Š Step 6: Testing real-time UI updates...

[1A[2KğŸ“Š Agent visible in dashboard: [33mfalse[39m

[1A[2KğŸ“Š Step 7: Checking for real-time status indicators...

[1A[2KğŸ“Š Status indicators found: [33m0[39m

[1A[2KğŸ“Š Online indicators found: [33m0[39m

[1A[2KğŸ“Š Activity indicators found: [33m0[39m

[1A[2Kâœ… WebSocket monitoring test completed

[1A[2KğŸ“Š Summary: Real-time WebSocket communication validated

[1A[2K[33/36] tests/tool_palette_node_connections.spec.ts:180:7 â€º Tool Palette and Node Connections â€º Node connection handle detection and interaction
[1A[2Ktests/tool_palette_node_connections.spec.ts:180:7 â€º Tool Palette and Node Connections â€º Node connection handle detection and interaction
ğŸš€ Starting node connection test...

[1A[2Ktests/tool_palette_node_connections.spec.ts:84:7 â€º Tool Palette and Node Connections â€º Tool drag-and-drop from palette to canvas
ğŸ“Š Test 1: Identifying drag-and-drop targets...

[1A[2KğŸ“Š Canvas container visible: [33mfalse[39m

[1A[2Kâœ… Tool drag-and-drop test completed

[1A[2K[34/36] tests/tool_palette_node_connections.spec.ts:309:7 â€º Tool Palette and Node Connections â€º Complex workflow topology creation
[1A[2Ktests/tool_palette_node_connections.spec.ts:309:7 â€º Tool Palette and Node Connections â€º Complex workflow topology creation
ğŸš€ Starting complex workflow topology test...

[1A[2KğŸ“Š Test 1: Creating multiple agents...

[1A[2KğŸ“Š Created agent 1: [33m92[39m

[1A[2KğŸ“Š Created agent 2: [33m93[39m

[1A[2KğŸ“Š Created agent 3: [33m94[39m

[1A[2KğŸ“Š Total agents created: [33m3[39m

[1A[2KğŸ“Š Test 2: Creating complex workflow topology...

[1A[2KğŸ“Š Complex workflow created: [33m4[39m

[1A[2KğŸ“Š Test 3: Verifying topology integrity...

[1A[2Kâœ… Complex workflow topology test completed

[1A[2K[35/36] tests/tool_palette_node_connections.spec.ts:458:7 â€º Tool Palette and Node Connections â€º Connection validation and constraint checking
[1A[2Ktests/tool_palette_node_connections.spec.ts:458:7 â€º Tool Palette and Node Connections â€º Connection validation and constraint checking
ğŸš€ Starting connection validation test...

[1A[2KğŸ“Š Test 1: Testing valid connection topology...

[1A[2KğŸ“Š Valid workflow creation status: [33m200[39m

[1A[2Kâœ… Valid connection topology accepted

[1A[2KğŸ“Š Test 2: Testing invalid connection scenarios...

[1A[2KğŸ“Š Circular workflow creation status: [33m200[39m

[1A[2KğŸ“Š Circular references allowed (system permits cycles)

[1A[2KğŸ“Š Test 3: Testing non-existent node references...

[1A[2KğŸ“Š Invalid node workflow status: [33m200[39m

[1A[2Kâœ… Connection validation test completed

[1A[2K[36/36] tests/workflow_execution_http.spec.ts:15:7 â€º Workflow Execution with HTTP Tools â€º Execute workflow with HTTP tool and verify requests
[1A[2Ktests/workflow_execution_http.spec.ts:15:7 â€º Workflow Execution with HTTP Tools â€º Execute workflow with HTTP tool and verify requests
ğŸš€ Starting workflow execution test...

[1A[2KğŸ“Š Worker ID: 2

[1A[2KğŸ“Š Step 1: Creating test agent...

[1A[2Kâœ… Test agent created with ID: [33m1[39m

[1A[2KğŸ“Š Step 2: Attempting workflow creation...

[1A[2Kâœ… Workflow created with ID: [33m2[39m

[1A[2KğŸ“Š Step 3: Executing workflow...

[1A[2K[2m[WebServer] [22mERROR - [AgentRunner] Exception during runnable.ainvoke: Error code: 404 - {'error': {'message': 'The model `gpt-mock` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
[2m[WebServer] [22mTraceback (most recent call last):
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/managers/agent_runner.py", line 137, in run_thread
[2m[WebServer] [22m    updated_messages = await self._runnable.ainvoke(original_msgs, config)
[2m[WebServer] [22m                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2850, in ainvoke
[2m[WebServer] [22m    async for chunk in self.astream(
[2m[WebServer] [22m    ...<13 lines>...
[2m[WebServer] [22m            chunks.append(chunk)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2732, in astream
[2m[WebServer] [22m    async for _ in runner.atick(
[2m[WebServer] [22m    ...<7 lines>...
[2m[WebServer] [22m            yield o
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 256, in agent_executor
[2m[WebServer] [22m    return _agent_executor_sync(messages, previous=previous)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 248, in _agent_executor_sync
[2m[WebServer] [22m    return asyncio.run(_agent_executor_async(messages, previous=previous))
[2m[WebServer] [22m           ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/runners.py", line 194, in run
[2m[WebServer] [22m    return runner.run(main)
[2m[WebServer] [22m           ~~~~~~~~~~^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/runners.py", line 118, in run
[2m[WebServer] [22m    return self._loop.run_until_complete(task)
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/base_events.py", line 720, in run_until_complete
[2m[WebServer] [22m    return future.result()
[2m[WebServer] [22m           ~~~~~~~~~~~~~^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 208, in _agent_executor_async
[2m[WebServer] [22m    llm_response = await _call_model_async(current_messages)
[2m[WebServer] [22m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 134, in _call_model_async
[2m[WebServer] [22m    return await asyncio.to_thread(_call_model_sync, messages)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/threads.py", line 25, in to_thread
[2m[WebServer] [22m    return await loop.run_in_executor(None, func_call)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/thread.py", line 59, in run
[2m[WebServer] [22m    result = self.fn(*self.args, **self.kwargs)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 127, in _call_model_sync
[2m[WebServer] [22m    return llm_with_tools.invoke(messages)
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/runnables/base.py", line 5416, in invoke
[2m[WebServer] [22m    return self.bound.invoke(
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        input,
[2m[WebServer] [22m        ^^^^^^
[2m[WebServer] [22m        self._merge_configs(config),
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m        **{**self.kwargs, **kwargs},
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 369, in invoke
[2m[WebServer] [22m    self.generate_prompt(
[2m[WebServer] [22m    ~~~~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        [self._convert_input(input)],
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<6 lines>...
[2m[WebServer] [22m        **kwargs,
[2m[WebServer] [22m        ^^^^^^^^^
[2m[WebServer] [22m    ).generations[0][0],
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 946, in generate_prompt
[2m[WebServer] [22m    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
[2m[WebServer] [22m           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 765, in generate
[2m[WebServer] [22m    self._generate_with_cache(
[2m[WebServer] [22m    ~~~~~~~~~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        m,
[2m[WebServer] [22m        ^^
[2m[WebServer] [22m    ...<2 lines>...
[2m[WebServer] [22m        **kwargs,
[2m[WebServer] [22m        ^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 1011, in _generate_with_cache
[2m[WebServer] [22m    result = self._generate(
[2m[WebServer] [22m        messages, stop=stop, run_manager=run_manager, **kwargs
[2m[WebServer] [22m    )
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py", line 991, in _generate
[2m[WebServer] [22m    response = self.client.create(**payload)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_utils/_utils.py", line 287, in wrapper
[2m[WebServer] [22m    return func(*args, **kwargs)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py", line 925, in create
[2m[WebServer] [22m    return self._post(
[2m[WebServer] [22m           ~~~~~~~~~~^
[2m[WebServer] [22m        "/chat/completions",
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<43 lines>...
[2m[WebServer] [22m        stream_cls=Stream[ChatCompletionChunk],
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_base_client.py", line 1239, in post
[2m[WebServer] [22m    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
[2m[WebServer] [22m                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_base_client.py", line 1034, in request
[2m[WebServer] [22m    raise self._make_status_error_from_response(err.response) from None
[2m[WebServer] [22mopenai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `gpt-mock` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
[2m[WebServer] [22mDuring task with name 'agent_executor' and id '40f0318f-84e6-156c-6968-498b27db9d91'

[1A[2K[2m[WebServer] [22mERROR - [AgentNode] Exception in agent node agent-1 (agent_id=1): Error code: 404 - {'error': {'message': 'The model `gpt-mock` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
[2m[WebServer] [22mTraceback (most recent call last):
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/services/langgraph_workflow_engine.py", line 729, in agent_node
[2m[WebServer] [22m    created_messages = await runner.run_thread(db, thread)
[2m[WebServer] [22m                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/managers/agent_runner.py", line 137, in run_thread
[2m[WebServer] [22m    updated_messages = await self._runnable.ainvoke(original_msgs, config)
[2m[WebServer] [22m                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2850, in ainvoke
[2m[WebServer] [22m    async for chunk in self.astream(
[2m[WebServer] [22m    ...<13 lines>...
[2m[WebServer] [22m            chunks.append(chunk)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2732, in astream
[2m[WebServer] [22m    async for _ in runner.atick(
[2m[WebServer] [22m    ...<7 lines>...
[2m[WebServer] [22m            yield o
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 256, in agent_executor
[2m[WebServer] [22m    return _agent_executor_sync(messages, previous=previous)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 248, in _agent_executor_sync
[2m[WebServer] [22m    return asyncio.run(_agent_executor_async(messages, previous=previous))
[2m[WebServer] [22m           ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/runners.py", line 194, in run
[2m[WebServer] [22m    return runner.run(main)
[2m[WebServer] [22m           ~~~~~~~~~~^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/runners.py", line 118, in run
[2m[WebServer] [22m    return self._loop.run_until_complete(task)
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/base_events.py", line 720, in run_until_complete
[2m[WebServer] [22m    return future.result()
[2m[WebServer] [22m           ~~~~~~~~~~~~~^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 208, in _agent_executor_async
[2m[WebServer] [22m    llm_response = await _call_model_async(current_messages)
[2m[WebServer] [22m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 134, in _call_model_async
[2m[WebServer] [22m    return await asyncio.to_thread(_call_model_sync, messages)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/threads.py", line 25, in to_thread
[2m[WebServer] [22m    return await loop.run_in_executor(None, func_call)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/thread.py", line 59, in run
[2m[WebServer] [22m    result = self.fn(*self.args, **self.kwargs)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 127, in _call_model_sync
[2m[WebServer] [22m    return llm_with_tools.invoke(messages)
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/runnables/base.py", line 5416, in invoke
[2m[WebServer] [22m    return self.bound.invoke(
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        input,
[2m[WebServer] [22m        ^^^^^^
[2m[WebServer] [22m        self._merge_configs(config),
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m        **{**self.kwargs, **kwargs},
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 369, in invoke
[2m[WebServer] [22m    self.generate_prompt(
[2m[WebServer] [22m    ~~~~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        [self._convert_input(input)],
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<6 lines>...
[2m[WebServer] [22m        **kwargs,
[2m[WebServer] [22m        ^^^^^^^^^
[2m[WebServer] [22m    ).generations[0][0],
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 946, in generate_prompt
[2m[WebServer] [22m    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
[2m[WebServer] [22m           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 765, in generate
[2m[WebServer] [22m    self._generate_with_cache(
[2m[WebServer] [22m    ~~~~~~~~~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        m,
[2m[WebServer] [22m        ^^
[2m[WebServer] [22m    ...<2 lines>...
[2m[WebServer] [22m        **kwargs,
[2m[WebServer] [22m        ^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 1011, in _generate_with_cache
[2m[WebServer] [22m    result = self._generate(
[2m[WebServer] [22m        messages, stop=stop, run_manager=run_manager, **kwargs
[2m[WebServer] [22m    )
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py", line 991, in _generate
[2m[WebServer] [22m    response = self.client.create(**payload)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_utils/_utils.py", line 287, in wrapper
[2m[WebServer] [22m    return func(*args, **kwargs)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py", line 925, in create
[2m[WebServer] [22m    return self._post(
[2m[WebServer] [22m           ~~~~~~~~~~^
[2m[WebServer] [22m        "/chat/completions",
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<43 lines>...
[2m[WebServer] [22m        stream_cls=Stream[ChatCompletionChunk],
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_base_client.py", line 1239, in post
[2m[WebServer] [22m    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
[2m[WebServer] [22m                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_base_client.py", line 1034, in request
[2m[WebServer] [22m    raise self._make_status_error_from_response(err.response) from None
[2m[WebServer] [22mopenai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `gpt-mock` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
[2m[WebServer] [22mDuring task with name 'agent_executor' and id '40f0318f-84e6-156c-6968-498b27db9d91'

[1A[2K[2m[WebServer] [22mERROR - [AgentNode] Updated node_state to 'failed' in DB

[1A[2K[2m[WebServer] [22mERROR - [AgentNode] Re-raising exception to fail workflow execution

[1A[2K[2m[WebServer] [22mERROR - [LangGraphEngine] Execution failed â€“ execution_id=1
[2m[WebServer] [22mTraceback (most recent call last):
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/services/langgraph_workflow_engine.py", line 146, in execute_workflow
[2m[WebServer] [22m    await self._execute_workflow_internal(workflow, execution, db)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/services/langgraph_workflow_engine.py", line 214, in _execute_workflow_internal
[2m[WebServer] [22m    async for chunk in graph.astream(initial_state, config):
[2m[WebServer] [22m    ...<36 lines>...
[2m[WebServer] [22m            logger.warning(f"[LangGraphEngine] Received empty chunk #{chunk_count}")
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2732, in astream
[2m[WebServer] [22m    async for _ in runner.atick(
[2m[WebServer] [22m    ...<7 lines>...
[2m[WebServer] [22m            yield o
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/services/langgraph_workflow_engine.py", line 729, in agent_node
[2m[WebServer] [22m    created_messages = await runner.run_thread(db, thread)
[2m[WebServer] [22m                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/managers/agent_runner.py", line 137, in run_thread
[2m[WebServer] [22m    updated_messages = await self._runnable.ainvoke(original_msgs, config)
[2m[WebServer] [22m                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2850, in ainvoke
[2m[WebServer] [22m    async for chunk in self.astream(
[2m[WebServer] [22m    ...<13 lines>...
[2m[WebServer] [22m            chunks.append(chunk)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2732, in astream
[2m[WebServer] [22m    async for _ in runner.atick(
[2m[WebServer] [22m    ...<7 lines>...
[2m[WebServer] [22m            yield o
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 256, in agent_executor
[2m[WebServer] [22m    return _agent_executor_sync(messages, previous=previous)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 248, in _agent_executor_sync
[2m[WebServer] [22m    return asyncio.run(_agent_executor_async(messages, previous=previous))
[2m[WebServer] [22m           ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/runners.py", line 194, in run
[2m[WebServer] [22m    return runner.run(main)
[2m[WebServer] [22m           ~~~~~~~~~~^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/runners.py", line 118, in run
[2m[WebServer] [22m    return self._loop.run_until_complete(task)
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/base_events.py", line 720, in run_until_complete
[2m[WebServer] [22m    return future.result()
[2m[WebServer] [22m           ~~~~~~~~~~~~~^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 208, in _agent_executor_async
[2m[WebServer] [22m    llm_response = await _call_model_async(current_messages)
[2m[WebServer] [22m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 134, in _call_model_async
[2m[WebServer] [22m    return await asyncio.to_thread(_call_model_sync, messages)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/threads.py", line 25, in to_thread
[2m[WebServer] [22m    return await loop.run_in_executor(None, func_call)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/thread.py", line 59, in run
[2m[WebServer] [22m    result = self.fn(*self.args, **self.kwargs)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 127, in _call_model_sync
[2m[WebServer] [22m    return llm_with_tools.invoke(messages)
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/runnables/base.py", line 5416, in invoke
[2m[WebServer] [22m    return self.bound.invoke(
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        input,
[2m[WebServer] [22m        ^^^^^^
[2m[WebServer] [22m        self._merge_configs(config),
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m        **{**self.kwargs, **kwargs},
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 369, in invoke
[2m[WebServer] [22m    self.generate_prompt(
[2m[WebServer] [22m    ~~~~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        [self._convert_input(input)],
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<6 lines>...
[2m[WebServer] [22m        **kwargs,
[2m[WebServer] [22m        ^^^^^^^^^
[2m[WebServer] [22m    ).generations[0][0],
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 946, in generate_prompt
[2m[WebServer] [22m    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
[2m[WebServer] [22m           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 765, in generate
[2m[WebServer] [22m    self._generate_with_cache(
[2m[WebServer] [22m    ~~~~~~~~~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        m,
[2m[WebServer] [22m        ^^
[2m[WebServer] [22m    ...<2 lines>...
[2m[WebServer] [22m        **kwargs,
[2m[WebServer] [22m        ^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 1011, in _generate_with_cache
[2m[WebServer] [22m    result = self._generate(
[2m[WebServer] [22m        messages, stop=stop, run_manager=run_manager, **kwargs
[2m[WebServer] [22m    )
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py", line 991, in _generate
[2m[WebServer] [22m    response = self.client.create(**payload)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_utils/_utils.py", line 287, in wrapper
[2m[WebServer] [22m    return func(*args, **kwargs)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py", line 925, in create
[2m[WebServer] [22m    return self._post(
[2m[WebServer] [22m           ~~~~~~~~~~^
[2m[WebServer] [22m        "/chat/completions",
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<43 lines>...
[2m[WebServer] [22m        stream_cls=Stream[ChatCompletionChunk],
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_base_client.py", line 1239, in post
[2m[WebServer] [22m    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
[2m[WebServer] [22m                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_base_client.py", line 1034, in request
[2m[WebServer] [22m    raise self._make_status_error_from_response(err.response) from None
[2m[WebServer] [22mopenai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `gpt-mock` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
[2m[WebServer] [22mDuring task with name 'agent_executor' and id '40f0318f-84e6-156c-6968-498b27db9d91'
[2m[WebServer] [22mDuring task with name 'agent-1' and id '9bc59543-1ea7-06b5-7da1-dadb5a80beab'

[1A[2K[2m[WebServer] [22mERROR - Unhandled exception: Error code: 404 - {'error': {'message': 'The model `gpt-mock` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
[2m[WebServer] [22mTraceback (most recent call last):
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/middleware/errors.py", line 165, in __call__
[2m[WebServer] [22m    await self.app(scope, receive, _send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/middleware/worker_db.py", line 101, in __call__
[2m[WebServer] [22m    await self.app(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/middleware/cors.py", line 85, in __call__
[2m[WebServer] [22m    await self.app(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/middleware/exceptions.py", line 62, in __call__
[2m[WebServer] [22m    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
[2m[WebServer] [22m    raise exc
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
[2m[WebServer] [22m    await app(scope, receive, sender)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/routing.py", line 714, in __call__
[2m[WebServer] [22m    await self.middleware_stack(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/routing.py", line 734, in app
[2m[WebServer] [22m    await route.handle(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/routing.py", line 288, in handle
[2m[WebServer] [22m    await self.app(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/routing.py", line 76, in app
[2m[WebServer] [22m    await wrap_app_handling_exceptions(app, request)(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
[2m[WebServer] [22m    raise exc
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
[2m[WebServer] [22m    await app(scope, receive, sender)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/routing.py", line 73, in app
[2m[WebServer] [22m    response = await f(request)
[2m[WebServer] [22m               ^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/fastapi/routing.py", line 301, in app
[2m[WebServer] [22m    raw_response = await run_endpoint_function(
[2m[WebServer] [22m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<3 lines>...
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/fastapi/routing.py", line 212, in run_endpoint_function
[2m[WebServer] [22m    return await dependant.call(**values)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/routers/workflow_executions.py", line 74, in start_workflow_execution
[2m[WebServer] [22m    execution_id = await langgraph_workflow_engine.execute_workflow(workflow_id)
[2m[WebServer] [22m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/services/langgraph_workflow_engine.py", line 146, in execute_workflow
[2m[WebServer] [22m    await self._execute_workflow_internal(workflow, execution, db)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/services/langgraph_workflow_engine.py", line 214, in _execute_workflow_internal
[2m[WebServer] [22m    async for chunk in graph.astream(initial_state, config):
[2m[WebServer] [22m    ...<36 lines>...
[2m[WebServer] [22m            logger.warning(f"[LangGraphEngine] Received empty chunk #{chunk_count}")
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2732, in astream
[2m[WebServer] [22m    async for _ in runner.atick(
[2m[WebServer] [22m    ...<7 lines>...
[2m[WebServer] [22m            yield o
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/services/langgraph_workflow_engine.py", line 729, in agent_node
[2m[WebServer] [22m    created_messages = await runner.run_thread(db, thread)
[2m[WebServer] [22m                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/managers/agent_runner.py", line 137, in run_thread
[2m[WebServer] [22m    updated_messages = await self._runnable.ainvoke(original_msgs, config)
[2m[WebServer] [22m                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2850, in ainvoke
[2m[WebServer] [22m    async for chunk in self.astream(
[2m[WebServer] [22m    ...<13 lines>...
[2m[WebServer] [22m            chunks.append(chunk)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2732, in astream
[2m[WebServer] [22m    async for _ in runner.atick(
[2m[WebServer] [22m    ...<7 lines>...
[2m[WebServer] [22m            yield o
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 256, in agent_executor
[2m[WebServer] [22m    return _agent_executor_sync(messages, previous=previous)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 248, in _agent_executor_sync
[2m[WebServer] [22m    return asyncio.run(_agent_executor_async(messages, previous=previous))
[2m[WebServer] [22m           ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/runners.py", line 194, in run
[2m[WebServer] [22m    return runner.run(main)
[2m[WebServer] [22m           ~~~~~~~~~~^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/runners.py", line 118, in run
[2m[WebServer] [22m    return self._loop.run_until_complete(task)
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/base_events.py", line 720, in run_until_complete
[2m[WebServer] [22m    return future.result()
[2m[WebServer] [22m           ~~~~~~~~~~~~~^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 208, in _agent_executor_async
[2m[WebServer] [22m    llm_response = await _call_model_async(current_messages)
[2m[WebServer] [22m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 134, in _call_model_async
[2m[WebServer] [22m    return await asyncio.to_thread(_call_model_sync, messages)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/threads.py", line 25, in to_thread
[2m[WebServer] [22m    return await loop.run_in_executor(None, func_call)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/thread.py", line 59, in run
[2m[WebServer] [22m    result = self.fn(*self.args, **self.kwargs)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 127, in _call_model_sync
[2m[WebServer] [22m    return llm_with_tools.invoke(messages)
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/runnables/base.py", line 5416, in invoke
[2m[WebServer] [22m    return self.bound.invoke(
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        input,
[2m[WebServer] [22m        ^^^^^^
[2m[WebServer] [22m        self._merge_configs(config),
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m        **{**self.kwargs, **kwargs},
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 369, in invoke
[2m[WebServer] [22m    self.generate_prompt(
[2m[WebServer] [22m    ~~~~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        [self._convert_input(input)],
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<6 lines>...
[2m[WebServer] [22m        **kwargs,
[2m[WebServer] [22m        ^^^^^^^^^
[2m[WebServer] [22m    ).generations[0][0],
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 946, in generate_prompt
[2m[WebServer] [22m    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
[2m[WebServer] [22m           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 765, 

[1A[2K[2m[WebServer] [22min generate
[2m[WebServer] [22m    self._generate_with_cache(
[2m[WebServer] [22m    ~~~~~~~~~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        m,
[2m[WebServer] [22m        ^^
[2m[WebServer] [22m    ...<2 lines>...
[2m[WebServer] [22m        **kwargs,
[2m[WebServer] [22m        ^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 1011, in _generate_with_cache
[2m[WebServer] [22m    result = self._generate(
[2m[WebServer] [22m        messages, stop=stop, run_manager=run_manager, **kwargs
[2m[WebServer] [22m    )
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py", line 991, in _generate
[2m[WebServer] [22m    response = self.client.create(**payload)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_utils/_utils.py", line 287, in wrapper
[2m[WebServer] [22m    return func(*args, **kwargs)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py", line 925, in create
[2m[WebServer] [22m    return self._post(
[2m[WebServer] [22m           ~~~~~~~~~~^
[2m[WebServer] [22m        "/chat/completions",
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<43 lines>...
[2m[WebServer] [22m        stream_cls=Stream[ChatCompletionChunk],
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_base_client.py", line 1239, in post
[2m[WebServer] [22m    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
[2m[WebServer] [22m                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_base_client.py", line 1034, in request
[2m[WebServer] [22m    raise self._make_status_error_from_response(err.response) from None
[2m[WebServer] [22mopenai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `gpt-mock` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
[2m[WebServer] [22mDuring task with name 'agent_executor' and id '40f0318f-84e6-156c-6968-498b27db9d91'
[2m[WebServer] [22mDuring task with name 'agent-1' and id '9bc59543-1ea7-06b5-7da1-dadb5a80beab'

[1A[2KâŒ Workflow execution failed: [33m500[39m

[1A[2KğŸ“Š Step 5: Testing direct HTTP tool usage...

[1A[2K[2m[WebServer] [22mERROR:    Exception in ASGI application
[2m[WebServer] [22mTraceback (most recent call last):
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/uvicorn/protocols/http/h11_impl.py", line 408, in run_asgi
[2m[WebServer] [22m    result = await app(  # type: ignore[func-returns-value]
[2m[WebServer] [22m             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m        self.scope, self.receive, self.send
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/uvicorn/middleware/proxy_headers.py", line 84, in __call__
[2m[WebServer] [22m    return await self.app(scope, receive, send)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/fastapi/applications.py", line 1054, in __call__
[2m[WebServer] [22m    await super().__call__(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/applications.py", line 112, in __call__
[2m[WebServer] [22m    await self.middleware_stack(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/middleware/errors.py", line 187, in __call__
[2m[WebServer] [22m    raise exc
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/middleware/errors.py", line 165, in __call__
[2m[WebServer] [22m    await self.app(scope, receive, _send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/middleware/worker_db.py", line 101, in __call__
[2m[WebServer] [22m    await self.app(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/middleware/cors.py", line 85, in __call__
[2m[WebServer] [22m    await self.app(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/middleware/exceptions.py", line 62, in __call__
[2m[WebServer] [22m    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
[2m[WebServer] [22m    raise exc
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
[2m[WebServer] [22m    await app(scope, receive, sender)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/routing.py", line 714, in __call__
[2m[WebServer] [22m    await self.middleware_stack(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/routing.py", line 734, in app
[2m[WebServer] [22m    await route.handle(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/routing.py", line 288, in handle
[2m[WebServer] [22m    await self.app(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/routing.py", line 76, in app
[2m[WebServer] [22m    await wrap_app_handling_exceptions(app, request)(scope, receive, send)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
[2m[WebServer] [22m    raise exc
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
[2m[WebServer] [22m    await app(scope, receive, sender)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/starlette/routing.py", line 73, in app
[2m[WebServer] [22m    response = await f(request)
[2m[WebServer] [22m               ^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/fastapi/routing.py", line 301, in app
[2m[WebServer] [22m    raw_response = await run_endpoint_function(
[2m[WebServer] [22m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<3 lines>...
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/fastapi/routing.py", line 212, in run_endpoint_function
[2m[WebServer] [22m    return await dependant.call(**values)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/routers/workflow_executions.py", line 74, in start_workflow_execution
[2m[WebServer] [22m    execution_id = await langgraph_workflow_engine.execute_workflow(workflow_id)
[2m[WebServer] [22m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/services/langgraph_workflow_engine.py", line 146, in execute_workflow
[2m[WebServer] [22m    await self._execute_workflow_internal(workflow, execution, db)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/services/langgraph_workflow_engine.py", line 214, in _execute_workflow_internal
[2m[WebServer] [22m    async for chunk in graph.astream(initial_state, config):
[2m[WebServer] [22m    ...<36 lines>...
[2m[WebServer] [22m            logger.warning(f"[LangGraphEngine] Received empty chunk #{chunk_count}")
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2732, in astream
[2m[WebServer] [22m    async for _ in runner.atick(
[2m[WebServer] [22m    ...<7 lines>...
[2m[WebServer] [22m            yield o
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/services/langgraph_workflow_engine.py", line 729, in agent_node
[2m[WebServer] [22m    created_messages = await runner.run_thread(db, thread)
[2m[WebServer] [22m                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/managers/agent_runner.py", line 137, in run_thread
[2m[WebServer] [22m    updated_messages = await self._runnable.ainvoke(original_msgs, config)
[2m[WebServer] [22m                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2850, in ainvoke
[2m[WebServer] [22m    async for chunk in self.astream(
[2m[WebServer] [22m    ...<13 lines>...
[2m[WebServer] [22m            chunks.append(chunk)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py", line 2732, in astream
[2m[WebServer] [22m    async for _ in runner.atick(
[2m[WebServer] [22m    ...<7 lines>...
[2m[WebServer] [22m            yield o
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 256, in agent_executor
[2m[WebServer] [22m    return _agent_executor_sync(messages, previous=previous)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 248, in _agent_executor_sync
[2m[WebServer] [22m    return asyncio.run(_agent_executor_async(messages, previous=previous))
[2m[WebServer] [22m           ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/runners.py", line 194, in run
[2m[WebServer] [22m    return runner.run(main)
[2m[WebServer] [22m           ~~~~~~~~~~^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/runners.py", line 118, in run
[2m[WebServer] [22m    return self._loop.run_until_complete(task)
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/base_events.py", line 720, in run_until_complete
[2m[WebServer] [22m    return future.result()
[2m[WebServer] [22m           ~~~~~~~~~~~~~^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 208, in _agent_executor_async
[2m[WebServer] [22m    llm_response = await _call_model_async(current_messages)
[2m[WebServer] [22m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 134, in _call_model_async
[2m[WebServer] [22m    return await asyncio.to_thread(_call_model_sync, messages)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/threads.py", line 25, in to_thread
[2m[WebServer] [22m    return await loop.run_in_executor(None, func_call)
[2m[WebServer] [22m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/thread.py", line 59, in run
[2m[WebServer] [22m    result = self.fn(*self.args, **self.kwargs)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/zerg/agents_def/zerg_react_agent.py", line 127, in _call_model_sync
[2m[WebServer] [22m    return llm_with_tools.invoke(messages)
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/runnables/base.py", line 5416, in invoke
[2m[WebServer] [22m    return self.bound.invoke(
[2m[WebServer] [22m           ~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        input,
[2m[WebServer] [22m        ^^^^^^
[2m[WebServer] [22m        self._merge_configs(config),
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^

[1A[2K[2m[WebServer] [22m^^^^^^^^^
[2m[WebServer] [22m        **{**self.kwargs, **kwargs},
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 369, in invoke
[2m[WebServer] [22m    self.generate_prompt(
[2m[WebServer] [22m    ~~~~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        [self._convert_input(input)],
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<6 lines>...
[2m[WebServer] [22m        **kwargs,
[2m[WebServer] [22m        ^^^^^^^^^
[2m[WebServer] [22m    ).generations[0][0],
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 946, in generate_prompt
[2m[WebServer] [22m    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
[2m[WebServer] [22m           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 765, in generate
[2m[WebServer] [22m    self._generate_with_cache(
[2m[WebServer] [22m    ~~~~~~~~~~~~~~~~~~~~~~~~~^
[2m[WebServer] [22m        m,
[2m[WebServer] [22m        ^^
[2m[WebServer] [22m    ...<2 lines>...
[2m[WebServer] [22m        **kwargs,
[2m[WebServer] [22m        ^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py", line 1011, in _generate_with_cache
[2m[WebServer] [22m    result = self._generate(
[2m[WebServer] [22m        messages, stop=stop, run_manager=run_manager, **kwargs
[2m[WebServer] [22m    )
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py", line 991, in _generate
[2m[WebServer] [22m    response = self.client.create(**payload)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_utils/_utils.py", line 287, in wrapper
[2m[WebServer] [22m    return func(*args, **kwargs)
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py", line 925, in create
[2m[WebServer] [22m    return self._post(
[2m[WebServer] [22m           ~~~~~~~~~~^
[2m[WebServer] [22m        "/chat/completions",
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    ...<43 lines>...
[2m[WebServer] [22m        stream_cls=Stream[ChatCompletionChunk],
[2m[WebServer] [22m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m    )
[2m[WebServer] [22m    ^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_base_client.py", line 1239, in post
[2m[WebServer] [22m    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
[2m[WebServer] [22m                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2m[WebServer] [22m  File "/Users/davidrose/git/zerg/backend/.venv/lib/python3.13/site-packages/openai/_base_client.py", line 1034, in request
[2m[WebServer] [22m    raise self._make_status_error_from_response(err.response) from None
[2m[WebServer] [22mopenai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `gpt-mock` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
[2m[WebServer] [22mDuring task with name 'agent_executor' and id '40f0318f-84e6-156c-6968-498b27db9d91'
[2m[WebServer] [22mDuring task with name 'agent-1' and id '9bc59543-1ea7-06b5-7da1-dadb5a80beab'

[1A[2KğŸ“Š Tools endpoint not available or error: apiRequestContext.get: read ECONNRESET
Call log:
[2m  - â†’ GET http://localhost:8001/api/tools[22m
[2m    - user-agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/136.0.7103.25 Safari/537.36[22m
[2m    - accept: */*[22m
[2m    - accept-encoding: gzip,deflate,br[22m
[2m    - X-Test-Worker: 2[22m


[1A[2KğŸ“Š Step 6: Checking UI for workflow execution...

[1A[2Ktests/tool_palette_node_connections.spec.ts:180:7 â€º Tool Palette and Node Connections â€º Node connection handle detection and interaction
ğŸ“Š Test 1: Detecting canvas nodes...

[1A[2KğŸ“Š Existing nodes on canvas: [33m0[39m

[1A[2KğŸ“Š No existing nodes - attempting to create nodes for connection test...

[1A[2KğŸ“Š Test 2: Detecting connection handles...

[1A[2KğŸ“Š Connection handles found: [33m0[39m

[1A[2Kâš ï¸  No connection handles detected - may need UI implementation

[1A[2Kâœ… Node connection test completed

[1A[2Ktests/workflow_execution_http.spec.ts:15:7 â€º Workflow Execution with HTTP Tools â€º Execute workflow with HTTP tool and verify requests
ğŸ“Š Execute buttons found: [33m0[39m

[1A[2KğŸ“Š Run buttons found: [33m0[39m

[1A[2KğŸ“Š Workflow elements found: [33m0[39m

[1A[2Kâœ… Workflow execution test completed

[1A[2KğŸ“Š Summary: Workflow execution infrastructure validated

[1A[2K  1 failed
    tests/data_persistence_recovery.spec.ts:19:7 â€º Data Persistence and Recovery â€º Data persistence across sessions 
  35 passed (1.0m)

[36m  Serving HTML report at http://localhost:9323. Press Ctrl+C to quit.[39m
